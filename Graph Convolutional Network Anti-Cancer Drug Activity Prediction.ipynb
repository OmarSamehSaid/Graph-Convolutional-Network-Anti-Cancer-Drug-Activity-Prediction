{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ca6a8f",
   "metadata": {},
   "source": [
    "## Data mining questions\n",
    "\n",
    "1- Based on the provided template, describe the format of the input file (sdf file).\n",
    "\n",
    "- Structure Data Format (SDF) is a file format commonly used in chemistry for storing and exchanging molecular structures, properties, and related data.\n",
    "- Can contain information about individual molecules or collections of molecules\n",
    "- it include information about the positions of individual atoms in a chemical molecule as well as the connections between them\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "2- What are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?\n",
    "\n",
    "- data :The data is in a tokenized form and includes the nodes of the chemical molecule.The batch_size refers to the number of samples in a batch, while max_len_nodes indicates the padded length of the tokenized nodes.\n",
    "\n",
    "- edge : it contains information about the connections between atoms.\n",
    "- node2graph:It is The segmented mean input tensor contains information about segmented IDs.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "3- For each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?\n",
    "- dim of gnn_out is (batch_size_node_dimension, hidden layers), where batch_size_node_dimension refers to the dimension of the input data vector (i.e., the dimension of the tokenized vector for the entire batch) and hidden layers represents the aggregation output of the model for each hidden layer.\n",
    "- dim of avg is determined by calculating the segmented mean of gnn_out using the segmented IDs. Specifically, the output of gnn_out is (tokenized_vector_dimension, hidden_layers) for each sample in the batch_size, and a segment ID is assigned to each sample.\n",
    "\n",
    "---\n",
    "\n",
    "4- What is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?\n",
    "\n",
    "- segment_mean: calculates the average of data that have the same segmented ids.\n",
    "\n",
    "- reduce_mean: computes the mean value of elements across the specified dimensions of a tensor.\n",
    "- The shape of the \"pred\" tensor is (num_of_graphs, num_of_units in the output layer), where the first dimension represents the number of graphs and the second dimension is the number of units in the output layer, which is 1.\n",
    "\n",
    "---\n",
    "\n",
    "5- What is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?\n",
    "\n",
    "- By increasing the number of trainable parameters in the network, the complexity of the model will increase, allowing it to better distinguish features in each node through a more complex hyperplane. This increased complexity can lead to more accurate results for node classification.\n",
    "- the number of layers used in the template was the default number which is 4 layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ae494",
   "metadata": {},
   "source": [
    "## problem formulation\n",
    "</br>\n",
    "\n",
    "### problem definition\n",
    "\n",
    "- Our goal is to create a model that can predict the effectiveness of chemical compounds against non-small cell lung cancer using complex chemical structured data. The model will be designed to distinguish between compounds that are effective and those that are not.\n",
    "- input data consists of 2 feature sets: the first set represents the nodes, and the second set represents the edges between these nodes.\n",
    "- output is if this chemical compound is effective (1.0) or not (0.0)\n",
    "---\n",
    "\n",
    "### Data mining function\n",
    "- classification and prediction\n",
    "\n",
    "---\n",
    "\n",
    "### Challenges\n",
    "\n",
    "- Our dataset is stored in SDF files, which are chemical files that represent each sample as nodes and the edges that connect these nodes, along with the corresponding output. Therefore, we require a specialized function to extract the relevant information from these files.\n",
    "\n",
    "- The data is imbalanced\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Model impact\n",
    "\n",
    "- Addressing this medical problem has the potential to make significant progress in the field of medicine.\n",
    "\n",
    "---\n",
    "\n",
    "### The ideal solution\n",
    "\n",
    "- at the end Trial 3.6 (randomOverSample)(GNN-FiLM) was highest for me and got  0.88152 on kaggle wtih thos hyper parameters\n",
    "* params[\"hidden_dim\"] = 64\n",
    "* params[\"num_layers\"] = 6\n",
    "* params[\"film_parameter_MLP_hidden_layers\"] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c12d52",
   "metadata": {},
   "source": [
    "## Experimental protocol\n",
    "\n",
    "### Data preprocessing\n",
    "---\n",
    "- load data and visualize explore it\n",
    "- handle the imbalance problem\n",
    "---\n",
    "### Building models\n",
    "\n",
    "- Start building models each model has different hyperparameters\n",
    "- evaluate each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d12cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet networkx\n",
    "# !pip install --quiet tf2_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e4bd180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "from tqdm.notebook import tqdm\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#importing libraries for displaying network of molecule\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a6e700fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "\n",
    "#for deep Graph Neural Network\n",
    "from tf2_gnn.layers.gnn import GNN, GNNInput\n",
    "#importing tensorflow and other libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import segment_mean #to calculate segmented mean\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model #layers and model\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout #layers\n",
    "from tensorflow.keras.optimizers import Adam #optimizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import math\n",
    "import pandas as pd \n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a53bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sdf(file):\n",
    "  #opening the file\n",
    "  with open(file, 'r') as rf:\n",
    "    content = rf.read()\n",
    "    samples = content.split('$$$$')\n",
    "    \n",
    "    def parse_sample(s):\n",
    "        lines = s.splitlines()\n",
    "        links = []\n",
    "        nodes = []\n",
    "        label = 0\n",
    "        for l in lines:\n",
    "            if l.strip() == '1.0':\n",
    "                label = 1\n",
    "            if l.strip() == '-1.0':\n",
    "                label = 0\n",
    "            if l.startswith('    '):\n",
    "                feature = l.split()\n",
    "                node = feature[3]\n",
    "                nodes.append(node)\n",
    "            elif l.startswith(' '):\n",
    "                lnk = l.split()\n",
    "                if int(lnk[0]) - 1 < len(nodes):\n",
    "                    links.append((   \n",
    "                        int(lnk[0])-1,   #first atom\n",
    "                        int(lnk[1])-1, # zero-based index #second atom\n",
    "                        # int(lnk[2]) ignore edge weight\n",
    "                    ))\n",
    "        return nodes, np.array(links), label #returning nodes, links and label\n",
    "    #parse_sample for each molecule\n",
    "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7d6e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adeb63029b424fbea8507d9dbb5587be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reading train.sdf file\n",
    "training_set = read_sdf('train.sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3956ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20936\\852145860.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.unique(np.array(training_set)[:,2],return_counts=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=object), array([23806,  1218], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(training_set)[:,2],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9928cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the train data\n",
    "training_set, validation_set = train_test_split(training_set, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feedd6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20936\\852145860.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.unique(np.array(training_set)[:,2],return_counts=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=object), array([19032,   987], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(training_set)[:,2],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7504694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ccb7a661f84b859bf3a107290dce92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_set = read_sdf('test_x.sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8cd9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cm.rainbow(np.linspace(0, 1, 50))\n",
    "\n",
    "def visualize(sample):\n",
    "  #initiating an instance of Graph\n",
    "  G=nx.Graph()\n",
    "  #all atoms as nodes\n",
    "  nodes = sample[0]\n",
    "  #all connections as edges\n",
    "  edges = sample[1]\n",
    "  #empty dictionary for labels for the all nodes\n",
    "  labeldict={}\n",
    "  #empty array for each node color\n",
    "  node_color=[]\n",
    "  for i,n in enumerate(nodes):\n",
    "    #adding node to the graph each node as (0,1,2,3..)\n",
    "    G.add_node(i)\n",
    "    #dictionary building with [key,value] as [0:'C']\n",
    "    labeldict[i]=n\n",
    "    #color coding\n",
    "    node_color.append(colors[hash(n)%len(colors)])\n",
    "\n",
    "  # a list of nodes:\n",
    "  for e in edges:\n",
    "    #adding egde to the graph from one connection to other connection\n",
    "    G.add_edge(e[0], e[1]) \n",
    "\n",
    "  #drawing the graph with labels for nodes as atoms and connections as edges    \n",
    "  nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n",
    "  #draw the graph\n",
    "  plt.show()\n",
    "  #returns graph\n",
    "  return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ec78e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACVaElEQVR4nOzdd3hUZd7G8e85M2mEQAi99xaaIEoRERC7YgFRRFfEBnZBxcJrR9HFdUGwIXbEArbFgohSVHpHShAIhNAkoQXSZs7z/jGCYJJJG5gkc3+ui2vXzCm/SZm556mWMcYgIiIiIlJEdrALEBEREZHSTYFSRERERIpFgVJEREREikWBUkRERESKRYFSRERERIpFgVJEREREikWBUkRERESKRYFSRERERIpFgVJEREREikWBUkRERESKRYFSRERERIpFgVJEREREikWBUkRERESKRYFSRERERIpFgVJEREREikWBUkRERESKRYFSRERERIpFgVJEREREikWBUkRERESKRYFSRERERIpFgVJEREREikWBUkRERESKRYFSRERERIpFgVJEREREikWBUkRERESKRYFSRERERIpFgVJEREREikWBUkRERESKRYFSRERERIpFgVJEREREikWBUkRERESKRYFSRERERIpFgVJEREREikWBUkRERESKRYFSRERERIpFgVJEREREisUd7AJEROTkM8aQngGOAxEREOa2gl2SiJQhCpQiImXUjj2G7+c5rE4wJCQaMjJ9X7csqF0d4htbnN3RplM7C5etgCkiRWcZY0ywixARkcDZtsPw6kdeFq8x2LavVTI3Lhu8DlSOhRuvcHHxORaWpWApIoWnQCkiUkYYY/jse4dJUx2M8YXFwjitpcWIW1xUq6xQKSKFo0ApIlIGOI7hP+96+W5u0V/SXTZUjIH/POKmbg2FShEpOM3yFhEpA17/uHhhEnwtmvsPwfDRHlL3q61BRApOgVJEpJRbssZh2g+BCYCOA/sOwn/e9aIOLBEpKM3yFhEpxTIyDS++5cW2wPGT/9JSV7Ft7Tj2755L1pGdWLabqApNqd6wP7WaDiYsIu7YsY4D81cYZi8y9Oykrm8RyZ8CpYhIKfbTAkPKfv/HJCdMImHB3ZSr2Ix6rYYRHdsS42RzMGUpyRsmcmDPAtr2mnrCOZYFk7/20uNMzfwWkfwpUIqIlGJf/OjFsiCv3ukDexaQsOAuKtXqTdueU7FdEccei6vVm3rx95OSPCPHecbAlmRYu8nQqokCpYj4pzGUIiKlVMp+w+akvMMkQOLq0YBFiy6vnhAmj7Jd4VStd1mu57psWLhS4yhFJH8KlCIipVRCov+wZxwv+3bNJqZyByKj6xb6+o4DG7YoUIpI/hQoRURKqcRk3044ecnO3IvjOUJk+QZFur4BNiUpUIpI/hQoRURKqYxMONlbcGdmndzri0jZoEApIlJKuV2+VsS8hEVUwXaXIyMtscj3cOldQkQKQC8VIiKlVI2qFl5v3o9btou4Gj05lLKMjMPbi3SPWtWKWJyIhBQFShGRUqpZg/z7u+u3GQEY1s8fiuPN2X/tONnsTZqe67m2bWjZKDhvE8YYduwxLFnjMH+Fw/K1DinaDlKkxLKM9tYSESmVvI6h3z0eDqb5P+7vhc2bU7v57UTHxmOcbA6lrmBHwiSiY+NzLGx+1OGtj3L1pTW45pprqFOnzkl4Fn9zHMOytYavZjmsWGc4kpHzmIox0LmdxeXn2jRvqDYRkZJCgVJEpBR7Z5qXj75xcBz/xx1KXUnS2nHs2zWHrPRd2HYYURWaUqXuJdRpcQfhkVVznBMRlkVk6k18+83XZGVlcfbZZ3PdddfRr18/KleuHNDnsWajw78nedm+C2wbv8/HZYPXgTbNLB682UXt6lp4XSTYFChFREqx9X+kcOez0YAroNe1LLi+j82gK10cOHCAL774gilTpvDjjz9i2zbnn38+AwYM4PLLLycmJqbI93Ecw1tTHT751sl3P/J/ctm+8HnX9S4u7aHWSpFg0l+giEgp5DgOb731Fmd1akby2ufxP9+7cGwbqleBay/2vUVUrFiRQYMGMWPGDHbs2MHLL7/M/v37ueGGG6hevTrXXHMNX331FZmZmYW6j9cxjJ7o5ZNvfc2RhQmTvvMh2wMvv+tlynQ/s5NE5KRToBQRKWVWrlxJt27duPXWW7nkkkv46cs7aNbACtgSP8bAw7e6iIzI2ZVcvXp17rrrLn799Ve2bNnCE088wfr167niiiuoUaMGN998M7NmzcLrb/r5XyZNdZg1PzBB+K2pDjN/zaffX0ROGnV5i4iUEocOHeKJJ55g3LhxNGvWjNdee41zzjkHgH0HDfeO8rDrT1/LXVFZFjxym4tzuxQuna5du5YpU6bw0UcfsXnzZmrUqEH//v0ZMGAAnTp1wrJODKdrNjrcOyqwrYpREfDO826qxmlMpcippkApIlLCGWOYOnUq9913H/v27eOJJ57g/vvvJzw8/ITj9h80PPGKhzUbC38P24aIMHj4NhfdTi96U6cxhsWLFzNlyhQ++eQTdu7cSaNGjbj22msZMGAArVu3xnEMgx7xsHOP/27utNRVbFs7jv2755J1ZCeW7SaqQlOqN+xPraaDCYuIO+F4lw1d2ls8dbe7yPWLSNEoUIqIlGB//PEHd911FzNmzODyyy9n7Nix1K9fP8/jHce37M6bnzpkZwOWrws7L0dnTJ/Z1mLYTS6qVgpc657X62XOnDlMmTKFqVOnsn//ftq0acP5fR5h+fZ+fs/9e6mjZtRuPoTo2JYYJ5uDKUvZkfA25Su1yXWpI8uCyWPcVK+sVkqRU0mBUkSkBMrIyOCFF17g+eefp0aNGrzyyitcdtllBT4/7bDhh98c/veTw7aduR9TLhJ6dLLo08tF0/onN4BlZmYyY8YMpkyZwvq91xBb83xsOyzXYw/sWcCy73tSqVZv2vaciu2KOOFxx5tFSvIMqtbL+f2wbbjuEpub+gZ21ruI+KdAKSJSwvzwww/ceeedbN26lQceeIDHHnuM6OjoIl/vcLrhj62Gvft8rZHlIqFxPYsaVcgxtvFkM8Zw6ZBsMjLzvu/KWVeQmvwDXfpuIDK6bqHv0bIxjP+/3MOqiJwcGmgiIlIEXq9vJxdjICoSwtzFD2bJyckMGzaMTz/9lB49evD111/TsmXLYl83OsqiXYuS0QW8Yw9+w6RxvOzbNZuYyh2KFCYB/tjmW5LIZZeM5ywSChQoRUQK6I+thh9+dViz0WFTEng8vq/bFtSpAfFNLHp2sukQb2EXIsx4PB7Gjx/P448/TlRUFB988AEDBw485a2Hp8KOPf47xbIz9+J4jhBZvkGR75GdDakHoGqlIl9CRApJgVJEJB9r/3CY8JGX9Zv/nsRyPMfAtp2QvNvw/TwvNarALVe76HGmlW8oXLBgAUOHDmXlypUMHTqUZ599lkqVym4Syvacmvt4TtF9RMRHC5uLiOQh22N44xMv94zykpDo+5q/NR6PPrZ7Lzz7mpcnXvFy4FDuLXKpqancdtttdOnSBZfLxcKFC5kwYUKZDpMA4fkMbQyLqILtLkdGWuJJvY+IBJYCpYhILrKyDP/3Xy+ffe9gDDiFWCz8aIScv8Jw1zMe9u77O1Q6jsM777xD8+bN+eSTTxg/fjwLFy7kjDPOCOwTKKHq1/LfYmvZLuJq9ORQyjIyDm8v0j2iIiGuYpFOFZEiUqAUEfkHYwyj3vCy5Hfjdw3H/DiOr7XygRc8HEk3rFmzhnPOOYfBgwdz/vnns2HDBu68805crtBZ4qZKJYjJZ8J6/TYjAMP6+UNxvFk5HnecbPYmTc/z/GYN8h9qICKBpTGUIiL/8P08wy9LA7OimteB7bsNN93/C9Pe6kmTJk2YNWsWvXr1Csj1SxvLsujczuKnBSbP4QMVq3WmWefxJCy4m8XTO1G7+e1Ex8ZjnGwOpa5gR8IkomPjqVL30lyuD53bKUyKnGpah1JE5Dip+w03jPCQken/uMJuCwjQoc4Unv2/a4iIiMjliqFj3SaHu57Jfx/vQ6krSVo7jn275pCVvgvbDiOqQlOq1L2EOi3uIDyyao5z3C74dKybiuUVKkVOJbVQiogc538/O2Tl7GU9wfHbAtZrNeyEbQGTN0zkwJ4FObYFtC2DO+46IiL0stuikUV8E9iw2f8kp5i4dsR3m1Tg69oWXNTdUpgUCQK1UIqI/MXjMfS/38OBQ3kfU5xtAQEm/9tNjaoKPEk7DbeM9ODJv6GyQGwLYivAO8+7KV9O31+RU02TckRE/vLHNuM3TAIkrh4NWLTo8mqOMAlgu8LzDJMWsGh1IaaLl2F1a1rccV0A34IseOR2l8KkSJAoUIqI/CUh0eAvjhR3W0Db5buH+Fx+rotBVxbvbciywLZh5BAXHeL1liYSLBrMIyLyl63J4HKRZzdscbcF9Hph0zYFyuPdcLmLqnEW4z7wku0p3Hqftg2xMb6WSYVJkeBSoBQR+UtGVvHWnSzQPfKZPR6KLjzbpn28xfgPvfy2zMHgYFl5r81pWb4tMC/sbnHr1ermFikJFChFRP7idllg5Z0oA7EtoFuvurmqXtnivusPMPapLlx787u4y5/B5qQT9/6OivAtWt6pncWFZ9tUjFGQFCkp9NImIvKXGlXx20J5dFvAlOQZZBzeTmR0nUJd37agTg2FoLx8+OGHZKQl8uyDTahWLQyv15Cy3zcEITwMKseiHXBESigNOhER+UuzBla+Y/iKtS2g5buH5GSM4a233uLyyy+nWrVqALhcFtUqW9SqZlGlkrZTFCnJ1EIpIvKXFo0s3G7wePI+pjjbAjoOtGuuUJSbxYsXs2bNGsaMGRPsUkSkCBQoRUT+Eh1lcW5nix9/y3ufaYDazW6mQpWOJK0dx9Y1Y07YFrB6o2uo0+KOHOdYFtSrCS0bK1Dm5q233qJevXr07t072KWISBEoUIqIHOfK81zM+MVPE+VfCrstoDHQ7wKXum1zkZaWxpQpUxg+fDguV96zu0Wk5NIYShGR4zStb3Flb5tA5j7bhpaN4YKzFSZz8+mnn3L48GFuuummYJciIkWkvbxFRP4hPdO3z/SfKfjt+i4Iy/LNUH7zabdmeOeha9euVKhQge+//z7YpYhIEamFUkTkH6IiLMY85KZijG8B7aKyLHC7YNR9LoXJPPz+++/Mnz+fW265JdiliEgxKFCKiOSiZlWL8f/npn5t/O7vnZej2wKOGeGivbYFzNOkSZOoUqUKffr0CXYpIlIM6vIWEfHD4zF88q3D+185eLwOxoBl5R0Qbdu3PNAF3SzuGOCifLRaJvOSmZlJnTp1uPHGG7VckEgpp0ApIlIA+w449OozmmoNb8RDtVyPqVQBene1uaynTe3qCpL5+eyzz+jfvz9r166lZcuWwS5HRIpBgVJEpADmz59P165d+emnnzjjzB5s3GbYd8D3WPly0KSeRVysQmRhXHDBBaSlpfHrr78GuxQRKSatQykiUgCTJ0+mdu3anHPOOdi2RfuWCo/+7NhjmLPYYcMWw8ZEw+F0317mlStBy0YW1WJT+enn+bz5xthglyoiAaBAKSKSj+zsbD755BMGDRqEbWuCjT+//+Hw3hcOS3832DZgwDmuH+xAGmzdYfB6YzmrfxL7TAT7DxpiKyigi5Rm6vIWEcnHN998w6WXXsry5cs57bTTgl1OiZSZZXh7msPUGc6xiUkFYdsQHQX33+jinDMV1kVKKwVKEZF8XHfddaxatYrVq1dr68RcpB02jHjJw4Ytvi0mC8sCDPCvy23+dYWt77FIKaSPgyIifqSlpfHVV18xcOBABZ1cZGb5wmRCYtHCJPjCJMD7Xzl8/E0xtyYSkaBQoBQR8ePLL7/kyJEjXHfddcEupUR693OHDVsK3sWdn0nTHH7/Q6FSpLRRl7eIiB8XXnghhw8fZt68ecEupcRZt8nh7me9+bZMpqWuYtvacezfPZesIzuxbDdRFZpSvWF/ajUdTFhE3LFjbRtqVIFJo9yEh6lFWKS00CxvEZE87N69m5kzZ/Lqq68Gu5QS6f2vHCzLf1d3csIkEhbcTbmKzajXahjRsS0xTjYHU5aSvGEiB/YsoG2vqceOdxzYsQdmLzKcf5YCpUhpoUApIpKHTz75BJfLxdVXXx3sUkqcXX8aFq3y3zR5YM8CEhbcRaVavWnbcyq2K+LYY3G1elMv/n5SkmfkOM+y4IuZXs4/S6OyREoL/bWKiORh8uTJXHTRRcTFxeV/cIj5ZZmvddKfxNWjAYsWXV49IUweZbvCqVrvshxfNwYSEuHPVI3IEiktFChFRHKxceNGFi1axPXXXx/sUkqkhC3Gb6A0jpd9u2YTU7kDkdF1i3aPRAVKkdJCgVJEJBeTJ08mJiaGSy+9NNillEgJicbvzO7szL04niNElm9QpOu7bNiUpEApUlooUIqI/IMxhsmTJ9O3b1+ioqKCXU6JdDj95F7fsuDISb6HiASOAqWIyD8sXryYP/74g4EDBwa7lBIrvy3NwyKqYLvLkZGWeNLuISIlh/5cRUT+4cMPP6RmzZr07Nkz2KWUWFXzmadk2S7iavTkUMoyMg5vL/T1vQ5UqVTE4kTklFOgFBE5jsfj4ZNPPmHAgAG4XK5gl1NitWxkk9+3p36bEYBh/fyhON6sHI87TjZ7k6bneq4x0KyB1qEUKS0UKEVEjvPjjz+yZ88edXfno1VTC6/X/zEVq3WmWefx7Nsxi8XTO7F9/evs2zWX1B2z2LrmJRZ+2Y4dG9/N9Vy3GxrXU6AUKS20sLmIyHEmT55MixYtaN++fbBLKdG6nmYRHZX/5JzazW6mQpWOJK0dx9Y1Y8hK34Vth/m2Xmx0DXVa3JHjHJcN53a2iIpQoBQpLRQoRSQkeTyGw+m+rtVyURAeZnH48GG++OILHnnkEaz8Vu0OceHhFpf2tPnse8fv8kEAMXHtiO82qcDX9jrQp5c60ERKEwVKEQkJxhg2bDHM+MWwZqPD1h0c67K1LahdHSLtZMIrdOLaAdcFt9hS4rpLbH74xWH/If/7eReGbcH5Z1m0aKRAKVKaWMYE6mVARKRkWrHO4dWPvGxK8nWnevNqUTMesNzUrAq39ndxzhkKNflZtMrhkf/kM5iygGwbYmPgnefclI9WC7FIaaJAKSJlVlaW4Y1PHL6c5WBb4BTw1c4CDNC9o8X9g1xUKK9wkxdjDNfc8ikp3quKdR3bhohwGPuYm8Z19f0WKW308VtEyqT0TMOIl7x89ZOvObKgYRJ8YRLgl2WGe0d5SD2gz925McZwzz338Nnb13Jm00XYdtEWI7ctqFRBYVKkNFOgFJEyx3EMT4zzsibBFGtsn+PA9t3w4IseMjIVKo9njOHBBx9k/PjxvPHGGzz/2Fm8/qSb+rV8jxckWLr+OuaCsy3efk5hUqQ0U5e3iJQ5n8/0MmFyPlOPC8Gy4KrzbO64Tgudgy9Mjhw5kueee45XXnmFu+6669hjXq/h12WGL350WLXB9/Zi275WSN/jvhbg8DA4r6tFn14umtRXkBQp7RQoRaRM2b3XcOPDHrI9/o9LS13FtrXj2L97LllHdmLZbt/aiA37U6vpYMIicu4t+MpIF/FN1LHz9NNP88QTTzBmzBiGDx+e53EH0gwbEw1/bDMcSfcFy8oVoWkDi0Z1LMLDFSRFygoFShEpU974xMvUGf7XRkxOmETCgrspV7EZtZsPITq2JcbJ5mDKUnYkvE35Sm1o22vqCee4bOja3uLJu0N7tbXRo0fzyCOPMGrUKB599NFglyMiJYQCpYiUGVlZhn73evzu3nJgzwKWfd+TSrV607bnVGxXxAmPO94sUpJnULXeZTnOtSyY8h83VSuFZsvayy+/zLBhw3j88cd56qmngl2OiJQg6rsRkTJj3WaT71aAiatHAxYturyaI0wC2K7wXMMk+BbvXromND+DT5gwgWHDhjFixAiefPLJYJcjIiWMAqWIlBkbthj87ZhoHC/7ds0mpnIHIqPrFvr6LhdsTAy9QDlx4kTuuusu7r//fp5//nltSykiOShQikiZsXWHOTabODfZmXtxPEeILN+gSNf3emHz9tAKlO+99x633347d955Jy+99JLCpIjkSoFSRMqMrOy/FyU/WdIzQidQfvzxxwwePJibb76ZcePGKUyKSJ4UKEWkzHDls0xkWEQVbHc5MtISi3yPsBCZ5D1t2jSuv/56rr/+et544w3somyBIyIhQ68QIlJm1Kxi4a8NzbJdxNXoyaGUZWQc3l7o67tsqFOj7LfS/e9//+Paa6/l6quv5u2331aYFJF86VVCRMqMZg0tvPlskFO/zQjAsH7+UBxvVo7HHSebvUnTcz3XMdCsQdkOlN9//z39+vWjT58+vP/++7jya/YVEQFCpPNGREJBfBMLl43fUFmxWmeadR5PwoK7WTy9E7Wb3050bDzGyeZQ6gp2JEwiOjaeKnUvzXGuMdC2Rdn9HD5r1iyuuOIKLrjgAqZMmUJYWFiwSxKRUkILm4tImfLsax7mLjb5tlQeSl1J0tpx7Ns1h6z0Xdh2GFEVmlKl7iXUaXEH4ZFVTzjeOF4yDq3hyq4/c9ttt1GxYsWT+CxOvblz53LhhRfSvXt3vvrqKyIicq7RKSKSFwVKESlT1v7hcPez3pNy7SrWW3wx+V4iIyO5/fbbuffee6lTp85JudepNH/+fM4//3zOPPNMpk+fTlRUVLBLEpFSpuz23YhISIpvYnPxOZbf9SgLy2VD+5YWH789hMTERO68804mTpxIw4YN+de//sWqVasCd7NTbPHixVx44YW0b9+er7/+WmFSRIpELZQiUuYcTjfc/JiH1P3+x1MWhG1BRARMGuWmeuW/U+qhQ4d46623ePnll0lKSuKCCy7gwQcfpFevXqVmvcYVK1bQs2dPWrZsyYwZM4iJiQl2SSJSSqmFUkTKnOgoizEPuYmJBtsq+mdm24KwMHhhuOuEMAkQExPD/fffz6ZNm/jwww/ZtWsXvXv35vTTT2fKlCl4PJ7iPo2Tas2aNfTu3ZsmTZrw3XffKUyKSLEoUIpImVSnhsWLD2SRefgPjCl8M6VtQeVYePkRF62a5v1SGRYWxsCBA1m+fDk//PADVapU4brrrqNJkyaMHTuWtLS0YjyL/KUdNiQmGzYlGXb9aXCc/AP0+vXrOffcc6lbty4zZswocxOMROTUU5e3iJRZt912Gx999ClP/3cD38+Pw3F8S//4Y9u+Yy7tYXH7NS6iIgvffb1ixQrGjBnDxx9/TExMDEOHDuWee+6hRo0aRXwmfzPGsDrB8O0ch5UbDHtSTnw8MgKa1rc45wyL886yKV/uxPo3btzIOeecQ1xcHLNnz6ZKlSrFrklERIFSRMqkadOm0a9fPyZOnMgtt9zC/oOG7+Y5fDfXIXl37udUqQTnn2VzaQ+b6lWKPw5y27ZtjB07ljfffJOsrCxuuOEGHnjgAVq0aFGk663a4PDf97xs3UG+621a+Lrr+15g868+NuHhFlu2bKF79+5ER0czZ84cqlevXrQnJiLyDwqUIlLmJCUl0a5dO3r16sVnn32WY5JM2hHDH1sNBw75dr+JiYYm9SxiK5ycyTT79+/njTfeYOzYsezcuZPLLruMBx98kG7duhVoAo/HY3jzU4dpPzjYNjiF6MG3LKhdHW698k9uuPYsXC4Xc+bMoXbt2sV4RiIiJ1KgFJEyxev1cu6557Jp0yZWrlxJXFxcsEs6JjMzk48++ogxY8awdu1aOnXqxAMPPMCVV16Z5xaH2R7DE694WbTK5NtdnxfbMng86excdRM//O+/1KtXrxjPQkQkJ03KEZEy5YUXXmDu3Ll8+OGHJSpMAkRERHDTTTexevVqpk+fTmRkJFdffTXNmzfn1Vdf5ciRIznOGTOpeGESwDEWlh1Bo05TsMLrFuMZiIjkToFSRMqMhQsX8vjjj/Poo49yzjnnBLucPNm2zSWXXMLs2bNZtGgRHTp04O6776Z+/fo8+eST/PnnnwDMWeTw4/zihcmjLMuFx2Mz+k0P3gLMBBcRKQx1eYtImXDo0CFOO+00qlatyrx58wgLCwt2SYWyefNmXn75ZSZNmoQxhn8NGsIO8zzpGS78vUinpa5i29px7N89l6wjO7FsN1EVmlK9YX9qNR1MWETOVtq7r7e5onfuXewiIkWhQCkiZcKNN97IF198wYoVK2jUqFGwyymylJQUXn31VSZ/fZBa8c9iWXl3JCUnTCJhwd2Uq9iM2s2HEB3bEuNkczBlKTsS3qZ8pTa07TU1x3nV4mDyGDd2IPenFJGQpkApIqXeRx99xMCBA/nggw+4/vrrg11OsRljuHFENsl7wLcAUE4H9ixg2fc9qVSrN217TsV2RZzwuOPNIiV5BlXrXZbr+c8Pc3FmW416EpHA0KuJiJRqW7ZsYejQoQwcOLBMhEmAvfsheY9FXmESIHH1aMCiRZdXc4RJANsVnmeYdLlgye9qSxCRwFGgFJFSy+PxMHDgQOLi4pgwYUKwywmYjYn+w55xvOzbNZuYyh2IjC78rG2vF9ZvLvx2lCIieXEHuwARkaJ65plnWLRoEfPmzStT+1Fv22n8LmCenbkXx3OEyPINin6PHUU+VUQkB7VQikipNG/ePJ599lmeeOIJunTpEuxyAior27fDzcmU7Tm51xeR0KJAKSKlzr59+xg4cCBnnXUWjz76aLDLCbgwN37XngyLqILtLkdGWmKR7+HWqkEiEkAKlCJSqhhjGDJkCAcPHuTDDz/Mc8vC0qxOdcvvft2W7SKuRk8OpSwj4/D2It2jbo0iFicikgsFShEpVd59910+/fRT3nzzzTK7J3WzBvn3d9dvMwIwrJ8/FMebleNxx8lmb9L0XM91uaBFY738i0jgaFKOiJQaCQkJ3H333QwePJj+/fsHu5yTplplqF4Fdu/N+5iK1TrTrPN4EhbczeLpnajd/HaiY+MxTjaHUlewI2ES0bHxVKl7aY5zvV5o31KLmotI4GhhcxEpFbKysujatSsHDx5k2bJllC9fPtglnVSffuflzU+dfPfxPpS6kqS149i3aw5Z6buw7TCiKjSlSt1LqNPiDsIjq+Y4J64ifPwfNy6XQqWIBIZaKEWkVPi///s/Vq1axfz588t8mAS48Gyb9790SM/0f1xMXDviu00q8HUtoO8FtsKkiASUBtGISIk3a9YsXnzxRUaNGsXpp58e7HJOiQrlLe66PrATjmwbGtSBfufrpV9EAktd3iJSou3du5d27drRsmVLfvjhB2w7dMKQMYb/G+tl4UqDU8xXasvyLRU04XE3jeupdVJEAkuBUkROrexs2JwA61bDgX2+BRdj46BFa2jcHMLCjh1qjOHKK6/kl19+YdWqVdSqVSuIhQdHRqZhxBgPa/+gyKHSsnwzu0fd56Jj69AJ5CJy6ihQisipsXYlfPIufPcFZP01MPDoGpJer+9/wyPgoiug/yBodRqvv/46Q4cO5auvvqJPnz5BKLpkyMwyvPyel5m/GizL/6Ln/2RbUKki/N8dLto0U5gUkZNDgVJETq7UvfD8ozDzf+BygzefPf9cLvB6OXBmd1p/9D/63HgTEyZMODW1lnC/LXcY+76XvfvAwsH4GQZvW4AFF3e3uO0aF9FR6uYWkZNHgVJETp6l8+H+wXD40N+tkAXkMXAYi8hXPyLirB4np75SyOs1LFxl+L8X5kN4K7CjT3jctqBOTejZyebi7jZVKilIisjJp0ApIifH4l/hjgG+IOlvH0E/jGVhud0wfjJ0OjvABZZeGRkZVKpUiWeeeZbrbxzGn/sMXi+Ui7KoXwsiwhUiReTUUqAUkcBLToK+5/jGShYxTB5j2RARAdNmQ+2yudViYc2aNYvevXuzcuVK2rZtG+xyRES0DqWIBJgx8Pi9kJ1V/DAJYBzftR6/NzDXKwNmzpxJ9erVadOmTbBLEREBFChFJNB++J9v7GQuYybfTT2CtXIXkat2sTUr5+M9/kih9YZcNrD2emHpAvjh65NRcakzc+ZMevfujWWpa1tESgYFShEJrI8m+rZk8SPTwMhdhwp3XduGj94qRmFlw969e1m+fDnnnXdesEsRETlGgVJEAifxD1i5JN+u6QtjwvloXwYr07MLfm3HgVVLYcvGYhZZus2aNQtjDL179w52KSIixyhQikjgrFhcoMMeqhZNZbfNiJ2FbKUsxD3KqpkzZxIfH0/t2rWDXYqIyDEKlCISOGtXgdud72Exts3IatHMOJTFT4cyC359t9u3406IMsYwc+ZMdXeLSImjQCkigbN7B3jy2QnnL0Mql6NRuIsROw9R4NXLPB7YmVyMAku3jRs3sm3bNgVKESlxFChFJHA8BR8TGW5bPFujPEvSPXy6P6MQ9yhYYC2LZs6cSVhYGOecc06wSxEROYECpYgETnRMvjO8j3dtbCQdotw8tiuN7IK0Uto2lI8pRoGl28yZM+nSpQvly5cPdikiIidQoBSRwGnaAgqxNqJlWbxQM4ZNWV7eTDlSkBOgactiFFh6eTwefv75Z3V3i0iJpEApIoHTsm2uC5r70zsmgvPKh/P07sOkOfm0Unq9vnuEoEWLFnHw4EEFShEpkRQoRSRwTu8C5aILfdoLNWP40+OwND2f8ZHlouGMrkUsrnSbOXMmsbGxdOzYMdiliIjkoEApIoETVQ6uGgguV6FOa18ujAGxkf4Pcrngyut89whBM2fOpFevXrgK+b0VETkVLFPg9TpERApg53a44mzILMTM7YKIiITP50LtuoG9bilw8OBB4uLiGD9+PEOGDAl2OSIiOaiFUkQCq2YdGP5k4K97/+MhGSYBZs+ejdfr1fhJESmxFChFJPD63QA9LyzUEkJ5sm3ocQH0v7H41yqlZs6cScOGDWncuHGwSxERyZUCpYgEnm3DC6/DWb0KtYxQDpYFXXv6rhWIcFpKabtFESnpQvcVWkROrvAI+M/bcPtwsF2Fm6jjcvnOuX04vPyOb/xkiEpKSmLDhg0KlCJSoilQisjJExYGQ4bDlBnQ+Rxfi6Ptyr210bZ9j1kWdDobPvred25Y2KmvuwSZOXMmlmXRq1evYJciIpInzfIWkVMneRt8+zmsWQFrlpOxdzdulxt3pcrQuj20Pg0uuhLq1A92pSXGgAED2LRpE4sWLQp2KSIieVKgFJGgqVy5Mg899BAjRowIdiklkuM4VK9endtuu41Ro0YFuxwRkTypy1tEgsbj8RAW4l3a/qxcuZK9e/dy/vnnB7sUERG/FChFJGiys7Nxu93BLqPEmjlzJtHR0XTp0iXYpYiI+KVAKSJBk52drRZKP2bOnMk555xDeHh4sEsREfFLgVJEgsIYg8fjUQtlHtLT05k3b56WCxKRUkGBUkSCwuv1AqiFMg/z5s0jMzNTgVJESgUFShEJCo/HAyhQ5mXmzJnUqlWL+Pj4YJciIpIvBUoRCYrs7GwAdXnnYebMmfTu3RurOFtXioicIgqUIhIUaqHM2+7du1m5cqW6u0Wk1FDTgIgEhVoowes1bNsJf2w1HDpisIDYChbrVy0ELHr37h3sEkVECiR0X8lFJKhCuYVywxaHr2Y5/LzQkOXL1Rzt2fbtXXYRPQbu5fOfKnJZL0PdGur2FpGSTYFSRIIiFFsoU/cbXn7Py2/LDS4bvM7fj/1zE1zbHcOXPzpM+8Hhsp4Wt1/jIipSwVJESiaNoRSRoAi1FsolaxwGPeJhwUpfcjw+TObl6DHfzDbc9IiHTUnG/wkiIkGiQCkiQRFKLZQLVjg8+h8vRzLAKUCQ/CfHQMoBuHeUh41bFSpFpORRoBSRoDgaKMt6C2VisuGJ8V4cJ2e3dmE4DmRmwYh/ezhwSKFSREoWBUoRCYqjXd5luYXS6zWMftODcSAQEdBx4NAReOVDbwCuJiISOGX3lVxESrRQaKH8bp5h49b8j0tLXcW2tePYv3suWUd2Ytluoio0pXrD/tRqOpiwiLhjxzoO/LzQcEkPh/Yt1SYgIiWDAqWIBEVZb6E0xjBthhcL/62TyQmTSFhwN+UqNqNeq2FEx7bEONkcTFlK8oaJHNizgLa9pp5wjsuGL2YqUIpIyVE2X8lFpMQr6y2U6zf7Fi3358CeBSQsuItKtXrTtudUbFfEscfiavWmXvz9pCTPyHGe14HflhtSDxjiKmopIREJPn28FZGgKOvLBq1OMNj5ZL3E1aMBixZdXj0hTB5lu8KpWu+yXM81BtZt0uQcESkZFChFJCjK+rJBCYkG/ARK43jZt2s2MZU7EBldt9DXd9l/3UNEpARQoBSRoCjrLZQ7/zR+15zMztyL4zlCZPkGRbq+AfakKFCKSMmgQCkiQVHWWyg9J3tlHwNerR4kIiWEAqWIBEVZb6GMzmff7bCIKtjucmSkJRbp+paN9vYWkRJDgVJEgqIst1B6PB6iw3djkXcTomW7iKvRk0Mpy8g4vL3Q93AcaFinOFWKiASOAqWIBEVZaqE0xrBmzRrGjh3L5ZdfTuXKlXnr1REYXH7Pq99mBGBYP38ojjcrx+OOk83epOl53BOaNlALpYiUDGWvaUBESoXS3EJpjGHLli3MmjWLn376iZ9++ok9e/YQHh5O165defDBB+nU5Xz+Pdm3ZmReKlbrTLPO40lYcDeLp3eidvPbiY6NxzjZHEpdwY6ESUTHxlOl7qU5zo2tAM0VKEWkhLCMMZomKCInXbbHsHi1Yd0mQ0KiIWFTCjt37qJrp1Y0bWDRvKFF53YW5aJKZkjauXPnsfA4a9Ystm7dim3bnHHGGfTq1Ytzzz2Xrl27EhUVdeyc5173MHuR8RsqAQ6lriRp7Tj27ZpDVvoubDuMqApNqVL3Euq0uIPwyKonHG9bcMPlNv+6wn8LqIjIqaJAKSIn1aHDhk+/c/jfzw6HDvvWT3ScE7cjdLl8M5YjwuGCbjYDLrGpVjm4wXLfvn3Mnj37WIBct24dAK1bt+bcc8/l3HPPpXv37lSsWDHPa2xKMgx5wuN3+aDCsiyIioD3X3RTqULJDN8iEnoUKEXkpFmwwuHfb3s5mEaBQ5XLhrAwuPM6Fxd1t7CsUxOaDh8+zC+//HKsG3vZsmUYY2jcuPGxFsgePXpQvXr1Ql333S+8fPi1QyBfaR+5zUXvrhoCLyIlhwKliAScMYYPv3Z49wsHy6LIYer8syweGOzC5Qp8qMzKymLhwoXHAuSCBQvIzs6mRo0ax1oge/XqRf369Yt1n2yPYfhoD+s2FzxU58Wy4NzOFg/f5jplQVtEpCAUKEUk4Cb/z8vb04rfz2sB53ezePDm4gcor9fLihUrjgXIefPmceTIEWJjY+nZs+exANmiRYuAh7W0I4aHX/KwYTM4xXjF7d7R4rEhLtxuhUkRKVkUKEUkoFaudxg2OrBbuDx4s4sLzy5cF68xhvXr1x8LkLNnz2bfvn2UK1eOs88++1iAPO2003C5Tv7kloxMw8RPHb6c5WBbhQiWxovL7eLGK2yuvcTGZStMikjJo0ApIgGTnmkY/KiHvan+A1Na6iq2rR3H/t1zyTqyE8t2E1WhKdUb9qdW08GERcSdcHxkBLz7vJuqcf7D1NatW09Yymfnzp2EhYXRuXPnYwGyU6dOhIeHB+LpFsnK9Q5vfeZl7SbfeNHcZoBblu+f4xhSkmcw9qm2nNO1eF3vIiInkwKliATMlz96eeVD/13dyQmTSFhwN+UqNqN28yFEx7bEONkcTFnKjoS3KV+pDW17TT3hHJcNl59rc+fAE1sSd+/ezc8//3xsJvbmzZuxLIsOHTocC5DdunUjOjo64M+1uDYlGX5e4LBus+GPrYbD6b4u/pjy0LyhRXxji24dsuh6ZiMuueQS3nrrrWCXLCKSJwVKEQkIYwyDHvGwfVfexxzYs4Bl3/ekUq3etO05FdsVccLjjjeLlOQZVK13WY5zoyJg0jNHWLhgzrFWyDVr1gDQsmXLYwGyR48eVKpUKaDP7VQwxuQ6dvOll17i4YcfZtOmTdSrVy8IlYmI5E+BUkQCYlOS4bb/8/g9ZuWsK0hN/oEufTcQGV230PdYM+da9iR+Tv369Y8FyF69elGzZs2ill3ipaWl0aBBA6699lrGjx8f7HJERHKlQCkiAfHdXIcxb+c9Gcc4XuZMqUz52NZ0vOSXwt/AeGhZZy3Dbq5Ew4YNQ2rZnFGjRvHMM8+wZcuWMh2eRaT00sq4IhIQf2w1+JssnZ25F8dzhMjyDYp2A8tNdKV2NGrUKKTCJMCdd95JREQEL730UrBLERHJlQKliARE2hET0N1gcnPgUGh2qMTGxnL33Xfz+uuvs3fv3mCXIyKSgwKliAREfo2GYRFVsN3lyEhLPGn3KMvuu+8+jDGMHTs22KWIiOSgQCkiAVGpguU38Fm2i7gaPTmUsoyMw9sLfX3LgsqxoZsoq1SpwtChQxk3bhz79+8PdjkiIidQoBSRgGjawMKbzwY59duMAAzr5w/F8WbleNxxstmbND3Xcy3Ltz5jKBs+fDiZmZlMmDAh2KWIiJxAgVJEAqJl4/zDXsVqnWnWeTz7dsxi8fRObF//Ovt2zSV1xyy2rnmJhV+2Y8fGd3M913EKdo+yrGbNmtxyyy28/PLLpKWlBbscEZFjtGyQiATMPaOyWbfJF/78OZS6kqS149i3aw5Z6buw7TCiKjSlSt1LqNPiDsIjq+Y4J64ifPwfNy5XaIfKbdu20bhxY0aPHs3w4cODXY6ICKBAKSIB9PNCh2dfy6ffuwhsC2680ub6Pn7WJQohN998M99++y1btmwhMjIy2OWIiKjLW0QCp/sZFi0b+/beDhTbgsqx0Pd8vVwd9fDDD7Nnzx7efvvtYJciIgKohVJEAixpl+HWkR48XgK2LuWYh1y0j1egPN7AgQP55Zdf2LhxI+Hh4cEuR0RCnF6hRSSg6tawGDnU1zUdiHUjh1xrK0zm4tFHH2Xbtm18+OGHwS5FREQtlCJycvyy1Dee0uvkP0nnn2zb17o5dIBN3/M1bjIvV111FatXr2bdunW43e5glyMiIUyBUkROmuTdhhcmevj9D8B4wfIfDi3LFyRrV4dHb3fRopFaJv1ZunQpHTt25KOPPmLAgAHBLkdEQpgCpYicVI5j+N+sfTz90nJia3QH/jFpx+LYguiN6sKVvV307mIRHh7aywMV1MUXX8y2bdtYtWoVtq0ALiLBoT4SETmpbNsiYcUkfp/9f6xeu4udKRVI2GrYf9BgDMREWzSpZ9G8oUWdGmCF8obdRTBy5EjOOussvvrqK6688spglyMiIUotlCJyUhljiI+P57TTTmPKlCnBLqdM6tWrFwcOHGDJkiUK5CISFOofEZGTauHChaxfv56bbrop2KWUWSNHjmTZsmV8//33wS5FREKUWihF5KS6/fbb+fbbb0lMTMTl0oztk8EYQ9euXbFtm19++UWtlCJyyqmFUkROmiNHjvDxxx9z4403KkyeRJZlMXLkSH777TfmzJkT7HJEJASphVJETprJkydz/fXXs3HjRpo0aRLscso0YwwdOnSgcuXK/Pjjj8EuR0RCjAKliJw05557Lh6PR61mp8i0adPo168fv/32G126dAl2OSISQhQoReSkSExMpGHDhrzzzjsMGjQo2OWEBMdxaN26NY0aNWL69OnBLkdEQojGUIrISfHee+8RHR1Nv379gl1KyLBtm8cee4xvvvmG5cuXB7scEQkhaqEUkYBzHIfGjRvTs2dP3n777WCXE1I8Hg/Nmzenffv2TJ06NdjliEiIUAuliATcnDlzSExM1NqTQeB2u3nkkUf4/PPPWbt2bbDLEZEQoRZKEQm4G264gQULFpCQkKA1EYMgKyuLxo0b06NHD0a98D7zljis32LYuNVwJB1sG6pUghaNLFo1sTnnDItyUfo5iUjRKVCKSEAdOHCAmjVrMnLkSB599NFglxOynnx+Gl/PqUilGudg24AB5x+v9i4bvA5EhMOFZ9v863Kb2AoKliJSeAqUIhJQEydOZMiQIWzdupU6deoEu5yQk55hePNTL1//ZDCOB8t2F+g824boKLh/kItzztBoKBEpHAVKEQmorl27UqFCBe0rHQQH0gwPvuBhy/acrZEFYQEGuPFKm39drp2NRKTgCvbRVUSkANavX8/8+fP5+OOPg11KyEnPNDz0ooctyUULk+ALkwDvfeEQEQbXXKxQKSIFo34NEQmYd955h0qVKnH55ZcHu5SQ89anDpuSwHECc72Jnzms3xygi4lImacWShEJCI/Hw/vvv891111HZGRksMsJKas2OHw5K//wl5a6im1rx7F/91yyjuzEst1EVWhK9Yb9qdV0MGERcceOtSx4/k0vbz1rEebWRB0R8U+BUkQCYsaMGezatUtrTwbB+1862Lb/1snkhEkkLLibchWbUa/VMKJjW2KcbA6mLCV5w0QO7FlA215/L4TuOLB9F8xbYujVWYFSRPzTpBwRCYh+/fqRkJDAypUrtfbkKZS0yzDoYY/fYw7sWcCy73tSqVZv2vaciu2KOOFxx5tFSvIMqta77ISv2za0aAiv/F9YwOsWkbJFYyhFpNj27t3L119/zU033aQweYr9stTXOulP4urRgEWLLq/mCJMAtis8R5gEXyvl2k2QekDtDiLinwKliBTb5MmTMcZw/fXXB7uUkLNhi/l7enYujONl367ZxFTuQGR03SLdY2OiAqWI+KdAKSLF9s4773DZZZdRtWrVYJcScjYmGr/LBGVn7sXxHCGyfIMiXd+2YXOSAqWI+KdAKSLFsnz5clauXKnJOEFyJOPkXt+24PBJvoeIlH4KlCJSLO+88w7Vq1fnoosuCnYpISm/8ZNhEVWw3eXISEss8j1cGhYrIvlQoBSRIsvMzGTy5Mn861//wu3WKmTBULWS/8ct20VcjZ4cSllGxuHthb6+1wtV8rmHiIgCpYgU2ddff01qaqq6u4OoZWMbVz47JNZvMwIwrJ8/FMebleNxx8lmb9L0XM81QNMGaqIUEf+0DqWIFNnFF19MamoqCxYsCHYpIevH3xyef9Ob73F/L2zenNrNbyc6Nh7jZHModQU7EiYRHRt/wsLmR4WHwVcT3ISHK1SKSN7URyUiRZKcnMyMGTN49dVXg11KSOt2ukVUJKTnM3GmdrObqVClI0lrx7F1zRiy0ndh22G+rRcbXUOdFnfkOMdlwwXdbIVJEcmXAqWIFMkHH3xAeHg41157bbBLCWmRERaXnGPz+UzH79aLADFx7YjvNqnA1/Y6cFkvjYwSkfzplUJECs0Yw9tvv03fvn2pWLFisMsJedf3sakQDYHcpMi2oE8vi8Z11TopIvlToBSRQvvtt9/YuHGjJuOUEDHRFg/c7CJQI+JtGyrHwm3985ntIyLyFwVKESm0d955h/r169OzZ89glyJ/6XKazW39i/+SbttQLhJeeNBNVKRaJ0WkYBQoRaRQDh8+zCeffMKNN96Ind+q2nJKXXOxi7sG2th2/gue58ayfC2T40a6qV9LYVJECk7vBiJSKNOmTSMtLY1BgwYFuxTJxZXnuXjtCTf1avr+uyDB0vXXMX16WrzznMKkiBSe1qEUkULp0aMHtm3z008/BbsU8cPrNfy23PDFjw4r1/te5m0LrL/Co9djwLKICIcLz7bp08umQW0FSREpGgVKESmwzZs307hxY95//31uuOGGYJcjBXQwzbBxq2HTNsORDF+r5aL53zP1o+fZ+sccIsI1+UZEikfrUIrIMfsOGlatNyQkGrbvNmRlQ0QY1Klh0bSBxfdffkpMTAx9+/YNdqlSCBXKW5zeyuL0Vn9/rXqkmwkv/Mr2pEQaN24cvOJEpExQoBQR1m1ymDrDYd4Sg9cBlwscr28fZwuwXQavF4xzLz36dmfbrkhaNAp21VIc7du3B2D58uUKlCJSbJqUIxLC0jMM4z7wcNcz3mNhEvCFx7+OMX/9N4Blu0nndO582surH3nJyNSImdKqWrVq1KpVi+XLlwe7FBEpAzSGUiRE7U4xPPCCh11/glOEVwHLgjrV4d8j3FStpMkcpdEll1yCMYZvv/022KWISCmnFkqREJSy33DvKA+79xYtTAIYAzv2wH2jPKQe0OfS0qh9+/ZqoRSRgFCgFAkxjmN45lUvqfs51sVdVF4H/kyF5173os6O0qd9+/bs2rWLXbt2BbsUESnlFChFQsz/fnZYnWCKHSaP8jqwfJ3h2zkKlKXN8RNzRESKQ7O8RUJIZpbhrc8KliTTUlexbe049u+eS9aRnVi2m6gKTanesD+1mg4mLCLuhOMnfublvLMswsM0nrK0aNiwIRUrVmT58uVcdNFFwS5HREoxBUqREPLzQt/C1vlJTphEwoK7KVexGfVaDSM6tiXGyeZgylKSN0zkwJ4FtO019YRzDh2GeUsM53ZRoCwtLMvitNNOUwuliBSbAqVICJnxi4Nl+SbU5OXAngUkLLiLSrV607bnVGxXxLHH4mr1pl78/aQkz8hxnmXBD784nNtFI2lKk/bt2/O///0v2GWISCmnV36REOE4hg1bjN8wCZC4ejRg0aLLqyeEyaNsVzhV612W4+vGwLrNRpNzSpn27duzadMmDhw4EOxSRKQUU6AUCRE7/4TMLP/HGMfLvl2ziancgcjouoW+x+F02JNaxAIlKI5OzFm5cmWQKxGR0kyBUiREHDiUf8thduZeHM8RIss3KMZ9inyqBEGLFi2IiIjQOEoRKRYFSpEQoY5oyU1YWBht2rRRoBSRYlGgFAkRFcvnP/s6LKIKtrscGWmJxbhPkU+VIGnfvj0rVqwIdhkiUoopUIqEiFrVICLc/zGW7SKuRk8OpSwj4/D2Qt+jXCRUq1zEAiVo2rdvz++//05mZmawSxGRUkqBUiRE2LZF84YWVj4NlfXbjAAM6+cPxfHmnMXjONnsTZqe8/oWtGhkYeV3Aylx2rdvj8fj4ffffw92KSJSSilQioSQ88+y8102qGK1zjTrPJ59O2axeHontq9/nX275pK6YxZb17zEwi/bsWPjuznOcwyc300vKaVR27ZtsW1b4yhFpMi0sLlICOnZyWLCR5CeYYC8WxJrN7uZClU6krR2HFvXjCErfRe2HebberHRNdRpccc/zjCUL2dxTke1TpZG5cqVo3nz5gqUIlJkCpQiIeRwWirhR6aTbl+X77Exce2I7zapgFe28Ka+RUrKFdSsWbN4RUpQtG/fXoFSRIpM/VMiIWLatGnEx8fz8//up2qFP3EF6K/fZUPNuD9Z/POTxMfH884772i3nFKoffv2rFy5Eq/XG+xSRKQUUqAUKeN2795Nv3796NevH127dmXt2t955amaVKoIdjFfAVw2VK4EYx+vydq1a+nTpw+DBw/mggsuYMuWLYF5AnJKnHbaaRw+fJg//vgj2KWISCmkQClSRhlj+PDDD4mPj2fu3Ll88sknfP7559SsWZOqlSzGPuqmWpxvdnZR2BZUrwL/fdRN5ViLypUr89577/Hdd9+xYcMGWrduzbhx49TiVUoc3YJR3d4iUhQKlCJlUFJSEpdeeik33HADF154IWvXrqV///4nLOlTo6rFxGfcXHyO72sF7QI/etxlPS3efNpN9conJtILL7yQNWvWMHjwYO69917OPvts1q5dG5DnJSdP5cqVqVu3rgKliBSJAqVIGWKM4c0336RVq1asWLGCr7/+msmTJ1OlSpVcjy8XZXH/IDf/fdRFl/Z/r1Hpcp143NH/tm04q4PFuJEu7vmXm6jI3Js3Y2JieOWVV5g3bx6pqam0b9+eZ599lqysnOtaSsmhiTkiUlSW0eh5kTJh8+bN3HLLLfz888/ccsst/Pvf/yY2NrZQ19i7z7BqgyEh0bB9lyEjCyLDoW4Ni6YNLNq1sKgcW7g+8oyMDJ5++mlefPFFWrVqxaRJk+jYsWOhriGnxpNPPsmECRPYs2ePFqgXkUJRoBQp5bxeL6+88gqPPfYY1apVY+LEifTu3TvYZeWwfPlyBg8ezKpVqxg+fDhPPvkk5cqVC3ZZcpyvvvqKK664gqSkJOrUqRPsckSkFFGXt0gptm7dOs4++2yGDRvGzTffzOrVq0tkmARfd+qiRYsYNWoU48aNo127dsyZMyfYZclxNDFHRIpKgVKkFMrOzub555/ntNNOIyUlhblz5zJu3DjKly8f7NL8CgsL4+GHH2blypXUqFGDHj16MGTIEA4cOBDs0gSoW7cucXFxCpQiUmgKlCKlzIoVK+jUqRMjR47k/vvvZ8WKFXTr1i3YZRVK8+bNmTNnDhMmTGDy5Mm0atWKb775JthlhTzLsjQxR0SKRIFSpJTIzMzk//7v/zjjjDPweDwsXLiQ0aNHExUVFezSisS2be644w5+//132rRpw6WXXsrAgQP5888/g11aSFOgFJGiUKAUKQUWLlxIhw4deOGFFxg5ciRLliwpMzOl69Wrx7fffsv777/P999/T3x8PFOmTNH2jUHSvn17tm7dSmpqarBLEZFSRIFSpAQ7cuQIDzzwAF27dqVcuXIsXbqUJ554gvDw8GCXFlCWZXHDDTewdu1aevXqxXXXXUefPn3Yvn17sEsLOUcn5qxYsSK4hYhIqaJlg0RKqDlz5nDLLbewfft2nn76ae6//37cbnewyzolvvzyS+644w7S0tL497//za233opd3I3HJV/7DhpmzffyzAufUrfJ+WBXxBgoXw6aNbBo0ciix5k2tatrjUoROZECpUgJc+jQIUaMGMFrr71Gt27dmDRpEs2aNQt2Wafc/v37efDBB3nrrbfo0aMHEydOpEmTJsEuq0za+afhnWleZi8yOAYcx4NlnfjhxbYACxwHOrayuKmvTYtGCvki4qNAKVKCzJgxg9tuu42UlBRGjx7NHXfcEfItc7NmzeK2225jx44dPPPMM9x3330h01J7shlj+N/PDq9NcfB6wesU7DzbBmPgmotsbrzSJjxMLZYioU6BUqQE2LdvH8OGDePdd9/lvPPO480336RBgwbBLqvEOHz4MI8//jj//e9/6dChA5MmTaJt27bBLqtUcxzDy+96+XZu0d8CLAvaNLN47n5Xnvu6i0hoCO2mD5ES4IsvviA+Pp4vvviCSZMmMWPGDIXJf4iOjuall17it99+Iz09ndNPP53HH3+czMzMYJdWao2fXLwwCb5WyjUbDY/914vHo7YJkVCmQCkSJHv27OGaa67hqquu4owzzmDt2rUMHjwYy1JLT146derEsmXLeOyxxxg9ejTt27dn/vz5wS6r1Pl1mcNXswITAB0HVq03fPJtAfvLRaRMUpe3yClmjGHKlCncc889WJbFuHHjuPbaaxUkC2n16tXcfPPNLFmyhHvuuYdnn322xG89WRIcOmz41wgPhw77Whjzkpa6im1rx7F/91yyjuzEst1EVWhK9Yb9qdV0MGERcScc77LhzWfcNKit32ORUKQWShE/PMawLcvDxoxstmZ6yC7m56/k5GQuv/xyBg4cyHnnncfatWsZMGCAwmQRtGnThvnz5zNmzBjefPNN2rRpw8yZM4NdVon37Rwn3zCZnDCJxdM7cyhlCfVaDaPdedNp0/MzqjXoS/KGiaz79bZcz5sy3XuSqhaRkk4tlCL/sDPLw0eph/n5UDrrMrLJPu4vJMyC5hFh9KgQyXVx5akTXrDZxsYYJk2axAMPPEBUVBSvvfYaV1xxxcl5AiFo06ZN3Hrrrfz8888MHjyYMWPGUKlSpUJfZ9efhg2Jhs3bDGlHwLIhriI0rW/RrKFFxfKlO/g7juG6Bzz86WcTnAN7FrDs+55UqtWbtj2nYrsiTryGN4uU5BlUrXdZjnNdLvjsv24qxgTm++R1DFlZgAURYWDbpfv7L1KWKVCK/OXPbC9P7tjH9APpWIC/EWE2YIALK0TxVO1K1Ahz5Xnsli1buO222/jxxx+56aabeOmll4oUdsS/o6F9+PDhlCtXjldffZUrr7wy3/Oysg2zFxk+/8HLxq2+r7lccDS6+NZl9M1o7nqaxeW9bTrEW6WyVXnjVsOQJzx+j1k56wpSk3+gS98NREbXLfQ9HrrFxQXditb5ZYxh7SbDrPmGtX84bEkGz1/lhodB43rQqonN+WfZNK5X+r7/ImWZAqUI8O2BIzyYlMoRx1CYTjsXEGlbjK5dicsrRZ/wmOM4TJgwgUceeYTKlSszceJEzj///IDWLTklJydzxx138PXXX9OvXz9eeeUVatSokeux6zc7PP+ml+27fIExv1dDl+1bq7HzaRbDBrmoHFu6Qs03sx3+827ev+HG8TJnSmXKx7am4yW/FPr6Lhf06Wlz1/V5f8DKy8JVDhM/8bIl+e/vc673+OuxFo1g6AAXrZtq5JZISaC/RAl5H6SkMWRrCmmFDJMAXuCIY7g7KZW3/jx07OsJCQmcc8453HPPPQwaNIg1a9YoTJ4itWvX5ssvv+STTz5hzpw5xMfH89577/HPz87TZni56xkvO/b4/rsgH62PhpxFqwyDHvawcn3pmtm8Ocng9pP1sjP34niOEFm+QZGu7/XCxq2F+54cSTe8+JaHR//jJXHHX9fxc4mjjyVsgXtHeXltipesbLWLiASbAqWEtOn7j/BY8j7A14VdFEfPe3rnfqbuPciLL75I27Zt2bVrF3PmzGH8+PHExMQEpF4pGMuy6N+/P+vWreOSSy5h0KBBXHjhhSQmJgLwybdeXp3iYP7qzi4sx4GMTHhojLdUhcojGaZAwbk4DqcX/NiDaYb7n/cw81dfUYWpzfnr2Gk/ODz6Hy8ZmQqVIsGkQCkha3e2l4e2pxK4TkvDsM27Gfnfcdxzzz2sWrWK7t27B+zqUniVK1fmgw8+4JtvvmHdunW0bt2akc9+yZufFj8EOgYcL4z8r5eU/SU7zBw4cIAVK1aQlLQVx8m7HT4sogq2uxwZaYlFvpergL3dWdmGh1/ysHn73+GwKIyBlesNT4334hTnQiJSLNoQV0LW/yXvI90xflsmM1ct49D7b5K5fDHO/v3YFWOJaN+RmH/dRkS70/9xtAVhbi765mdebN/0ZJYuhXTxxRezZs0aHnr4KWavPp3wSC+WVfhxfv/kGMjIgpfe8TLqPlfQJuqkp6eTmJjIli1bjv07/r/37fO1wjds9zj1247AtnN/7pbtIq5GT1KSZ5BxeDuR0XUKVYdtQfXKBfsefPCVQ0Ji4Vol8+IYWLTa8PVPDlf0Lv7PVUQKT5NyJCRtzfTQfcNOv2Hy0EfvsP/fTxHe+jTK978BV606eHcmk/bJ+2StWUHsQ08SM2BQruf+1KwGTSLDTkrtUnSTpnqZ8o0XY/yHnsIu6g3w4oMuTm91cjp9srOzSUpKOiEwHh8cd+3adezYsLAw6tWrR8OGDU/416BBA1LTm/HSe/6HX5y4bNA0bFf4CY87TjapyTOoUvfSHOfaNgy6wmZgH/+h7o+thiFPevINk4X9OYSFwXvPu6lepXRNlhIpC9RCKSHpo9Q0bMhzEk7m8sXs//dTRHbrSZWXJ2K5//5TKXdhH/befyv7X3yS8BatiGh/xgnnuoAPU9N4spaWBipJsrIN//vZyTdMJidMImHB3ZSr2Ix6rYYRHdsS42RzMGUpyRsmcmDPAtr2mnrCOS4bvvzRKXKgdByHHTt25GhZPPpv+/btOH8N9rQsizp16tCwYUOaNWvGBRdccEJwrFWrFq48+p1TDxis9/0HuYrVOtOs83gSFtzN4umdqN38dqJj4zFONodSV7AjYRLRsfG5BkrHgfim+Ye5T7/zYlvgzWdx9cL+HLxe38/h9mvVSilyqqmFUkLSuRt2sjEz7/X4/rxrEBm/zaHmd7/hrl4zx+OeXTvYefFZRJ7Vg6qvvJPj8frhLua1qBXQmqV4flnq8MQr/ufxF2dRb8uCaeNyX9TbGMPevXvz7JLeunUrWVlZx46vVq1ajtbFo/+/Xr16hIeH57hHQf3fWA8LVxq/M6kBDqWuJGntOPbtmkNW+i5sO4yoCk2pUvcS6rS4g/DIqjnOqV4FPnzR7XcB8v0HDf3v9+D186Mozs8hOgo+G+smIlytlCKnklooJeRkOIbNfsKk8XrJXDyf8Pi2uYZJAHeNWoS3bEPmot8wXi/WP1qEtmV5SfM6lHdp3ltJsXaTweXCb5BJXD0asGjR5dUcIQbAdoXnGmLANxbwu582EWnW5Notffjw4WPHxsbGHguJl1122QnhsX79+kRHR+d6j0C4orfNb8vzXyArJq4d8d0mFfi6lgVXnWfnu5vN0t+N358BFO/ncDjd97Nu31KBUuRUUqCUkLM1y+N3vUlnfyomIx13bf+7hLhq1yVrzQqc/ftwVa5ywmMG2JzpoW25orckSWBt2OI/yBjHy75ds4mp3KFIO8Q4jodHHn+bxFXPExUVdSwg9uzZ84QWxoYNGxIbG1v0J1JMHeItzupgMX+FKdKSSbmxbahdHfr0yv8DVEKi/2Bf3J+DbcHGREP7loU+VUSKQYFSQk5GoJYWOTpaJI+ZvZkaTVKi/Jnq/+dR3EW9bQtOO70n/S/0Ur58eVwu36xvy7Lwer1s2rSJLVu2HPuabds5/n9uXzsZj3doGM7SNWeSme3Od0xp/nxrWw44P5nELdn51rR+UyxebxjksWBXcX8OlgVbtutvT+RUU6CUkBORz/unHRuHFRmFJznJ73HeHduxosphV4zN9XEN4SpZTna+N8awdWsS87/17cpjjMFxnBz/P7ev5fb4yVahyhm0v2Amth2OZRftrcAYXxPn73MHceG7HxfonNMvnkfFqp2KdL+CcIxv0XkRObUUKCXk1A13Y5H3zjiWy0XEGV3I+G0Ont07c5+Us3snWetWE9mtZ47xk0fVD9eyQSVJTD7DEou7qLc7LIw7htzILVcPLtL5/3Q0aBY1kBbknM3bD/LKlKocTjc4hWyptC2Dx5vF7/MGMah/Yy67bG6B7j9lVjOS9+Z93eL+HCzArXc2kVNOf3YScqJdNvXD3SRm5T0xp8LNd5Lx62z2jXrMt2zQcaHReL3se/ZRMIYKg+/I9fxaYS5i3ZqQU5I0a2DzxzYnz7F7xV3U2+uFxvUC1yx9tJv4ZGrYEM7sYJjwkZeZvxpctv99tIFjx7RuZnPHtdDxtB956aUv6dOnD2effXa+91yzw8OuX/OeZV7cn4NjPOzYtoZly1y0adOGsDB9sBM5FfSOJyGpR0wk/laqi2h/BrEPPkHGvJ/YM6gvh7/5gsxlCzn8zRfsuakfGb/8TOyDTxBxWscc57qA7uUjT1rtUjTNGlj5zi6u32YEYFg/fyiONyvH446Tzd6k6Xme37xh6RvnEBNt8fCtbl5/ys2FZ1sc37Dusn3/juZa24LOp1n8+yEX/3nYRdOGMSxYsADbtunduzfbt2/P935N61v5brVYvJ+Dm2kfv8Dpp59OTEwMXbp04d5772Xy5Mls3LjxlAwnONWysgwJiYYlaxyW/u6wOcng9bfIp8hJoHUoJSRtyMjivITd+R53bOvFZYtxDuzDrhBLRPsziLkxt60X//ZNk+q00QzvEqUg6x/C8QtqN89zUe9/LqhtWdCoDrzxtDto2y8GSrbHsGU7bNxq2H/AtzVp+XLQpL5F43oWUbkMQv7qq6+44oorqFq1KklJSURE5Fzq56jNSYZb/y/v3oGjivJzAN/P4v3nPWzdsoJFixYd+/fHH38AUKlSJc444wzOPPPMY/9bo0aNgn+DSogDhwzfz3OY+ZvD1h3kmLHvdkPTenBRdxe9uuT+cxMJJAVKCVnXbNrDosOZfpcQKiwX0K5cOF82qR7Aq0qgPP+Gh58XnpxFvR+82cWFZ4dup8+oUaMYOXIk7du3Z+nSpScEa48xzE/LZMWRLFanZ7HlzWicnS7IZ9xmYX8OLtvXgvr0PTlHc6WkpLBkyRIWLVrE4sWLWbhwIXv27AGgbt26nHnmmcf+HW3dLImysg0ffOXw6XcOXsf/ZDPL8j0eFQG3XG3Tp1f+64SKFJUCpYSsLZnZnJewi6wA/gW4ge+b1aCZ9vEukbbtMNw8MgvHCVzws22oXhneHuUmPMSn9l999dVMnTqVgQMH8uGHH5LmdXhnbxrvpRxij8fBhW8yXLn1kdT8Nvak1PDSCBentcz/52uMISkp6YRWzCVLlnD48GEsyyI+Pv5YC+aZZ55JmzZtirVDUSAkJhuefMXD9t1FW7WgTTOLx+9wERcb2r+ncnIoUEpIe2/vIf5vx/6AXe//asZya9WS2bIR6rKzs3nyySeZ/HUWjTqMCljXtGXB2MdctGoSuq2TRxljaNu2LWvWrOGut95jQZfe/OnxkqNB2EDtzyoRlRyOVex1MH1sG3qcafHYkKLPNfV6vaxbt47FixcfC5mrVq3C4/EQERFB+/btT2jJbNKkySkb4rBxq2H4aA/pmTm7twvKtqFaHPz3MTdVKylUSmApUErIe3HXfsbvOVTs69xWJYbHalYs9WPoyqLNmzdz3XXXsWTJEp56+lnSIoezZDX5Tg4piNv621xzsb8pXqElPT2dhg+MJPz2+7CMweTx9+A+aFP/vSpYHqvYodK2oUJ5eOc5NxXKB/bvLz09nRUrch+PGRsbe0Ir5skaj5my33DLYx7S0oseJo9y2VCrOrzxlPY7l8BSoBQB3t57iGd37MdAocZUHo0RD9esyG1VYhQmS6DJkyczdOhQqlatykcffUSnTp3IyjI8OcHLwpVFe/k7OjZt8FU2A/soTB7vjT8PMmrngQIdG5kcRu2pcVgORQ6Vtg1RkTD2UTcN65yav7/U1NRj4zGP/tu92zfJ7/jxmGeccQann346FSpUKPK9jDE89l8vi1cHbqtMy4KrL7S5/Rr97krgKFCK/GVjRjYPJKWwPD3bt6hgHguWgy9IeoG2UWG8VDeO5pGa0V3SHDx4kLvuuosPPviA66+/ngkTJpzwxu71Gj793uGdzx0w+a+/eJRt+xZJf2Cwi67t1c19vEWHM7l60548Nw3ITeSOMGp+HYsr3S50qLQsqFEFnr3PTYPawfswd/x4zKPd5UuWLCEtLQ3LsmjZsuUJrZiFGY85d7HDUxPy/5iblrqKbWvHsX/3XLKO7MSy3URVaEr1hv2p1XQwYRFxJxxvWb5VCRrX1YdgCQwFSpHjzJgxgz7DH+Lq9z5mbVQF9npypozKLptzYiK5oXJ5OpQLV6tkCbRo0SIGDBjAn3/+yauvvsr111+f57Fbdxgm/8/L7EXm2OeIfy4tdPRr0VFwaU+bAZfYxETr5368dMeh94ZdJGfnMmbyL8eW4Vq+GGf/fuyKsUS070jFa2+n9r4eVFxTDmOZfIOlbfkm9/S7wOamq+wS2XXr9XpZv379Ca2Y/xyPeXx3eZMmTbDtnB9Q7n4mm/Vb/Hd1/73EUjNqNx9CdGxLjJPNwZSl7Eh4m/KV2uRYYsllw/ndLB4YrP1NJDAUKEWO06dPH5KSkli2bBmWZfFntpfNmdlkGt8e4A0iwqgepm6iksrr9fLiiy/y+OOP06FDBz766CMaN25coHP3HzT8usywIdGQsMXh0GFfa2TlWIsWjSxaNrbo0s4K+ZnceXlv7yEe/2vYSG4OffQO+//9FOGtT6N8/xtw1aqDd2cyaZ+8T9aaFcQ+9CRxF95MxVXliFkbhTs999bfyrFwUXebS3vYVI0rXT+L9PR0Vq5ceULI3LhxI5BzPOYZZ5xBplODmx/zv2bngT0LWPZ9TyrV6k3bnlOxXSeuAep4s0hJnkHVepflODfMDdNecRMdVbq+j1IyKVCK/GXLli00btyYN998k1tuuSXY5UghJScnc8MNNzB79mweeeQRnnzySW27d4oYY+ixYReJWZ5cA2Xm8sXsGXw1kd16+rYyPW6zbePxsPf+W8n45Weqvf0ZEe3PAAPuNJuIPWHYGTZRNvy3eSXiG9rEVSxb4cffeMzWXUZSrelIsPIeWrFy1hWkJv9Al74biIyuW+j7v/CAi46tNXRDik9t3SJ/ee2116hYsSLXXXddsEuRQvrqq68YPHgwUVFRzJo1i549ewa7pJCyNiObLVl5t6QdnDQBLItKI587IUwCWG43lR4bxc6Lz+Lg269S9ZV3wAJPjIMnJhOAQ0BGg2jiKkSdzKcRFHFxcZx//vmcf/75gC+cb9++nUWLFvHJzLrsTXew8tgl2The9u2aTUzlDkUKk7YNCYmGjq2L9RREAO3lLQLAkSNHeOutt7j55pspV65csMuRAkpPT+eOO+7giiuuoHv37qxcuVJhMghWHsm53/ZRxuslc/F8wuPb4q5eM9dj3DVqEd6yDZmLfsPksjemK597lCWWZVG3bl369u1L1Vrtsay8232yM/fieI4QWb5B0e4FJO9WJ6UEhgKlCPDxxx+zf/9+hg4dGuxSpIBWr15Nx44deeedd3jttdf4/PPPqVy5crDLCklrM7Lz7O5y9qdiMtJx1/bfguaqXReTkY6zf1/OawBr0kMjUB4vO/vkXt8A2flvqy5SIAqUEvKMMbzyyitcfPHFBZ7AIcFjjGH8+PGcccYZuFwuli5dypAhQzTbPoj25bYbTmEdHc6fy8/RAKm5rLhQ1kVE+H88LKIKtrscGWmJRbq+BURomLEEiAKlhLz58+ezYsUK7rrrrmCXIvn4888/6dOnD3fffTe33347ixYtIj4+PthlhTyLvMO8HRuHFRmFJznJ7zW8O7ZjRZXDrhgb4OpKrwa1LFx+3qUt20VcjZ4cSllGxuHthb6+Y6BuTX0Qk8BQoJSQN378eJo0aXJsULyUTD/++CPt2rVjwYIFTJ8+nbFjxxIZGRnssgSo7LbzfDOxXC4izuhC1tpVeHbvzPUYz+6dZK1bTcSZXbFy2VDABqqFhd7bVbMGVr4L7tdvMwIwrJ8/FMebc1iA42SzN2l6ruca47uHSCCE3l+oyHF27tzJZ599xp133pnrosISfFlZWTz00EOcd955tGrVilWrVnHJJZcEuyw5TuuocPwNxatw851gDPtGPZZj0o3xetn37KNgDBUG35Hr+RbQJir0dqM6vQDL+VSs1plmncezb8csFk/vxPb1r7Nv11xSd8xi65qXWPhlO3ZsfDfXc6MioUUjBUoJDC0bJCFt4sSJhIeHM2jQoGCXIrnYuHEjAwYMYOXKlbz44osMHz5cwb8EOq2c/7AX0f4MYh98gv3/foo9g/pS/tobcdeshWfnDt/C5quXE/vgE0Sc1jHX873AaeXyGVBYBtWqZtGxlcWydf738a7d7GYqVOlI0tpxbF0zhqz0Xdh2mG/rxUbXUKdFzqDusuHi7jaREQqUEhha2FxCVnZ2NvXr16dPnz68/vrrwS5HjmOM4b333uOuu+6iVq1afPTRR3TsmHvYkJLhooRdrMvI9js559jWi8sW4xzYh10hloj2ZxBz421EtDs9z/Oqum0WtqyFOwQnXi1b6/Dgi/nv5V1Ybhe887ybWtVC73sqJ4daKCVkffHFF+zcuZM777wz2KXIcY4u3/Txxx9z0003MW7cOMqXLx/ssiQfN1UpzwPbcy75c7yIth2IGFO4D2828K/K5UMyTAJ0iLe5oJvDzN/8t1IW1k19bYVJCSi1UErI6t69O7ZtM3v27GCXIn/57bffuO6669i3bx9vvPEG1157bbBLkgLKNoZLNu5mY0Y2gWpPs4Eqbpufm9ckxt905zIu7bDhtsc97N1HvpN08mPbEN8Y/vOIG5etQCmBE7p/oRLSVq5cybx587RUUAnh9Xp5+umn6d69O7Vr12blypUKk6VMmGUxtm5cQK/pAP+pWzmkwyRA+WiL/zzsJq4ifpcRyo9xPES6djDqfoVJCbzQ/iuVkDVhwgRq167N5ZdfHuxSQt62bdvo2bMnTz31FI899hhz5syhQYMGwS5LiqBlVDhjAhgqH6pRke4xWhoKoEZVi/GPu2ndrPBB8Ohogdpxf/Ddu6357JN3A1ucCAqUEoL27dvHhx9+yJAhQwgL0zYRwTR16lTatWtHYmIis2fP5qmnnsLt1tDu0qxvpWherhuHC98e3IXlAjCGtFde5PRNvwe2uFKuSiWLl0a4uO9fNhX+Glbsr6Hx6III1SrDM/e6eP/l1gy+aQC33347c+bMOfkFS0jRGEoJOS+//DIjRowgKSmJ6tWrB7uckHT48GHuu+8+3nrrLfr168ebb75JpUqVgl2WBNDa9CzuS0plfUY2Fr7tE/05motqh7l4sUYMj15+CRs2bGDhwoVqsc5Ftsfw6zLDj785rNts2H/wxMerVYZWTSwuPNumQ7yF/VfyzM7O5qKLLmL58uUsWLCApk2bBqF6KYsUKCWkOI5Ds2bN6Ny5Mx9++GGwywlJK1asYMCAAWzbto1x48YxePBg7cNdRmUbwxf7DvPO3jR+z8gGfEuLHJ1XYsOxBdEbhrsZVKU818ZFE2Xb7N27l06dOlGuXDl+/fVXKlSoEIRnUHrsO2hIO+zr3q4YAzHRef9N7du3j65du+L1elmwYAFxcYEd+yqhSYFSQsp3333HxRdfzPz58+ncuXOwywkpjuMwduxYHn74YeLj45kyZQotWrQIdllyimzMyGbFkSzWpGeR4nEwGGLdNq0iw2lbLpxWkWE5PlisW7eOLl260LVrV77++msNhwigTZs20alTJ1q3bs0PP/xAeHjo7UQkgaVAKSHlkksuYffu3SxevFitYqfQ7t27GTRoEN9//z3Dhg3jueeeIyIi9HY+kcL78ccfufDCC7nzzjsZO3ZsjsezPYYt22FjomHnXoPXA+Hh0KC2RbMGFrWqob/1PPzyyy+ce+65DBw4kEmTJun7JMWij3sSMv744w++++473n77bb1w5sNxDDv2wIE0gwVUjLGoWZVj47AK4/vvv+fGG28EfC3EF154YYCrlbKsd+/ejB8/nqFDh9K8eXPuuMO3jeCOPYb//eTwzRyHw+m+Y91/zQIywNEtw2tVgyt621xwlk15P93Aoahbt25MmjSJG264gebNmzNixIhglySlmFooJWQMHz6c9957j6SkJKKiooJdTomTkWn4eaHhh18dNmwxZGad+HhkBDRrYHFBN5uenSwiwv2/OWdmZvLII4/w8ssvc9FFF/HOO+9oEpQU2f33388rr7zC119/y96sc/nga99IzILsHmMB5aNh+E0uzu6oxU3+6fHHH+eZZ55h6tSp9O3b98QH04/Abz/D7ytg3WpITfF9Q6tUh/i20LoDdOkOYeoyD3UKlBISDh8+TJ06dbj99tsZPXp0sMspURzH8OUsh3emORzJ8A3qz+tV4ehj5SLh5n42fXrZubZarl+/ngEDBrB27VpeeOEF7rnnHmxbb+RSdF6vlz5X3EiqaxjlYlvz97zwgjn6u3vh2RbDBrlwudRaeZQxhgEDBvD1118zd+5cOnbsCHv3wHuvwueT4XAauNzgeP9+cbAssF3g9UBsJbj6RrjhdqgQG9TnIsGjQCllRkamYct2w6G/ZjrGVbSoXwvcbouJEycyZMgQNm3apCVIjvNnquGZVz38/kfRzm/TzGLkUBdVKvnenI0xTJo0iXvvvZd69eoxZcoUTjvttMAVLCEr9YDhrqez2LXXwbKKPlrLsqB7R4vHhrq0W8xx0tPT6dWrF4mJiax58Wkqv/4iZKT/PXYgP7bLFyyffBm69z65xUqJpEAppVrqAcN3cx1+/M0haVfOljW3CxrXgyVzRlEjZh1ff/VJcAotgXb9abj3OQ/7DhR9f2DbhsqxMPYxN+H2fm677TamTp3Kbbfdxn/+8x+io6MDWrOEJscx3Pech3WbC9bFXRA3XmHzryuKsvR62bV7505m9OrIvyIcjGVhFTYeWDYYB4Y8ALcP+3uLHgkJCpRSKmVmGd793GHaDw6OybuL1sdgjCE8zDDk2rA8u2lDyZF0w62Pe/gzpehh8iiXDRWiM1g8/QwOHdjDxIkTc47DEimGz2d6mTA5QEnyL7YNrz3hpkn90H4tOMYYeP4RzKfvFXIwQR7ufAhuvT8QV5JSQoFSSp1N2wxPvOJh1978gmTuWjeFJ+50Excbum8kL7/r4ds5BidAf/3G8WLS/sf7YztTt27dwFxUBEg7bLj6Pg9Z2fkcl7qKbWvHsX/3XLKO7MSy3URVaEr1hv2p1XQwYREnLt5t276dZP77qBY7AeC7L+CROwJ7zYlT4YyzAntNKbH0lySlyvrNDg+84CUzu2hhEmDdJrj7WQ//fcxN1UqhFyrXbHSYPjv/b15h3qAt24VV4QoOZaoLUQLrh98csvMJk8kJk0hYcDflKjajXqthRMe2xDjZHExZSvKGiRzYs4C2vaaecI7jwOoEQ2KyoUHt0HsdOEHKnzBqRK4z8t5NPcJNSQeJsGBDi6rUDz/xb7zHHyns9RrWNK9y4jVtG0beA1/MhXIa+hIKNO1SSo09KYaHxvjCZHHGUXkd+DMVHvq3h6ys0Gug/+x7B1c+f/nJCZNYPL0zh1KWUK/VMNqdN502PT+jWoO+JG+YyLpfb8txjsuGqT8EtltSZPpsx++E7gN7FpCw4C4q1TqXMy5dSJ0WQ6hU4xziavWmQZsRdL5iNTWb3JjruS4bvp+n31k+fBOOHPH7KT3TwMhdhwp+TceBPTvhi48CUKCUBgqUUioYYxjztpeMjMAMyvc6kLQT3vsytN5M9u4z/LrM+B03WdQ3aK8D85YYUg+EXkiXkyM9w7A12X9vROLq0YBFiy6vYrty7r5ku8KpWu+yXM/1OrA6IbReA3LIzICpH/iWBPLjwphwPtqXwcr0fJqL/2nKpKJ3J0mpokAppcLPCw1Lf/cfhMDXTbv2l1v4bVozZn8Qw5zJlVj0vzPZumYM2ZmpJxxrDHzyncOW7aHzYrdqg8n3tb04b9COA6s3hM73U06uP7b5/10yjpd9u2YTU7kDkdFFG7u7KQm8gRpMXBot/AUOHcj3sIeqRVPZbTNiZyFaKY2B7Vth3apiFCilhcZQSqnw2fdevwtuQ9HGUdkWfDXL4b4bQ2PsX0KiweXKe2m54r5Bu1y+e5xzZjELFQFS9vt/PDtzL47nCJHlGxT5HtnZ8O13c6hQ3iIsLKxQ/1yuMvC68fsK/L4o/CXGthlZLZp7dxzip0OZ9IrJ+WEzdxasXQnx7YpdqpRsCpRS4v2x1ZCQ6P+Yv7tpe9O259QTWtbiavWmXvz9pCTPyHGe14EZvzjcfo1NVGTZH5i/fZfx+75R3Ddorxe27w7h1h4JqECtOZmfvn37kZ2ZUujzLMsiPDy80EE0LCysyOcV59zczotcuxLLcQq0VNCQyuUYu/cII3YeYlH5cKyCrDPpdsH6NYX+3pYGXq9h737fh5KIcN+avKG8JJ0CpZR4y9c5+bZOFqebNisb1m8xtG9Zcl4IjDFkZWWRnp5e6H9HjhzJ8zFP3DO4ynU8qbX/cw9wkaKKLuf/8bCIKtjucmSkJRbjLobfVy8BssnOLty/rKysQp9z/HlpaWlFPjdQfmkSx1nRBduHO9y2eLZGea7bdoBP92dwTaWo/E/yOnAw/y710mJ3iuHbOQ5L1jhs2gbZnr8fiwiHJvWgU1ubi7rbIbc0nQKllHgbE43fQFncblrbgoQthvYt8z7GGENGRkaxA11Bz8/IyMApRPOM2+0mKirK77/KlSuTFuUmA0Ne02aL+wZt4XtRFQmERnX9vyFbtou4Gj1JSZ5BxuHtREbXKfQ9alWzaNq0QRErDA5jDF6vNyDht8mH42DH1gLf+9rYSMb8eZjHdqVxVWxk/idYlIkdc/buM0yY7GXeUt/7UW4vz5lZ8PsfsHaTw7tfOpzX1eL2a11ULF/6n39BKFBKibd1p/Hb9VXcblrH8fDWuz/y2osv5RkIMzIyCnXN8PDwXENduXLljv3/ChUq5BsC8zr3n//c7oL9Kb/xsZdpM508u72L+wZtu6BujdB48ZSTr0osVCgPB9PyPqZ+mxGkJH/P+vlDadtzGrbrxE80jpNNavIMqtS9NMe5tg3xjUvf76tlWbjd7mMfJItl2c+wK6nA4wssy+KFmjGct3kfb6Ycyff4bK/DrMVLWDpqFK1bt6ZVq1Y0bNiwVI0//WmBw3/e9ZKZ5WvYyG9i49FjZv5mmL/Cw4hbXHQ+rezPgVaglBIvgL07eXK5I6lWu3axQt3Rf5GRkSX2xbJpAyu/sffFeoP2en33EAkEy7I4t7PN1z85ea7wULFaZ5p1Hk/CgrtZPL0TtZvfTnRsPMbJ5lDqCnYkTCI6Nj7X31fHgXPOLPtv9H7Ft4Wfvi3UKb1jIjivfDhP7z5M3TD/378wC5YeyWbMmDHs378fgKioKFq2bHksYLZu3ZrWrVtTt27dgo3LPIU++97L6x8XbTCv48ChwzByrJcHBsOFZ5ft3zUFSinxIvOZTFjcblq3282FvXpx343nFen80uS0Fha27b8xojhv0C4b2jUvWW8IUrp1O20/X/xYwe8xtZvdTIUqHUlaO46ta8aQlb4L2w7z7ezU6BrqtMh9S8HKsdCpXYj/vrbpUKTZTy/UjOH0jSns8Ti0ivQfJR776DMebdiUnTt3smbNGn7//fdj//v555+TluZrgo6JiaFVq1bHQubR/61Ro0ZQguYPvzpFDpNHHW3N/PckLxXKQ9f2ZTdUKlBKidewjsUfW/Neg7K43bReB+rVCkChpUBcrEW3Dla+i5sX5Q3aZUP3My1iK4T4G7QERHp6OmPHjuW5556j8ZlvUbnO5Rg/SyfHxLUjvtukQt3jxitduEJ4Vi4AHTpDtRqwZ1ehTmtfLowBsZF8tN/PcCDbhuatoVEzLKBWrVrUqlWL888//9ghjuOQlJR0QtBcvnw5kydPPjbUqFKlSjlaM1u1akWVKlXyuHHx7d5r+O97+XTnFIJlwYtveXlvtEXFmLL5O2cZoyXspWT78kcv4yc7fsetHNizgGXf9/xr2aDCddMCjHvMRaumZfeT4/F+/8PhnmcD90J5vAmPu2jRKDS+j3JyOI7DlClTePTRR9mxYwdDhw7lvmFPMOzfFUjzvztggblsaNfC4sUHXSWuizUo3n4FXhkN5iSs0/T0WOjTv9Cneb1etmzZckLQXLNmDRs2bDg2y7169eo5WjNbtWpFxYoVi132iDEelq8t2GYa29aOY//uuWQd2Yllu30fvBv2p1bTwYRFxB071rah55kWjw4pm215CpRS4m3fZbjxYU++x/29sHnzPLtp/7mwOfiWJpk61k14WOi8sYx738P/fjYEaoMQy4Ire9vcObBkjh2V0mHu3LkMHz6cJUuWcOWVVzJ69GiaNWsGwJI1Do/+x4vjQHF+bW0bKlWACU+4qVopdP7m/TpyGK7q7mulDNTiny4XNGkBk7+HAk4aLIjs7Gw2btx4Qrf5mjVr+OOPP/D+NUC8Tp06OYJmfHw80dHRBbrHlu2GW0YW5j2nGbWbDzlhM40dCW9TvlKbHO85lgVTXnJTNa7s/e4pUEqp8MALHlZu8D/bG+BQ6kqS1o5j3645J3TTVql7CXVa3EF4ZNUTjrdtuPpCm9v6h1YQSs8w3P64h117yfcTeH5cNtSsBm885SYyouy9SMrJl5CQwIgRI/jyyy/p2LEjL730Et27d89x3G/LHZ4a78UxRcs9tg2VK8J/HnFTq5p+V0+w+De4tW/grudywSc/+kLlKZCRkcGGDRtyBM0tW7ZwNOY0bNgwR2tmixYtiIw8cfmjse97+WZ23hPB4J+9YlNzrH/seLNISZ6RY/1j24KBfWwGXVn23nMUKKVUWLLGYcSYwHfThrnhvdFuqlcJvTeXPSmG+57zsHdf0UOlbUO1OPjvY2rtkcLbu3cvTz31FK+//jq1atXi+eef59prr8W28x42sXGr4fk3PGzbWfDub9sCx8A5Z1jcc4NL43zz8uGbMOaJAFzIgufGw8VXBeBaxXP48GHWrVuXI2gmJSUBYNs2TZo0OSFofjLvUvYfCvN73ZWzriA1+Qe69N1Q6PWPm9aH15/yf/3SSIFSSo2HRu9hyboYLCtw3Sd3DLDpe0HZ+6RYUCn7DaNe97JyfeFeBoxxsCyb9i0tHh3iIq6i3qCl4DIyMhg3bhyjRo0C4NFHH+Xee+/N0VKUl2yP4YuZDtN+cNi7L/etqG0L+GsB6uYN4bpLXXQ7XeN78/XRW/Dvx8GywSnkh3iXy9en+8w4uOjKk1NfgBw4cIC1a9fmmHW+NzWD7gP2+D3XOF7mTKlM+djWdLzkl0Lf2+2Cb95w43aXrddNBUopFT744AOG3vkgZ1y6CHdkDRyneH+Itg1tm1v8+0FXSO+9Cr5dN6b/7PDWVIe0I3+35uTm6I5Fbiud9QsfYvY3D9OwYYNTWq+UXsYYPv74Yx555BG2b9/OkCFDeOKJJ6hatWr+J+fC6xiWrDas2mBYv8WQvNvg8fiWGmtU16J5A4sz29k0rR/af+OFtnoZPHoXJG3xBcv8JuscXYusRRt49hVo0vzU1HkSzF+2n5Hj/I+1zErfzS+f1qVag/60PufDIt3nvdFu6pSxTSDK5lQjKTOys7N58MEHGTt2LDfddBOPP12NES9Z7DtQjG5ay9di8cw9CpPgWzz6sl4uLjjbZu5iww+/OqzbbDiSfuJx0VHQspHF+d1sOrSwad36f4wYkcqnn34anMKlVPnll18YPnw4ixYt4vLLL2fGjBk0b1684OGyLTq1s+jULkBFik+bDjD1J5g+FaZMgj/W+77uDvs7XFoWeP6auNLqNLh2MFxweUAn4ARDZFQF4OSsgnG8zFOwYcepVrp/8lKm7dmzh/79+/Prr78yYcIEhg4dimVZjH/c8Pwbhe+mPdq6dv5ZFnfd4CJKE0hOEB5m0burRe+uNsYY9qTCgUO+71uF8r6xkn8vsVKe559/nhtvvJF58+Zx9tlnB7V2Kbk2btzIww8/zOeff87pp5/Ozz//TI8ePYJdluQnIhL6Xg9XDYQtG+H3FbB+DRzY52u1rBQHLdtC6/ZQt0Gwqw2YsAKkouJupgEQVgZHWqnLW0qko8uGZGdnM3XqVLp163bC48YYps92eGeaw4E0/O7+4rJ9rZm1qsHd17s4s63GUQWC4zh07twZr9fL4sWL/U6kkNCTkpLCM888w4QJE6hZsybPPfcc1113nX5PpERL3W+4+r78lwxaNetKUpJn0KVvQqE307BtmP66m4jwstWoob9sKXHeffddunXrRu3atVm6dGmOMAl/ddP2dPHpf908foeLLqdZxOWylm3NqtCri8WYES7ef8GtMBlAtm3z3//+l2XLlvHee+8FuxwpITIzM3nppZdo0qQJb7/9Nk8//TQbNmzg+uuvV5iUEi8u1iLW/06fANRvMwIwrJ8/FMebleNxx8lmb9L0XM+tW4MyFyZBLZRSgmRnZzNs2DDGjx/PLbfcwvjx44mIyGcj7384kGZIO+zrpo2NgXJRZe+PtqQZMGAAs2fPJiEhgZiYmGCXI0FijOGzzz7j4YcfZtu2bdx+++088cQTVKtWLdiliRTKc294mL0w/11yirKZhm37NoG447qy1+etQCklwu7du7n66qtZsGAB48eP57bbbgt2SVJA27Zto3nz5tx///0899xzwS5HguC3335j+PDhLFiwgMsuu4wXXniBli1bBrsskSJZs9Hh3lEFm5hT2M00AN55zk29WmWvsUOBUoJu4cKF9O3bF6/Xy7Rp0+jatWuwS5JCevzxx3nxxRdZt24dDRs2DHY5cops2rSJhx9+mKlTp9K+fXvGjBlDr169gl2WSLEYYxjyhIfN2wO3EyX4xvOf1tLixQfL5nxoDWiRoJo0aRLdu3enXr16LF26VGGylBoxYgSVK1fmoYceCnYpcgqkpqYybNgwWrZsyfz583nvvfdYsmSJwqSUCZZl8eDNgQ99tgvuu7HsdXUfpUApQZGVlcXQoUO55ZZbuOmmm/j555+pVatWsMuSIoqOjmb06NFMnTqVuXPnBrscOUkyMzN5+eWXadKkCRMnTuSJJ54gISGBf/3rX5pwI2VKk/oWg64I7O/0nQPsMr2HvLq85ZTbuXMn/fr1Y8mSJYwfP55bb7012CVJADiOQ5cuXcjOzmbx4sW4XGX3k3hJle0xZGX71rgLD+AsUmMM06ZNY8SIESQmJnLrrbfy1FNPUb169YDdQ6SkMcbw3/e9TP+5+DFp4GU2g/uW7ddEBUo5pebPn0/fvn2xLItp06bRuXPnYJckATR//ny6du3KpEmTGDx4cLDLKfMyswyzFxkWrXJYt8mwO+Xvx2Ir+HY2at/S4ryzbCqUL1rAXLBgAcOHD+e3337j4osv5t///jfx8fEBegYiJZsxhg++dnj/SwfLKtyYStv27cx2+7U2V51XtsMkKFDKKfTmm29y1113ceaZZzJ16lRq1KgR7JLkJLjuuuv46aef2Lhxo5YROkmysg0fTXf4/AeHw+l5L+x/dGMjlw0XdLO4+WoXFQsYLLds2cLDDz/Mp59+Srt27RgzZgy9e/cO4LMQKT0SEg0vvuVhy/a/N8vIy9HHWzaGB292U78MzujOjQKlnHSZmZncfffdTJw4kTvuuIOXX36Z8PDwYJclJ0lSUhLNmzfn3nvv5fnnnw92OWVOQqJh1Oseknf7thItKNuG8uXgwZtddG2f99iwffv2MWrUKF555RWqVKnCqFGjuOGGGzSEQUKeMYZVGwxfzXJY+rsh7UjOYyqUh05tLS4/16ZFI+u47WrLPgVKOal27NhB3759WbZsGa+99pq6QUPEE088wejRo1m/fr2WEQqgpb87PPZfL15v0ZYzObqf/b3/sunT68SAmJWVxWuvvcbTTz9NZmYmI0aMYNiwYURHRweoepGywxjDnlTYvsvg8UB4GNStaVGlUugEyH9SoJST5tdff6Vfv364XC4+//xzzjzzzGCXJKfI4cOHad68OZ07d2bq1Kn5nyD5Wr/Z4b7nvHi8hWuZzMujt7s4t4uNMYYvvviCESNGsHnzZm6++WaefvppDUkRkULROg8ScMYYXnvtNXr06EGzZs1YunSpwmSIObqM0LRp05gzZ06wyyn1MrMMz77mxesEJkwCvPSOlx9mLad79+707duXJk2asHLlSt58802FSREpNLVQSkBlZGRw55138vbbb3P33Xfz0ksvERYWFuyyJAi0jFDgvPmpl0+/c/INk2mpq9i2dhz7d88l68hOLNtNVIWmVG/Yn1pNBxMWEff3wcZLyo5ZOLsfYcyYMZx//vkn90mISJmmQCkBs337dvr27cvKlSt54403uPHGG4NdkgTZggUL6NKlC2+99RY333xzsMsplQ6nG/rd4yEr2/9xyQmTSFhwN+UqNqN28yFEx7bEONkcTFnKjoS3KV+pDW175Rx+8NqTFs0alM2t4ETk1FGglICYN28e/fr1IyIigi+++ILTTz892CVJCTFw4EBmzZpFQkICFSpUCHY5pc6XP3p55UP/M3AO7FnAsu97UqlWb9r2nIrtijjhccebRUryDKrWu+yEr7tsuKi7zf2D1HosIsWjMZRSLMYYJkyYQK9evYiPj2fp0qUKk3KC0aNHc/DgQZ577rlgl1IqzV9hyG/lkcTVowGLFl1ezREmAWxXeI4wCb618n5ZVoTp4iIi/6B+DimyjIwMhg4dyrvvvsv999/Piy++iNutXyk5Ud26dXnooYd4/vnnue2222jUqBH7DhpWbzAkbDVs32XIzoaIcKhbw6JpA4u2za0i7+xSlhhjWL/Z+B07aRwv+3bNJqZyByKj6xb6HvsPQuoBQ1xFfb9FpOj07i9FkpSUxFVXXcWaNWv48MMPGThwYLBLkhLswQcf5K233mLYw2/SocezzFticBxwuXzrKRrjWyPRtgxeB9wu6NnZot/5LprUD92gc+AQuS6efLzszL04niNElm9Q5PskJitQikjxKFBKoc2ePZv+/ftTrlw5fvvtN9q3bx/skqSEs13luHzQTNZvb8K8xV4c4xtt4/X+fYwx4P2rJc7jhZ/mG378zUP/i2wGXWETHh56gSc989TcJ+MU3UdEyi4FyhCQkWmYt8SwOsFh7SbD7hRfq1BEGDSqa9GikUWX9hbxjf1vE2WMYdy4cQwfPpwePXrw8ccfU6VKlVP4TKQ02r3XMOwFD3v2NgE4Fibzc3Sv3E+/c1i0yuHFB90h0YqWnp7O1q1bSUxMZO2GPcAAv8eHRVTBdpcjIy2xyPfUik4iUlya5V2GHU43fPi1w/SfHY5k+N40jm8ROuroRvYNa8P1l7s454ycwTI9PZ3bb7+dDz74gAceeIDnn39e4yUlX3+mGu56xkPqgaJtFXiUy4YaVeGVkW4qxpTuUHnkyJFjgfH4f0e/tnv37mPHutzhdB+QimWH+73mqllXkpI8gy59E4iMrlPomt55zk29WqX7+yoiwaVAWUYt/d3hhYle9h0Ap4A/4aP7/HZtb3H/INex1qCtW7dy5ZVXsn79eiZNmsSAAf5bTEQAHMdw7ygPG7b83dpYHLYNZ7SxGHWfy29LerAdPnw4R2A8/r/37Nlz7Fi3203dunVp0KBBrv9q1arF3c8aEhL93/PEZYOmYbtODKCOk01q8gyq1L00x7kR4TD9dTe2XXK/pyJS8ilQlkHTZzu8/K4X2yp4mDyebUNcRfjPw242/P4z/fv3JyYmhi+//JJ27doFvmApk6bN8PLqlMAvSfPwbS7O6xq8Fc/S0tKOBcTcWhr//PPPY8e63W7q1avnNzDmt4PQG594mTrDybeF9++FzZtTu/ntRMfGY5xsDqWuYEfCJKJj43MsbG7b0L6lxYsPqrdBRIpHgbKM+fE3h+ffzKVfu5BsG8LsNH7+uA1nd41nypQpVK5cOQAVSihIzzRcfY+nQJNKCrVdIBBbAT75jxu3++S0qKWlpeUZFhMTE9m7d++xY8PCwvwGxpo1axZ7y8ntuww3Puwp0LGHUleStHYc+3bNISt9F7YdRlSFplSpewl1WtxBeGTVHOc8dbeLbqdrSWIRKR4FyjJkxx7DzY/lv0VbQTlONrGRW/h0QjPtxy2F8s1sh/+8m/8Hm6JuF/jkXS7O7li0EHTo0KE8w2JiYiIpKSnHjg0LC6N+/fq5hsX69esHJDAWxIgxHpavNQEZOnCUZUHlWPhojBuXS93dIlI8CpRlhDGGYaO9/L7R/5tOYVuDAB66xcUF3dSCIQV397PZrNuE3wW5i7pdoG1Bp3YWz96XezftwYMH/QbG1NTUY8eGh4fnGxhtO/i/+8m7fR8WswvWUFlgo4e7OKNN8J+fiJR+CpRlxJqNDveO8t8iVNTWoOpV4MMXNWhfCsbrNVwyxEN2Pi3lK2ddQWryD3Tpu6HQO7yUj/Jw80Uzc50pfXxgjIiI8BsYa9SoUSICY0EUZE/vgrIsuOhsi+GDNXZSRAJDryZlxJeznGPL/+TmwJ4FJCy4K9fWoLhavakXfz8pyTNyPXf3Xli21tCxtQKl5C9pF/mGyeJuF5iW7qbfNbdimwPHAuKZZ55J//79TwiM1atXLzWBMT+Xn2uz80+YOqN4odKyoGMri3v+pcUnRSRwFCjLAK9j+HWp/67uxNWjAYsWXV7N0bUIYLvCc3QtHuWyYe4SQ8fWASpYyrSDafl3egRiu8DfFqyhQ5vKZSYw5seyLIZca1MhGt75wsGyCre259Flwc7rajHsJhdhJ2lSk4iEJgXKMiBpJ34n4hS3NcjrwLpNDqAWDcnfqRpEU7lylZAbhmFZFgP7uOjYxmL0m1627fStyOAvWB5dPqxieRg+2EXX9qERwEXk1FKgLAM2J/l/Bw9Ea9DWHb6JPyV5QWkpGSqUz/93JBDbBVYoX+RTS73mDW0mjbJYssbwxY8Oy9YaPLlM2LEtaN4QrujtovsZFuFh+vsVkZNDgbIMOJJx8u/h9UK2B8K1epDko15NcLvJNeAcZdku4mr0JCV5BhmHtxd6u8AK5aFybGiHI9u2OLOtxZltbTwew9YdsHWHISsb3C6oVQ0a17OICA/t75OInBrq+ygD8uv1C0RrEPjGUorkx+WyaFIP8osx9duMAAzr5w/F8WbleNxxstmbND3H120L4hsrJB3P7bZoXM+iV2ebC8+26d3VJr6JrTApIqeMIkIZUDXn0pEnONoadChlGRmHtxfpHhWi0eLHUmAXdLMx+B+KUbFaZ5p1Hs++HbNYPL0T29e/zr5dc0ndMYuta15i4Zft2LHx3RznOQbOO0svXSIiJYlelcuApvXzP6aorUHgmx3aopHCpBRMWloay355Ca8nPd9jaze7mY6Xziemcge2rhnDipkXs/rnfuze8gnVG11Di66v5TinQnk4q4N+H0VEShKNoSylHMdh0aJFfP7553z++edUa/cNkeUbYFm5f0Y42hqUsOBuFk/vRO3mtxMdG49xsjmUuoIdCZOIjo2nSt1Lc5xrAa2b6Q1c/MvIyOCNN95g1KhRHDhwgH6Dm7Mr/SLy6/yOiWtHfLdJBb7PrVdryRsRkZJGgbIUyc7OZu7cuXz++ed8+eWX7Nixg2rVqnHFFVdQu6XD3JWW3yVbaje7mQpVOpK0dhxb14whK30Xth3m23qx0TXUaXFHrucZ4HxtvSh58Hg8vP/++zz55JMkJydz00038fjjj1O7dl3ufNrD5qS8F9wvDJcNp7W0uKi7wqSISEmjrRdLuIyMDGbOnMnnn3/O119/TWpqKvXq1eOqq67iqquuomvXrrhcLg4cMlxzf+D3+nXZ0LW9xZN367OHnMhxHKZNm8b//d//sWHDBvr378/TTz9N8+bNjx2z60/DXc94OJBWuEW4/8llQ9XK8MpIN3EVFShFREqakAyUxhiSs72sTs9iU6aHTMcQblk0jHDTJiqceuGuoK63ePDgQb799lu++OILvv32W9LS0mjZsuWxENm+fftc6/v0Oy9vfBKYvX59DBHhFm+PclOjqt7ExccYw/fff89jjz3G8uXLueiiixg1ahTt27fP9fjk3Ybhoz2kHChaqLQs3xI4L41wUzVOv4ciIiVRSAXKA16HqfsO8+7eQ2zN8gK+vV8sfN263r+Oqxnm4sbK5bkmLprK7lOzO8zevXv5+uuv+fzzz5k5cyZZWVmcfvrpXHXVVVx55ZW0bNky32t4HcO9ozwkbAlMFyNAx8a/8cL/nROYi0mp98svv/Doo48yb948unXrxnPPPcfZZ5+d73mHDhte/cjLD7+afHd2Oero3vRXnGtzS3+bqAiFSRGRkiokAqUxhq/3H+HR5H2kOb6nm9+TtoBIy+KJWrEMiIs+KS2W27dv58svv+Tzzz9nzpw5GGM4++yzueqqq7jiiiuoX78A07f/IfWA4Z5nPexJKX6orOSezbRJ5zNixAiee+65kNkzWXJavnw5I0eO5Ntvv+W0007jueee4//bu/f4qMo7j+OfcybJTCYJxECIBMEIBWIUCl6WS3VfBJTaraAgYpdi0qK1dF+wVaqlRcEL3WpbqVvwRa2CoO22agWpFxBdVCraRLRoRJAgN0MChGuEXGfmPPvHbJCYZAicXJjh+/4HnXPOzHNGfOWb3+85z3PNNdec8v8XGzY7PL/aofAjgzHg8YQXza9X/++2DVdeajHhm+H1FEVE5MwW84Gy1jHMKDnISxXVxyuRp2pEio/f9+pCUius7L1161aWL1/OCy+8QGFhIfHx8YwaNYrx48czduxYMjIyXH/GoQrDrN8G2brr1K+trx5NHmOTP85i/vz5zJgxgxtuuIGnn36axMRE1+OT6FFcXMycOXN49tln6devH3PnzmXChAmuf7koP2j4aIth605DyV5DXR14E6BXpkW/LItB2RZpZ/lOOCIi0SSmA2WdY7hl5wHePlaDm2KdDQzyJ/CX3ukknuIPUmMMRUVFx5f32bhxI36/n29961uMGzeOb3/726SmproYXdNCIcMzKx2eWuFgnPBi0JHYVvicc7vCzB94GNj/y/tcsWIFkyZNYuDAgbz44ot069at1ccrZ5aSkhIeeOABlixZQvfu3bnvvvvIz88nLk4PZ4mISGMxHSjvLT3M0oPHTqsq+VU2MDbVz/xeXU56ruM4FBYWHg+R27dvp3PnzowdO5bx48czevRo/H5/K4zq5PYfMrz8lsNLbzhUHAu/5rEBiwZBM7s3jLvKw79ebpEQ37gy9P777zNmzBh8Ph+vvPIKOTk57TJ+aV/79+/nwQcfZOHChaSkpHD33XczdepUfD5fRw9NRETOYDEbKAuO1TBx+/5Wf99F53dldOfGbd9AIMDatWuPrxG5Z88eMjIyuP766xk/fjwjRowgISGh1cfTUo5jKCuH4p2GfQcMwRD4vHDBeRZ9syw6J5+8vbhr1y6uvfZaSkpKWLZsGaNGjWqHkUt7qKioYN68eTzyyCPYts2dd97J7bffTkpKSkcPTUREokBMBkpjDCOL97KjNhix1V1b9E+OPv04tRvW4xw5gt05Fe/gy0jJuw3v1y9tdL4NdI2zKbgwkzjLorq6usEakYcPHyYrK+v4k9nDhg3D42mfp8TbS0VFBRMnTuSNN97gD3/4A1OmTOnoIYkL1dXVPProozz00ENUVVUxffp0Zs6cSZcuJ6/Ei4iI1IvJQFl4rIYbT1KdPPrnJRz5zf0kXDyI5Ik348k8j9CeUo49+zR1Gz8k9af3kfLv32vy2ps/38zWpxexcuVKKisrycnJOb5G5KBBgzp0Dcv2EAgEmDZtGo8//jizZs1i7ty5egI8ygQCARYvXszcuXMpLy/n1ltvZfbs2WRmZnb00EREJArFZKC8/fOD/O1IFaFmjtduWE/5lBvxXZFL10eewDrhQQMTDHLgjh9Qs+5Nuj35V7yDL29wrQkGqSlYR9aS+ccrkdnZ2W14N2cmYwzz5s3jrrvu4qabbmLp0qWaZ9cKQo7hi2MQDEGiF5L9rfvLSSgU4plnnmHOnDns2LGDSZMmcf/999OnT59W/RwRETm7xGSgHLq5jLJAc3ES9k/7HjXvrqX7qneJy+je6Hhwbxl7/u0b+L4xgvQFSxod92PYPKBnzFciW2LZsmVMnjyZSy65hBUrVpCent7RQ4o6ZeWGlWsdPvzUYdvnUBf48lhqJ7iwt8XwwTYjh1r4TnNxb2MML730EnfffTcbN27kuuuuY+7cuQwYMKCV7kJERM5mMRcoK0IOAz4pbfa4CYUoHZ5DfN9sMv70t2bP2/fdsQQ+20KPdzdhNTEPcl12d3olaAkVgMLCQsaOHUtycjIrV65ssJezNK+s3LDgjyHe+zjy7jGWBcZAog9u/KbNpDE28XEtD5Zvvvkms2bNoqCggNzcXH75y18ydOjQVroLERGR8HMmMWVvhMokgHPkEKammrgePSOe5+nRE1NTjXPkcJPH95zkc84mQ4YMobCwEJ/Px7Bhw3jrrbdafO2RLwzrP3Z4/V2H199x+MeHDvsPG2Ls95wGjDGs+N8QU2YF+eCT8H1G2oqw/quoroE/vuhw25wg2z4/+fezfv16rr76akaOHEkoFOL1119nzZo1CpMiItLqYq7E5rRWEKl/n2ba2q32OTEiKyuLd955hwkTJjB69GgWLVpEXl5ek+cePGJ4Za3DqrUO5Yeafr/OKTD6GzZjcm16ZMTO1AJjDL9/xmHZ6tNbat8Y2L0Xpv8iyK/u9DCgX+PfCTdt2sQ999zDCy+8QE5ODsuXL+f666/XFA0REWkzMVehTDnJ9oh2ahqWL5FgaUnE80Jlu7ES/didU5s8nqynmhtJTU1l1apV5OXlkZ+fz7333tug0lgXMCx6PsR3ZgT544rmwyRAxVFY9ppD3swgv1kc5FhVbAT4P714+mGynuNAIAAzHw6xs/TL72XHjh3k5+dz8cUXs2HDBp566imKiooYN26cwqSIiLSpmEtFmfEe/HbzPzwtjwfv5cOo21REcN+eJs8J7ttD3eaP8f7L8CbnT9pAX1/MFXdbRXx8PE888QQPPvggDzzwAJMnT6a2tpaSvYbbZgd55hUHpwVbQcKXbeDX1hm+//Mgn3zmLoh1tE+3h7fCbA2OgUAQ/uuxICW79zBt2jT69+/P6tWrWbBgAVu2bCEvLy/m1kEVEZEzU8w9lANw47Z9vFdZ1+yWi8eXDbpyZHjZoBN+6JpQiAO33xpeNmjJ83gHXdbo+r7eONb0b/x0uDT03HPPkZeXx+XDx5OWvYTqGpvQaeYp24K4OPjVnQ33GY8WIccwZVaQsvLI8yWPHSri803zObLv79RV7cGy40js1JeMCyaS2XcK8d60r1xh2FV0Hwd3/J6ZM2cyffp0kpKS2vJWREREGonJQPnUgaPMKTsScQ/vBgubfyefuO6ZBPeUhRc2/3gDqXfdS8qk7ze6zgbuyOjEjzM6t9n4Y8kbb73HfY+dS1xCOpbtrqprW5CQAIt+EUf39Ohq4b67wWH27yI/yFVavJjigun4O/ejR/+pJKVeiHECfHHwA8qKnyT5nAEMHPl8o+vi7Er+9GtI75raRqMXERGJLCYD5dGQwyWbSqk9yZ0d33rxn+txKg5jd0rFO/hyUvKb3noRwoGy8MJMMuLVSmyJXy8K8to7Dsa0TgD02HBRX4t5Mz3YEaY2nGl++psgGzabZquTFeUF/PPVXM7JvIqBuc9je7wNjjuhOg6Wria915gmr7/nRx5yh0Rf5VZERGJDTE4ETPHY/DC9EwvKv4hYpfQOvATvw4+1+H1tYFJaksJkC23c6rB6nQEiB79TafOGHCjaYlhTYLh6eHQEyrqA4cMIYRJg58cPARbZwxY2CpMAtieh2TDpseG9IkeBUkREOkxMBkqA6d06sbKiih21wWa3YDwVNtAtzsOs7qmt8G5nh+WvOXhsIs6bPLHN2+uiGQ3avKVbnqCivKBRm9eyYNnqEFcPj44AtWO3ifgdGCfE4b1vkdLlEnxJkddHbUrIgc3bYq7RICIiUSRmA6XXtljYqwvjtpVT7RjcPFtrA3EWLDy/C8knWZZIwo58YXj7g8hVuYryAooLpjXZ5k3LvIpeOXdwsHR1o+uMga274LNdhq+df+ZXKXeVRT4eqD2AE6zCl5x12p+xe194jUstDyQiIh0hZgMlQHZiAn/unc6k7fupccxpVSo9hMPkk1npXJbUuBUpTdu0LXKYBHdtXsuComKHr53fftMPjDHU1NRQWVlJVVXV8T9P/OemXis5NAC4gZO1/t2NLbyMUEJ8m32EiIhIs2I6UAIM9ntZ1TeDO0oO8UFVHRZEnFf5Vf188fyuZxrZiQltNcSYVLzTRGx3u23zWlb4M04UCASaDHctDX6RXqusrKS6urpFW0Lato3f7ycpKQm/30+XXjadsiY0e368tyt2nJ+aYztP+Xs4UZym9oqISAeJ+UAJkOWNZ1mfbvzPoUoeK/+CkkCIOCDYxLn1r58b5+EH6Sl8r2sy8WojnrK9+yMHL7dtXseBl1dtYP691x0PfMFgU/9FG/P5fMfD3onBr/7PtLS0Rq9FOv+rryUkJDRoPX/0qcOMh5qvj1u2h7RzczlYupqayt34ks475e+j6zlE1VPvIiISW86KQAlgWxY3d0nmu2lJvHOslr8fq+Gjqjq21gSoNYZ4y6KPN47B/gSGJ/sYkeLDoyB52oKhL7dDbyvnpKUzderUUwp+fr8fu523zWzJPM/zB8zkYOmrfPqPHzEwdxm2p2FF3HECHCpdTdee1za61rbgwj76uyoiIh3nrAmU9WzL4soUH1em+Dp6KDHN5w23pZubX9Aabd6+fc5jzs/nnPb17SUp0aJPT9i+u/mQ3bnbUPoNfZTigumsf3kIPfr/kKTUHIwT4OihDykrXkxSak6TgdIYGJStQCkiIh3nrAuU0j6yelg4EUqUbtu8Hg/07hk9Ieq6UR5+uzTyY2E9+t1Cp66XUbJpPrs2Pkxd9V5sOz68Jmfvmzgv+z+avC4uHq4aptUHRESk4yhQSpvol2WdtOXtps0bCkHfrOgJlCOHWTz+HFRWR54KkJL2dXKuWNzi97VtuOYKi+Sk6PkuREQk9qisIW0iu7dFsj/yOfVt3sNla1j/8hB2f/oYh/f+nUNla9i1cR6FK75O2dalTV5r23DZxdETohK9Fj/O87TqvFLLgk5JcMsEPd4tIiIdSxVKaRMJ8RbXjrB57lUn4nqUp9Pm9dhwxaUWXVKjJ1AC5A6xePt9i3UfGJxWCJbGwF23eEhRdVJERDqYZVqysJ7IaSg/aMj/WZC6QOu+r2XBo7M9ZPeOvgJ7bZ3hZ/NCfFxsXFcrb8+3GZOr6qSIiHS86PuJLFGjWxeLqd9p3b9ilgU3ftOOyjAJ4E2weOgnHnKHhKuKp7oylccGbwLM+qFHYVJERM4YqlBKm3Icwz2/C7G+yH2b17bhgh6wYHYc3oTob/Ou+8DhkaUhjhwN31ukqQH1uw5depHFT6Z4yOgS/fcvIiKxQ4FS2lxtneGe/w6xYfPpt3ltG87PhId/Gkdqp9gJU4Gg4e33DS+94bBpu6GpzX5SksJzRq8b5aFvCxZJFxERaW8KlNIu6gKGJ5c5/PVVB9uixdVKywo/fDJqmMV/3uwh2R+7gSoYNOwqg70HDKFQeHH4C86z6HoODbZyFBEROdMoUEq7+mSrw8K/hPh0+5dt3KbUH+vZHW6b6GH44OicMykiInI2UKCUDvHZLsNr7zp8stVhWwkE/v9JcI8n3Nq+6Gs2I4daDOhnqTonIiJyhlOglA4Xcgy1teE2eKIXPB4FSBERkWiiQCkiIiIirmhimoiIiIi4okApIiIiIq4oUIqIiIiIKwqUIiIiIuKKAqWIiIiIuKJAKSIiIiKuKFCKiIiIiCsKlCIiIiLiigKliIiIiLiiQCkiIiIirihQioiIiIgrCpQiIiIi4ooCpYiIiIi4okApIiIiIq4oUIqIiIiIKwqUIiIiIuKKAqWIiIiIuKJAKSIiIiKuKFCKiIiIiCsKlCIiIiLiigKliIiIiLiiQCkiIiIirihQioiIiIgrCpQiIiIi4ooCpYiIiIi4okApIiIiIq4oUIqIiIiIKwqUIiIiIuKKAqWIiIiIuKJAKSIiIiKuKFCKiIiIiCsKlCIiIiLiigKliIiIiLiiQCkiIiIirihQioiIiIgrCpQiIiIi4ooCpYiIiIi48n+gz6rN8A6SsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x26ded3b4a30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying one sample\n",
    "plt.clf()\n",
    "visualize(training_set[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513751f1",
   "metadata": {},
   "source": [
    "# Trial 1 (No Upsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a430194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 500\n",
    "# maximum length of the tokenized vector\n",
    "max_len = 100 \n",
    "\n",
    "# build vocabulary from training set only for nodes characters\n",
    "all_nodes = [s[0] for s in training_set]\n",
    "\n",
    "#training tokenizer\n",
    "tokenizer = Tokenizer(num_words = max_vocab)\n",
    "tokenizer.fit_on_texts(all_nodes)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa94519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "def prepare_single_batch(samples):\n",
    "  #nodes characters array\n",
    "  sample_nodes = [s[0] for s in samples]\n",
    "  #tokenizing the sample nodes\n",
    "  sample_nodes = tokenizer.texts_to_sequences(sample_nodes)\n",
    "  #pad_sequences for each sample node with post padding and post truncating \n",
    "  sample_nodes = pad_sequences(sample_nodes, padding='post', truncating = 'pre')\n",
    "  #maximum length of nodes \n",
    "  max_nodes_len = np.shape(sample_nodes)[1]\n",
    "  #defining edges\n",
    "  edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]\n",
    "  edges = [e for e in edges if len(e) > 0]\n",
    "\n",
    "  #array definition for segmented_ids\n",
    "  node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]\n",
    "  \n",
    "  #reshaping as 1 vector\n",
    "  all_nodes = np.reshape(sample_nodes, -1)\n",
    "  #concatenating all the edges as size [total_edges ,2]\n",
    "  all_edges = np.concatenate(edges)\n",
    "\n",
    "  node_to_graph = np.reshape(node_to_graph, -1)\n",
    "  #returns a dictionary of features(data,edges,node2grah) and label\n",
    "  return {\n",
    "      'data': all_nodes,\n",
    "      'edges': all_edges,\n",
    "      'node2grah': node_to_graph,\n",
    "  }, np.array([s[2] for s in samples]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc96a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
    "    while True:\n",
    "      dataset = list(dataset)\n",
    "      if shuffle:\n",
    "        #randomly shuffling\n",
    "        random.shuffle(dataset)\n",
    "      \n",
    "      #length of dataset\n",
    "      l = len(dataset)\n",
    "      #for creating batches from given dataset\n",
    "      for ndx in range(0, l, batch_size):\n",
    "        #creating batch samples with given batch_size\n",
    "        batch_samples = dataset[ndx:min(ndx + batch_size, l)]\n",
    "        #returning a generator with prepared batches\n",
    "        yield prepare_single_batch(batch_samples)\n",
    "        \n",
    "      if not repeat:\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9ceb5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "Shape is (96,)\n",
      "edges\n",
      "Shape is (84, 2)\n",
      "node2grah\n",
      "Shape is (96,)\n",
      "label [0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# showing one batch:\n",
    "for train_batch in gen_batch(training_set, batch_size=4):\n",
    "    for k,v in train_batch[0].items():\n",
    "        print(k)        \n",
    "        print(\"Shape is \"+str(np.shape(v)))\n",
    "        pass\n",
    "    print('label', train_batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f7af7",
   "metadata": {},
   "source": [
    "## Trial_1.1 (template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50384a54",
   "metadata": {},
   "source": [
    "in this trial i will use the template to see the results and my expectation to get good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa6eed19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
      "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\n",
      "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 80)           40000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " gnn (GNN)                      (None, 32)           24384       ['embedding[0][0]',              \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]',                \n",
      "                                                                  'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n",
      " da)                                                              'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 64,417\n",
      "Trainable params: 64,417\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Input layer (tokenized text)\n",
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different.it is the total number of edges in this batch\n",
    "\n",
    "#Input for edge data\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "#Input for node2graph ids\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "#embedding over data with each token as a vector\n",
    "embeded = Embedding(tokenizer.num_words, 80)(data)\n",
    "\n",
    "\n",
    "# number of graphs\n",
    "#calculating number of graphs\n",
    "num_graph = tf.reduce_max(node2graph)+1  \n",
    "\n",
    "#gnn_input layer with inputs as defined above\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "#defining hyperparameters for GNN layer\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"hidden_dim\"] = 32\n",
    "gnn_layer = GNN(params)  \n",
    "#outpur shape: [data_dimension,hidden layers]\n",
    "gnn_out = gnn_layer(gnn_input) \n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "#calculating segmented mean based on segment_ids\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )\n",
    "\n",
    "print('mean:', avg)\n",
    "\n",
    "#final dense layer with sigmoid\n",
    "pred = Dense(1, activation='sigmoid')(avg)\n",
    "#output shape: [batch_size,1]\n",
    "print('pred:', pred)\n",
    "\n",
    "#Building The Model \n",
    "#inputs is dictionary of data, edges, node2graph\n",
    "#output: prediction value from dense layer\n",
    "model = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da492609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model by using my adam optimizer and BinaryCrossentropy loss\n",
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "993a4061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/GatherV2_1_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_1_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgcn/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgcn/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/rgcn/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626/626 [==============================] - 11s 12ms/step - loss: 0.2575 - auc: 0.4549 - val_loss: 0.1887 - val_auc: 0.5996\n",
      "Epoch 2/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1946 - auc: 0.6123 - val_loss: 0.2072 - val_auc: 0.6502\n",
      "Epoch 3/30\n",
      "626/626 [==============================] - 7s 12ms/step - loss: 0.1881 - auc: 0.6577 - val_loss: 0.1871 - val_auc: 0.6509\n",
      "Epoch 4/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1850 - auc: 0.6759 - val_loss: 0.1780 - val_auc: 0.6868\n",
      "Epoch 5/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1820 - auc: 0.7017 - val_loss: 0.1715 - val_auc: 0.6965\n",
      "Epoch 6/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1804 - auc: 0.7091 - val_loss: 0.1727 - val_auc: 0.7049\n",
      "Epoch 7/30\n",
      "626/626 [==============================] - 8s 12ms/step - loss: 0.1790 - auc: 0.7149 - val_loss: 0.1842 - val_auc: 0.7155\n",
      "Epoch 8/30\n",
      "626/626 [==============================] - 7s 12ms/step - loss: 0.1767 - auc: 0.7320 - val_loss: 0.1751 - val_auc: 0.7263\n",
      "Epoch 9/30\n",
      "626/626 [==============================] - 7s 12ms/step - loss: 0.1755 - auc: 0.7337 - val_loss: 0.1696 - val_auc: 0.7213\n",
      "Epoch 10/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1748 - auc: 0.7391 - val_loss: 0.1841 - val_auc: 0.7267\n",
      "Epoch 11/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1725 - auc: 0.7520 - val_loss: 0.1715 - val_auc: 0.7309\n",
      "Epoch 12/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1737 - auc: 0.7498 - val_loss: 0.1684 - val_auc: 0.7354\n",
      "Epoch 13/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1723 - auc: 0.7527 - val_loss: 0.1733 - val_auc: 0.7558\n",
      "Epoch 14/30\n",
      "626/626 [==============================] - 7s 12ms/step - loss: 0.1716 - auc: 0.7543 - val_loss: 0.1649 - val_auc: 0.7563\n",
      "Epoch 15/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1712 - auc: 0.7561 - val_loss: 0.1679 - val_auc: 0.7483\n",
      "Epoch 16/30\n",
      "626/626 [==============================] - 7s 12ms/step - loss: 0.1727 - auc: 0.7512 - val_loss: 0.1703 - val_auc: 0.7425\n",
      "Epoch 17/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1699 - auc: 0.7624 - val_loss: 0.1719 - val_auc: 0.7464\n",
      "Epoch 18/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1695 - auc: 0.7683 - val_loss: 0.1704 - val_auc: 0.7509\n",
      "Epoch 19/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1697 - auc: 0.7696 - val_loss: 0.1688 - val_auc: 0.7528\n",
      "Epoch 20/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1679 - auc: 0.7749 - val_loss: 0.1663 - val_auc: 0.7670\n",
      "Epoch 21/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1687 - auc: 0.7720 - val_loss: 0.1660 - val_auc: 0.7573\n",
      "Epoch 22/30\n",
      "626/626 [==============================] - 7s 10ms/step - loss: 0.1681 - auc: 0.7745 - val_loss: 0.1678 - val_auc: 0.7765\n",
      "Epoch 23/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1685 - auc: 0.7781 - val_loss: 0.1739 - val_auc: 0.7538\n",
      "Epoch 24/30\n",
      "626/626 [==============================] - 7s 10ms/step - loss: 0.1683 - auc: 0.7714 - val_loss: 0.1659 - val_auc: 0.7674\n",
      "Epoch 25/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1674 - auc: 0.7786 - val_loss: 0.1661 - val_auc: 0.7614\n",
      "Epoch 26/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1667 - auc: 0.7790 - val_loss: 0.1680 - val_auc: 0.7629\n",
      "Epoch 27/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1658 - auc: 0.7827 - val_loss: 0.1641 - val_auc: 0.7726\n",
      "Epoch 28/30\n",
      "626/626 [==============================] - 8s 12ms/step - loss: 0.1649 - auc: 0.7865 - val_loss: 0.1706 - val_auc: 0.7553\n",
      "Epoch 29/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1654 - auc: 0.7886 - val_loss: 0.1650 - val_auc: 0.7646\n",
      "Epoch 30/30\n",
      "626/626 [==============================] - 7s 11ms/step - loss: 0.1661 - auc: 0.7848 - val_loss: 0.1628 - val_auc: 0.7753\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "#math.ceil: returns the smallest integral value greater than the number\n",
    "#no. of batches for training data\n",
    "num_batchs = math.ceil(len(training_set) / batch_size)\n",
    "#no. of batches for validation data\n",
    "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
    "hist = model.fit(\n",
    "    gen_batch(\n",
    "        training_set, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=30,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set, batch_size=32, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d72eef",
   "metadata": {},
   "source": [
    "- 78.5% training AUC\n",
    "- 77.5% validation AUC\n",
    "i think its a good start and we can still improve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb569662",
   "metadata": {},
   "source": [
    "# Trial 2.1 (Upsampling) (template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9ae36fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20df0ecfebb642429c974ae093bf244a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_set2 = read_sdf('train.sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33d0ea4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20936\\3096225700.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.unique(np.array(training_set2)[:,2],return_counts=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=object), array([23806,  1218], dtype=int64))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(training_set2)[:,2],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9ff110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCount=23806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "786006c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20936\\3167736592.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  unique, counts = np.unique(np.array(training_set2)[:,2], return_counts=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique, counts = np.unique(np.array(training_set2)[:,2], return_counts=True)\n",
    "\n",
    "sns.barplot(x=unique, y=counts)\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Counts of target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "217b5f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20936\\202474016.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = pd.DataFrame(np.array(training_set2)[:,:], columns = ['0', '1', 'target'])\n"
     ]
    }
   ],
   "source": [
    "#convert the data from List to DataFrame to make upsampling\n",
    "data = pd.DataFrame(np.array(training_set2)[:,:], columns = ['0', '1', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0334234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampling = data.copy()  #take a copy of dataframe\n",
    "class_0 = resampling[resampling['target']==0]   # all rows has target zero\n",
    "class_1 = resampling[resampling['target']==1]   # all rows has target one\n",
    "class_1_after = resample(class_1, replace=True,n_samples = maxCount)   \n",
    "data_upsampled = pd.concat([class_0, class_1_after])    #add the new rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf8425cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23806\n",
       "1    23806\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_upsampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e6fa91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHFCAYAAADv8c1wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvtUlEQVR4nO3de1RVdf7/8ddJLiLJSUVuhUqmpoGWaIh+85KKmuiYtarxG2nLUZOUIXXqa05lfksn7/Md09RvRRdNa0rrmw4japqOl5RiFCPT0sQC8YIHdCkg7t8fM+5fR7x8RPAc9PlY66zl/uz33vu9T4t4rc++4LAsyxIAAAAu6SZPNwAAAFATEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAXNaOHTv05JNPKioqSrVr19bNN9+stm3baurUqTp27Jin25MkLV68WLNnz/bIsY8dO6bHHntMISEhcjgcGjBgQIWatLQ0ORyOy36aNGlyzfu/HE9+t4A3cfBnVABcysKFC5WcnKwWLVooOTlZrVq1UllZmbZv366FCxeqTZs2WrZsmafbVGJiorKzs7V///5rfuxnnnlGc+fO1VtvvaWmTZuqfv36at68uVvN4cOH9cMPP7iNxcfH6+GHH9bYsWPtMX9/f91zzz3XpG9TnvxuAW/i4+kGAHivzZs3a+TIkerZs6eWL18uf39/e13Pnj01duxYpaene7BD75Cdna2mTZvqP//zPy9a07BhQzVs2LDCeGhoqDp06HDVPZSXl+vMmTNu/40AVC0uzwG4qMmTJ8vhcGjBggUX/GXs5+en/v3728tnz57V1KlTdeedd8rf318hISF64okndPDgQbftmjRpoiFDhlTYX9euXdW1a1d7ed26dXI4HPrggw80YcIERUREKCgoSD169NDu3bvdtluxYoV++uknt0td58ybN09t2rTRzTffrLp16+rOO+/U888/f9nzP3bsmJKTk3XrrbfKz89Pt99+uyZMmKCSkhJJ0v79++VwOLR69Wrl5OTYx123bt1l930hhw8ftmfzbr75ZoWEhOj+++/Xhg0b3OrOHXfq1Kl65ZVXFBUVJX9/f33xxReSpE8//VStW7eWv7+/br/9dv35z3/WxIkT3b4TSbIsS3PnztXdd9+tgIAA1atXTw8//LB+/PFH4+8WuJEw0wTggsrLy7V27VrFxsYqMjLSaJuRI0dqwYIFGjVqlBITE7V//3698MILWrdunb7++msFBwdXqpfnn39enTp10v/+7/+qqKhIzz33nPr166ecnBzVqlVLc+fO1fDhw/XDDz9UuFS4ZMkSJScna/To0Zo+fbpuuukm7d27V99+++0lj3n69Gl169ZNP/zwg15++WW1bt1aGzZs0JQpU5SVlaUVK1YoPDxcmzdvVnJyslwulxYtWiRJatWqVaXO89z9YS+99JLCwsJ04sQJLVu2TF27dtWaNWvcAqUk/c///I+aN2+u6dOnKygoSM2aNVN6eroGDhyozp07a+nSpTpz5oymT5+uQ4cOVTjeiBEjlJaWppSUFL322ms6duyYJk2apI4dO+qf//ynQkNDL/ndAjccCwAuID8/35JkPfbYY0b1OTk5liQrOTnZbXzr1q2WJOv555+3xxo3bmwNHjy4wj66dOlidenSxV7+4osvLEnWAw884Fb34YcfWpKszZs322N9+/a1GjduXGGfo0aNsm655Rajc/i1N954w5Jkffjhh27jr732miXJWrVqlVvfd9111xUfQ5L19NNPX3T9mTNnrLKyMqt79+7Wgw8+aI/v27fPkmQ1bdrUKi0tddumffv2VmRkpFVSUmKPFRcXWw0aNLB+/b/8zZs3W5KsGTNmuG2fm5trBQQEWM8++6w9drHvFrjRcHkOQJU4d2no/Mtu9957r1q2bKk1a9ZUet+/vgQoSa1bt5Yk/fTTT5fd9t5779Xx48f129/+Vp9++qmOHDlidMy1a9cqMDBQDz/8sNv4ufO7mvO5lDfeeENt27ZV7dq15ePjI19fX61Zs0Y5OTkVavv37y9fX197+eTJk9q+fbsGDBggPz8/e/zmm29Wv3793Lb9/PPP5XA49Pjjj+vMmTP2JywsTG3atKn0JUbgekZoAnBBwcHBqlOnjvbt22dUf/ToUUlSeHh4hXURERH2+spo0KCB2/K5+6tOnTp12W2TkpL01ltv6aefftJDDz2kkJAQxcXFKSMj45LbHT16VGFhYRXu3wkJCZGPj89Vnc/FzJw5UyNHjlRcXJw+/vhjbdmyRdu2bVPv3r0veK7nf9eFhYWyLEuhoaEVas8fO3TokF3r6+vr9tmyZYtxuARuJNzTBOCCatWqpe7du+tvf/ubDh48qNtuu+2S9eeCTV5eXoXaX375xe1+ptq1a9s3U//akSNHKn3f06U8+eSTevLJJ3Xy5El9+eWXeumll5SYmKjvv/9ejRs3vuA2DRo00NatW2VZlltwKigo0JkzZ6qlz/fff19du3bVvHnz3MaLi4svWH9+oKtXr54cDscF71/Kz893Ww4ODpbD4dCGDRsueJM/T+EBFTHTBOCixo8fL8uyNGzYMJWWllZYX1ZWpv/7v/+TJN1///2S/vWL/9e2bdumnJwcde/e3R5r0qSJduzY4Vb3/fffuz0Rd6X8/f0vO/MUGBioPn36aMKECSotLdWuXbsuWtu9e3edOHFCy5cvdxt/99137fVVzeFwVAgrO3bs0ObNm422DwwMVLt27bR8+XK3/14nTpzQ559/7labmJgoy7L0888/q127dhU+MTExdq3JdwvcCJhpAnBR8fHxmjdvnpKTkxUbG6uRI0fqrrvuUllZmb755hstWLBA0dHR6tevn1q0aKHhw4frL3/5i2666Sb16dPHfnouMjJSzzzzjL3fpKQkPf7440pOTtZDDz2kn376SVOnTr3ge4xMxcTE6JNPPtG8efMUGxurm266Se3atdOwYcMUEBCgTp06KTw8XPn5+ZoyZYqcTqfat29/0f098cQTev311zV48GDt379fMTEx2rhxoyZPnqwHHnhAPXr0qHSvF5OYmKj//u//1ksvvaQuXbpo9+7dmjRpkqKionTmzBmjfUyaNEl9+/ZVr1699Pvf/17l5eWaNm2abr75Zre3t3fq1EnDhw/Xk08+qe3bt6tz584KDAxUXl6eNm7cqJiYGI0cOVLSxb9b4Ibj0dvQAdQIWVlZ1uDBg61GjRpZfn5+VmBgoHXPPfdYL774olVQUGDXlZeXW6+99prVvHlzy9fX1woODrYef/xxKzc3121/Z8+etaZOnWrdfvvtVu3ata127dpZa9euvejTcx999JHb9ueeHnv77bftsWPHjlkPP/ywdcstt1gOh8N+Uuydd96xunXrZoWGhlp+fn5WRESE9cgjj1g7duy47HkfPXrUeuqpp6zw8HDLx8fHaty4sTV+/Hjr9OnTbnVV9fRcSUmJNW7cOOvWW2+1ateubbVt29Zavny5NXjwYLen186d/7Rp0y6432XLllkxMTGWn5+f1ahRI+tPf/qTlZKSYtWrV69C7VtvvWXFxcVZgYGBVkBAgNW0aVPriSeesLZv327XXOy7BW40/BkVALjOlZWV6e6779att96qVatWebodoMbi8hwAXGeGDh2qnj172pcj33jjDeXk5OjPf/6zp1sDajRCEwBcZ4qLizVu3DgdPnxYvr6+atu2rVauXFkt92EBNxIuzwEAABjglQMAAAAGCE0AAAAGCE0AAAAGuBG8Cp09e1a//PKL6tatW+HPGwAAAO9kWZaKi4sVERGhm266+HwSoakK/fLLL4qMjPR0GwAAoBJyc3Mv+Xc2CU1VqG7dupL+9aUHBQV5uBsAAGCiqKhIkZGR9u/xiyE0VaFzl+SCgoIITQAA1DCXu7WGG8EBAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAM+Hi6AVyZ2D+86+kWAK+UOe0JT7dw1Q5MivF0C4BXavTiTk+3IImZJgAAACOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAOEJgAAAAMeDU1TpkxR+/btVbduXYWEhGjAgAHavXu3W41lWZo4caIiIiIUEBCgrl27ateuXW41JSUlGj16tIKDgxUYGKj+/fvr4MGDbjWFhYVKSkqS0+mU0+lUUlKSjh8/7lZz4MAB9evXT4GBgQoODlZKSopKS0ur5dwBAEDN4tHQtH79ej399NPasmWLMjIydObMGSUkJOjkyZN2zdSpUzVz5kzNmTNH27ZtU1hYmHr27Kni4mK7JjU1VcuWLdOSJUu0ceNGnThxQomJiSovL7drBg0apKysLKWnpys9PV1ZWVlKSkqy15eXl6tv3746efKkNm7cqCVLlujjjz/W2LFjr82XAQAAvJrDsizL002cc/jwYYWEhGj9+vXq3LmzLMtSRESEUlNT9dxzz0n616xSaGioXnvtNY0YMUIul0sNGzbUe++9p0cffVSS9MsvvygyMlIrV65Ur169lJOTo1atWmnLli2Ki4uTJG3ZskXx8fH67rvv1KJFC/3tb39TYmKicnNzFRERIUlasmSJhgwZooKCAgUFBV22/6KiIjmdTrlcLqP6yoj9w7vVsl+gpsuc9oSnW7hqBybFeLoFwCs1enFnte7f9Pe3V93T5HK5JEn169eXJO3bt0/5+flKSEiwa/z9/dWlSxdt2rRJkpSZmamysjK3moiICEVHR9s1mzdvltPptAOTJHXo0EFOp9OtJjo62g5MktSrVy+VlJQoMzPzgv2WlJSoqKjI7QMAAK5PXhOaLMvSmDFj9B//8R+Kjo6WJOXn50uSQkND3WpDQ0Ptdfn5+fLz81O9evUuWRMSElLhmCEhIW415x+nXr168vPzs2vON2XKFPseKafTqcjIyCs9bQAAUEN4TWgaNWqUduzYoQ8++KDCOofD4bZsWVaFsfOdX3Oh+srU/Nr48ePlcrnsT25u7iV7AgAANZdXhKbRo0frs88+0xdffKHbbrvNHg8LC5OkCjM9BQUF9qxQWFiYSktLVVhYeMmaQ4cOVTju4cOH3WrOP05hYaHKysoqzECd4+/vr6CgILcPAAC4Pnk0NFmWpVGjRumTTz7R2rVrFRUV5bY+KipKYWFhysjIsMdKS0u1fv16dezYUZIUGxsrX19ft5q8vDxlZ2fbNfHx8XK5XPrqq6/smq1bt8rlcrnVZGdnKy8vz65ZtWqV/P39FRsbW/UnDwAAahQfTx786aef1uLFi/Xpp5+qbt269kyP0+lUQECAHA6HUlNTNXnyZDVr1kzNmjXT5MmTVadOHQ0aNMiuHTp0qMaOHasGDRqofv36GjdunGJiYtSjRw9JUsuWLdW7d28NGzZM8+fPlyQNHz5ciYmJatGihSQpISFBrVq1UlJSkqZNm6Zjx45p3LhxGjZsGDNIAADAs6Fp3rx5kqSuXbu6jb/99tsaMmSIJOnZZ5/VqVOnlJycrMLCQsXFxWnVqlWqW7euXT9r1iz5+PjokUce0alTp9S9e3elpaWpVq1ads2iRYuUkpJiP2XXv39/zZkzx15fq1YtrVixQsnJyerUqZMCAgI0aNAgTZ8+vZrOHgAA1CRe9Z6mmo73NAGew3uagOsX72kCAACoQQhNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABghNAAAABjwamr788kv169dPERERcjgcWr58udv6IUOGyOFwuH06dOjgVlNSUqLRo0crODhYgYGB6t+/vw4ePOhWU1hYqKSkJDmdTjmdTiUlJen48eNuNQcOHFC/fv0UGBio4OBgpaSkqLS0tDpOGwAA1EAeDU0nT55UmzZtNGfOnIvW9O7dW3l5efZn5cqVbutTU1O1bNkyLVmyRBs3btSJEyeUmJio8vJyu2bQoEHKyspSenq60tPTlZWVpaSkJHt9eXm5+vbtq5MnT2rjxo1asmSJPv74Y40dO7bqTxoAANRIPp48eJ8+fdSnT59L1vj7+yssLOyC61wul958802999576tGjhyTp/fffV2RkpFavXq1evXopJydH6enp2rJli+Li4iRJCxcuVHx8vHbv3q0WLVpo1apV+vbbb5Wbm6uIiAhJ0owZMzRkyBC9+uqrCgoKqsKzBgAANZHX39O0bt06hYSEqHnz5ho2bJgKCgrsdZmZmSorK1NCQoI9FhERoejoaG3atEmStHnzZjmdTjswSVKHDh3kdDrdaqKjo+3AJEm9evVSSUmJMjMzL9pbSUmJioqK3D4AAOD65NWhqU+fPlq0aJHWrl2rGTNmaNu2bbr//vtVUlIiScrPz5efn5/q1avntl1oaKjy8/PtmpCQkAr7DgkJcasJDQ11W1+vXj35+fnZNRcyZcoU+z4pp9OpyMjIqzpfAADgvTx6ee5yHn30Ufvf0dHRateunRo3bqwVK1Zo4MCBF93Osiw5HA57+df/vpqa840fP15jxoyxl4uKighOAABcp7x6pul84eHhaty4sfbs2SNJCgsLU2lpqQoLC93qCgoK7JmjsLAwHTp0qMK+Dh8+7FZz/oxSYWGhysrKKsxA/Zq/v7+CgoLcPgAA4PpUo0LT0aNHlZubq/DwcElSbGysfH19lZGRYdfk5eUpOztbHTt2lCTFx8fL5XLpq6++smu2bt0ql8vlVpOdna28vDy7ZtWqVfL391dsbOy1ODUAAODlPHp57sSJE9q7d6+9vG/fPmVlZal+/fqqX7++Jk6cqIceekjh4eHav3+/nn/+eQUHB+vBBx+UJDmdTg0dOlRjx45VgwYNVL9+fY0bN04xMTH203QtW7ZU7969NWzYMM2fP1+SNHz4cCUmJqpFixaSpISEBLVq1UpJSUmaNm2ajh07pnHjxmnYsGHMHgEAAEkeDk3bt29Xt27d7OVz9wcNHjxY8+bN086dO/Xuu+/q+PHjCg8PV7du3bR06VLVrVvX3mbWrFny8fHRI488olOnTql79+5KS0tTrVq17JpFixYpJSXFfsquf//+bu+GqlWrllasWKHk5GR16tRJAQEBGjRokKZPn17dXwEAAKghHJZlWZ5u4npRVFQkp9Mpl8tVbTNUsX94t1r2C9R0mdOe8HQLV+3ApBhPtwB4pUYv7qzW/Zv+/q5R9zQBAAB4CqEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAAKEJAADAQKVC09dff62dO///i6Y+/fRTDRgwQM8//7xKS0urrDkAAABvUanQNGLECH3//feSpB9//FGPPfaY6tSpo48++kjPPvtslTYIAADgDSoVmr7//nvdfffdkqSPPvpInTt31uLFi5WWlqaPP/64KvsDAADwCpUKTZZl6ezZs5Kk1atX64EHHpAkRUZG6siRI1XXHQAAgJeoVGhq166dXnnlFb333ntav369+vbtK0nat2+fQkNDq7RBAAAAb1Cp0DRr1ix9/fXXGjVqlCZMmKA77rhDkvTXv/5VHTt2rNIGAQAAvIFPZTZq06aN29Nz50ybNk0+PpXaJQAAgFer1EzT7bffrqNHj1YYP336tJo3b37VTQEAAHibSoWm/fv3q7y8vMJ4SUmJDh48eNVNAQAAeJsrupb22Wef2f/++9//LqfTaS+Xl5drzZo1ioqKqrruAAAAvMQVhaYBAwZIkhwOhwYPHuy2ztfXV02aNNGMGTOqrDkAAABvcUWh6dy7maKiorRt2zYFBwdXS1MAAADeplKPuu3bt6+q+wAAAPBqlX4/wJo1a7RmzRoVFBTYM1DnvPXWW1fdGAAAgDepVGh6+eWXNWnSJLVr107h4eFyOBxV3RcAAIBXqVRoeuONN5SWlqakpKSq7gcAAMArVeo9TaWlpfy5FAAAcEOpVGj63e9+p8WLF1d1LwAAAF6rUpfnTp8+rQULFmj16tVq3bq1fH193dbPnDmzSpoDAADwFpUKTTt27NDdd98tScrOznZbx03hAADgelSp0PTFF19UdR8AAABerVL3NAEAANxoKjXT1K1bt0tehlu7dm2lGwIAAPBGlQpN5+5nOqesrExZWVnKzs6u8Id8AQAArgeVCk2zZs264PjEiRN14sSJq2oIAADAG1XpPU2PP/44f3cOAABcl6o0NG3evFm1a9euyl0CAAB4hUpdnhs4cKDbsmVZysvL0/bt2/XCCy9USWMAAADepFKhyel0ui3fdNNNatGihSZNmqSEhIQqaQwAAMCbVCo0vf3221XdBwAAgFerVGg6JzMzUzk5OXI4HGrVqpXuueeequoLAADAq1QqNBUUFOixxx7TunXrdMstt8iyLLlcLnXr1k1LlixRw4YNq7pPAAAAj6rU03OjR49WUVGRdu3apWPHjqmwsFDZ2dkqKipSSkpKVfcIAADgcZWaaUpPT9fq1avVsmVLe6xVq1Z6/fXXuREcAABclyo103T27Fn5+vpWGPf19dXZs2evuikAAABvU6nQdP/99+v3v/+9fvnlF3vs559/1jPPPKPu3btXWXMAAADeolKhac6cOSouLlaTJk3UtGlT3XHHHYqKilJxcbH+8pe/VHWPAAAAHlepe5oiIyP19ddfKyMjQ999950sy1KrVq3Uo0ePqu4PAADAK1zRTNPatWvVqlUrFRUVSZJ69uyp0aNHKyUlRe3bt9ddd92lDRs2VEujAAAAnnRFoWn27NkaNmyYgoKCKqxzOp0aMWKEZs6cWWXNAQAAeIsrCk3//Oc/1bt374uuT0hIUGZm5lU3BQAA4G2uKDQdOnTogq8aOMfHx0eHDx++6qYAAAC8zRWFpltvvVU7d+686PodO3YoPDz8qpsCAADwNlcUmh544AG9+OKLOn36dIV1p06d0ksvvaTExMQqaw4AAMBbXNErB/74xz/qk08+UfPmzTVq1Ci1aNFCDodDOTk5ev3111VeXq4JEyZUV68AAAAec0WhKTQ0VJs2bdLIkSM1fvx4WZYlSXI4HOrVq5fmzp2r0NDQamkUAADAk6745ZaNGzfWypUrVVhYqL1798qyLDVr1kz16tWrjv4AAAC8QqXeCC5J9erVU/v27auyFwAAAK9Vqb89BwAAcKMhNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABjwaGj68ssv1a9fP0VERMjhcGj58uVu6y3L0sSJExUREaGAgAB17dpVu3btcqspKSnR6NGjFRwcrMDAQPXv318HDx50qyksLFRSUpKcTqecTqeSkpJ0/Phxt5oDBw6oX79+CgwMVHBwsFJSUlRaWlodpw0AAGogj4amkydPqk2bNpozZ84F10+dOlUzZ87UnDlztG3bNoWFhalnz54qLi62a1JTU7Vs2TItWbJEGzdu1IkTJ5SYmKjy8nK7ZtCgQcrKylJ6errS09OVlZWlpKQke315ebn69u2rkydPauPGjVqyZIk+/vhjjR07tvpOHgAA1CiVfiN4VejTp4/69OlzwXWWZWn27NmaMGGCBg4cKEl65513FBoaqsWLF2vEiBFyuVx688039d5776lHjx6SpPfff1+RkZFavXq1evXqpZycHKWnp2vLli2Ki4uTJC1cuFDx8fHavXu3WrRooVWrVunbb79Vbm6uIiIiJEkzZszQkCFD9OqrryooKOgafBsAAMCbee09Tfv27VN+fr4SEhLsMX9/f3Xp0kWbNm2SJGVmZqqsrMytJiIiQtHR0XbN5s2b5XQ67cAkSR06dJDT6XSriY6OtgOTJPXq1UslJSXKzMy8aI8lJSUqKipy+wAAgOuT14am/Px8SVJoaKjbeGhoqL0uPz9ffn5+Ff5Y8Pk1ISEhFfYfEhLiVnP+cerVqyc/Pz+75kKmTJli3yfldDoVGRl5hWcJAABqCq8NTec4HA63ZcuyKoyd7/yaC9VXpuZ848ePl8vlsj+5ubmX7AsAANRcXhuawsLCJKnCTE9BQYE9KxQWFqbS0lIVFhZesubQoUMV9n/48GG3mvOPU1hYqLKysgozUL/m7++voKAgtw8AALg+eW1oioqKUlhYmDIyMuyx0tJSrV+/Xh07dpQkxcbGytfX160mLy9P2dnZdk18fLxcLpe++uoru2br1q1yuVxuNdnZ2crLy7NrVq1aJX9/f8XGxlbreQIAgJrBo0/PnThxQnv37rWX9+3bp6ysLNWvX1+NGjVSamqqJk+erGbNmqlZs2aaPHmy6tSpo0GDBkmSnE6nhg4dqrFjx6pBgwaqX7++xo0bp5iYGPtpupYtW6p3794aNmyY5s+fL0kaPny4EhMT1aJFC0lSQkKCWrVqpaSkJE2bNk3Hjh3TuHHjNGzYMGaPAACAJA+Hpu3bt6tbt2728pgxYyRJgwcPVlpamp599lmdOnVKycnJKiwsVFxcnFatWqW6deva28yaNUs+Pj565JFHdOrUKXXv3l1paWmqVauWXbNo0SKlpKTYT9n179/f7d1QtWrV0ooVK5ScnKxOnTopICBAgwYN0vTp06v7KwAAADWEw7Isy9NNXC+KiorkdDrlcrmqbYYq9g/vVst+gZouc9oTnm7hqh2YFOPpFgCv1OjFndW6f9Pf3157TxMAAIA3ITQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAYIDQBAAAY8OrQNHHiRDkcDrdPWFiYvd6yLE2cOFEREREKCAhQ165dtWvXLrd9lJSUaPTo0QoODlZgYKD69++vgwcPutUUFhYqKSlJTqdTTqdTSUlJOn78+LU4RQAAUEN4dWiSpLvuukt5eXn2Z+fOnfa6qVOnaubMmZozZ462bdumsLAw9ezZU8XFxXZNamqqli1bpiVLlmjjxo06ceKEEhMTVV5ebtcMGjRIWVlZSk9PV3p6urKyspSUlHRNzxMAAHg3H083cDk+Pj5us0vnWJal2bNna8KECRo4cKAk6Z133lFoaKgWL16sESNGyOVy6c0339R7772nHj16SJLef/99RUZGavXq1erVq5dycnKUnp6uLVu2KC4uTpK0cOFCxcfHa/fu3WrRosW1O1kAAOC1vH6mac+ePYqIiFBUVJQee+wx/fjjj5Kkffv2KT8/XwkJCXatv7+/unTpok2bNkmSMjMzVVZW5lYTERGh6Ohou2bz5s1yOp12YJKkDh06yOl02jUXU1JSoqKiIrcPAAC4Pnl1aIqLi9O7776rv//971q4cKHy8/PVsWNHHT16VPn5+ZKk0NBQt21CQ0Ptdfn5+fLz81O9evUuWRMSElLh2CEhIXbNxUyZMsW+D8rpdCoyMrLS5woAALybV4emPn366KGHHlJMTIx69OihFStWSPrXZbhzHA6H2zaWZVUYO9/5NReqN9nP+PHj5XK57E9ubu5lzwkAANRMXh2azhcYGKiYmBjt2bPHvs/p/NmggoICe/YpLCxMpaWlKiwsvGTNoUOHKhzr8OHDFWaxzufv76+goCC3DwAAuD7VqNBUUlKinJwchYeHKyoqSmFhYcrIyLDXl5aWav369erYsaMkKTY2Vr6+vm41eXl5ys7Otmvi4+Plcrn01Vdf2TVbt26Vy+WyawAAALz66blx48apX79+atSokQoKCvTKK6+oqKhIgwcPlsPhUGpqqiZPnqxmzZqpWbNmmjx5surUqaNBgwZJkpxOp4YOHaqxY8eqQYMGql+/vsaNG2df7pOkli1bqnfv3ho2bJjmz58vSRo+fLgSExN5cg4AANi8OjQdPHhQv/3tb3XkyBE1bNhQHTp00JYtW9S4cWNJ0rPPPqtTp04pOTlZhYWFiouL06pVq1S3bl17H7NmzZKPj48eeeQRnTp1St27d1daWppq1apl1yxatEgpKSn2U3b9+/fXnDlzru3JAgAAr+awLMvydBPXi6KiIjmdTrlcrmq7vyn2D+9Wy36Bmi5z2hOebuGqHZgU4+kWAK/U6MWdly+6Cqa/v2vUPU0AAACeQmgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGg6z9y5cxUVFaXatWsrNjZWGzZs8HRLAADACxCafmXp0qVKTU3VhAkT9M033+i+++5Tnz59dODAAU+3BgAAPIzQ9CszZ87U0KFD9bvf/U4tW7bU7NmzFRkZqXnz5nm6NQAA4GGEpn8rLS1VZmamEhIS3MYTEhK0adMmD3UFAAC8hY+nG/AWR44cUXl5uUJDQ93GQ0NDlZ+ff8FtSkpKVFJSYi+7XC5JUlFRUbX1WV5yqtr2DdRk1flzd60Uny73dAuAV6run+9z+7cs65J1hKbzOBwOt2XLsiqMnTNlyhS9/PLLFcYjIyOrpTcAF+f8y1OebgFAdZnivCaHKS4ultN58WMRmv4tODhYtWrVqjCrVFBQUGH26Zzx48drzJgx9vLZs2d17NgxNWjQ4KJBC9ePoqIiRUZGKjc3V0FBQZ5uB0AV4uf7xmJZloqLixUREXHJOkLTv/n5+Sk2NlYZGRl68MEH7fGMjAz95je/ueA2/v7+8vf3dxu75ZZbqrNNeKGgoCD+pwpcp/j5vnFcaobpHELTr4wZM0ZJSUlq166d4uPjtWDBAh04cEBPPcW0PwAANzpC0688+uijOnr0qCZNmqS8vDxFR0dr5cqVaty4sadbAwAAHkZoOk9ycrKSk5M93QZqAH9/f7300ksVLtECqPn4+caFOKzLPV8HAAAAXm4JAABggtAEAABggNAEAABggNAEAABggNAEVMLcuXMVFRWl2rVrKzY2Vhs2bPB0SwCqwJdffql+/fopIiJCDodDy5cv93RL8CKEJuAKLV26VKmpqZowYYK++eYb3XffferTp48OHDjg6dYAXKWTJ0+qTZs2mjNnjqdbgRfilQPAFYqLi1Pbtm01b948e6xly5YaMGCApkyZ4sHOAFQlh8OhZcuWacCAAZ5uBV6CmSbgCpSWliozM1MJCQlu4wkJCdq0aZOHugIAXAuEJuAKHDlyROXl5QoNDXUbDw0NVX5+voe6AgBcC4QmoBIcDofbsmVZFcYAANcXQhNwBYKDg1WrVq0Ks0oFBQUVZp8AANcXQhNwBfz8/BQbG6uMjAy38YyMDHXs2NFDXQEArgUfTzcA1DRjxoxRUlKS2rVrp/j4eC1YsEAHDhzQU0895enWAFylEydOaO/evfbyvn37lJWVpfr166tRo0Ye7AzegFcOAJUwd+5cTZ06VXl5eYqOjtasWbPUuXNnT7cF4CqtW7dO3bp1qzA+ePBgpaWlXfuG4FUITQAAAAa4pwkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQnAdcfhcFzyM2TIEI/11qRJE82ePdtjxwdQefztOQDXnby8PPvfS5cu1Ysvvqjdu3fbYwEBAVe0v9LSUvn5+VVZfwBqJmaaAFx3wsLC7I/T6ZTD4bCXfX199dRTT+m2225TnTp1FBMTow8++MBt+65du2rUqFEaM2aMgoOD1bNnT0nSZ599pmbNmikgIEDdunXTO++8I4fDoePHj9vbbtq0SZ07d1ZAQIAiIyOVkpKikydP2vv96aef9Mwzz9izXgBqDkITgBvK6dOnFRsbq88//1zZ2dkaPny4kpKStHXrVre6d955Rz4+PvrHP/6h+fPna//+/Xr44Yc1YMAAZWVlacSIEZowYYLbNjt37lSvXr00cOBA7dixQ0uXLtXGjRs1atQoSdInn3yi2267TZMmTVJeXp7bjBgA78cf7AVwXUtLS1NqaqrbbND5+vbtq5YtW2r69OmS/jUj5HK59M0339g1//Vf/6UVK1Zo586d9tgf//hHvfrqqyosLNQtt9yiJ554QgEBAZo/f75ds3HjRnXp0kUnT55U7dq11aRJE6Wmpio1NbXKzxVA9eKeJgA3lPLycv3pT3/S0qVL9fPPP6ukpEQlJSUKDAx0q2vXrp3b8u7du9W+fXu3sXvvvddtOTMzU3v37tWiRYvsMcuydPbsWe3bt08tW7as4rMBcC0RmgDcUGbMmKFZs2Zp9uzZiomJUWBgoFJTU1VaWupWd36Isiyrwj1I50/Unz17ViNGjFBKSkqF4zZq1KiKzgCApxCaANxQNmzYoN/85jd6/PHHJf0r6OzZs+eys0B33nmnVq5c6Ta2fft2t+W2bdtq165duuOOOy66Hz8/P5WXl1eyewCexI3gAG4od9xxhzIyMrRp0ybl5ORoxIgRys/Pv+x2I0aM0HfffafnnntO33//vT788EOlpaVJkj0D9dxzz2nz5s16+umnlZWVpT179uizzz7T6NGj7f00adJEX375pX7++WcdOXKkWs4RQPUgNAG4obzwwgtq27atevXqpa5duyosLEwDBgy47HZRUVH661//qk8++UStW7fWvHnz7Kfn/P39JUmtW7fW+vXrtWfPHt13332655579MILLyg8PNzez6RJk7R//341bdpUDRs2rJZzBFA9eHoOACrp1Vdf1RtvvKHc3FxPtwLgGuCeJgAwNHfuXLVv314NGjTQP/7xD02bNs1+BxOA6x+hCQAM7dmzR6+88oqOHTumRo0aaezYsRo/fryn2wJwjXB5DgAAwAA3ggMAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABggNAEAABj4f4T8cYDg0XXIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='target', data=data_upsampled)\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Counts of Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20f8b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the upsampled DataFrame into list\n",
    "training_set2 = data_upsampled.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb76304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, validation_set = train_test_split(training_set2, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e629866b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x26d9904ea60>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying one sample\n",
    "plt.clf()\n",
    "visualize(training_set2[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "220c0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary size\n",
    "max_vocab = 500\n",
    "# maximum length of the tokenized vector\n",
    "max_len = 100 \n",
    "\n",
    "# build vocabulary from training set only for nodes characters\n",
    "all_nodes = [s[0] for s in training_set2]\n",
    "\n",
    "#training tokenizer\n",
    "tokenizer = Tokenizer(num_words = max_vocab)\n",
    "tokenizer.fit_on_texts(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c95c7119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "Shape is (176,)\n",
      "edges\n",
      "Shape is (120, 2)\n",
      "node2grah\n",
      "Shape is (176,)\n",
      "label [0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# showing one batch:\n",
    "for train_batch in gen_batch(training_set2, batch_size=4):\n",
    "    for k,v in train_batch[0].items():\n",
    "        print(k)  \n",
    "        print(\"Shape is \"+str(np.shape(v)))\n",
    "        pass\n",
    "    print('label', train_batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b1ee5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='gnn_1/StatefulPartitionedCall:0', description=\"created by layer 'gnn_1'\")\n",
      "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='tf.math.segment_mean_1/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_1'\")\n",
      "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_1/Sigmoid:0', description=\"created by layer 'dense_1'\")\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_6[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 80)           40000       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " gnn_1 (GNN)                    (None, 40)           34640       ['embedding_1[0][0]',            \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]',                \n",
      "                                                                  'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.segment_mean_1 (TFOpLa  (None, 40)          0           ['gnn_1[0][0]',                  \n",
      " mbda)                                                            'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            41          ['tf.math.segment_mean_1[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 74,681\n",
      "Trainable params: 74,681\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 80)(data)\n",
    "\n",
    "\n",
    "num_graph = tf.reduce_max(node2graph)+1  \n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"hidden_dim\"] = 40\n",
    "gnn_layer = GNN(params)  \n",
    "gnn_out = gnn_layer(gnn_input) \n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )\n",
    "\n",
    "print('mean:', avg)\n",
    "\n",
    "pred = Dense(1, activation='sigmoid')(avg)\n",
    "print('pred:', pred)\n",
    "\n",
    "model = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8736deb",
   "metadata": {},
   "source": [
    "i expect to get higher than without upsample so above 80 maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc3ab667",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26522a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgcn/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgcn/embedding_lookup_grad/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgcn/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265/1265 [==============================] - 15s 11ms/step - loss: 0.6165 - auc: 0.7211 - val_loss: 0.5914 - val_auc: 0.7556\n",
      "Epoch 2/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.5851 - auc: 0.7573 - val_loss: 0.5688 - val_auc: 0.7727\n",
      "Epoch 3/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.5706 - auc: 0.7728 - val_loss: 0.5690 - val_auc: 0.7785\n",
      "Epoch 4/30\n",
      "1265/1265 [==============================] - 13s 11ms/step - loss: 0.5604 - auc: 0.7840 - val_loss: 0.5533 - val_auc: 0.7891\n",
      "Epoch 5/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.5474 - auc: 0.7960 - val_loss: 0.5280 - val_auc: 0.8170\n",
      "Epoch 6/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.5264 - auc: 0.8153 - val_loss: 0.5163 - val_auc: 0.8279\n",
      "Epoch 7/30\n",
      "1265/1265 [==============================] - 13s 11ms/step - loss: 0.5110 - auc: 0.8285 - val_loss: 0.4933 - val_auc: 0.8431\n",
      "Epoch 8/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.4978 - auc: 0.8386 - val_loss: 0.4845 - val_auc: 0.8489\n",
      "Epoch 9/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.4837 - auc: 0.8484 - val_loss: 0.4689 - val_auc: 0.8610\n",
      "Epoch 10/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.4745 - auc: 0.8549 - val_loss: 0.4596 - val_auc: 0.8692\n",
      "Epoch 11/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.4643 - auc: 0.8614 - val_loss: 0.4562 - val_auc: 0.8671\n",
      "Epoch 12/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.4518 - auc: 0.8700 - val_loss: 0.4293 - val_auc: 0.8847\n",
      "Epoch 13/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.4418 - auc: 0.8759 - val_loss: 0.4547 - val_auc: 0.8807\n",
      "Epoch 14/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.4340 - auc: 0.8807 - val_loss: 0.4079 - val_auc: 0.8964\n",
      "Epoch 15/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.4214 - auc: 0.8887 - val_loss: 0.4081 - val_auc: 0.8970\n",
      "Epoch 16/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.4146 - auc: 0.8922 - val_loss: 0.4080 - val_auc: 0.9028\n",
      "Epoch 17/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.4068 - auc: 0.8966 - val_loss: 0.3919 - val_auc: 0.9069\n",
      "Epoch 18/30\n",
      "1265/1265 [==============================] - 13s 11ms/step - loss: 0.4012 - auc: 0.8999 - val_loss: 0.3860 - val_auc: 0.9126\n",
      "Epoch 19/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.3900 - auc: 0.9049 - val_loss: 0.4008 - val_auc: 0.9098\n",
      "Epoch 20/30\n",
      "1265/1265 [==============================] - 13s 10ms/step - loss: 0.3817 - auc: 0.9094 - val_loss: 0.3637 - val_auc: 0.9214\n",
      "Epoch 21/30\n",
      "1265/1265 [==============================] - 13s 10ms/step - loss: 0.3792 - auc: 0.9110 - val_loss: 0.3734 - val_auc: 0.9181\n",
      "Epoch 22/30\n",
      "1265/1265 [==============================] - 13s 10ms/step - loss: 0.3742 - auc: 0.9136 - val_loss: 0.3700 - val_auc: 0.9221\n",
      "Epoch 23/30\n",
      "1265/1265 [==============================] - 13s 11ms/step - loss: 0.3641 - auc: 0.9182 - val_loss: 0.3630 - val_auc: 0.9219\n",
      "Epoch 24/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.3580 - auc: 0.9209 - val_loss: 0.3348 - val_auc: 0.9338\n",
      "Epoch 25/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.3528 - auc: 0.9233 - val_loss: 0.3544 - val_auc: 0.9286\n",
      "Epoch 26/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.3477 - auc: 0.9259 - val_loss: 0.3206 - val_auc: 0.9400\n",
      "Epoch 27/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.3422 - auc: 0.9283 - val_loss: 0.3331 - val_auc: 0.9348\n",
      "Epoch 28/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.3344 - auc: 0.9314 - val_loss: 0.3328 - val_auc: 0.9352\n",
      "Epoch 29/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.3283 - auc: 0.9340 - val_loss: 0.3103 - val_auc: 0.9423\n",
      "Epoch 30/30\n",
      "1265/1265 [==============================] - 14s 11ms/step - loss: 0.3258 - auc: 0.9352 - val_loss: 0.3063 - val_auc: 0.9440\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_batchs = math.ceil(len(training_set) / batch_size)\n",
    "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
    "hist = model.fit(\n",
    "    gen_batch(\n",
    "        training_set, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=30,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set, batch_size=32, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ef8423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771/771 [==============================] - 3s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(\n",
    "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
    ")\n",
    "y_pred = np.reshape(y_pred, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02c809b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'label':y_pred})\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('Trial_2_1_temp.csv')\n",
    "\n",
    "#Kaggle 0.82645"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4531d5b",
   "metadata": {},
   "source": [
    "## Trial_2.2 (GGNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df301977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_5/StatefulPartitionedCall:0', description=\"created by layer 'gnn_5'\")\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_18 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_5 (TFOpLamb  ()                  0           ['input_18[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 80)           40000       ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " input_17 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  ()                  0           ['tf.math.reduce_max_5[0][0]']   \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " gnn_5 (GNN)                    (None, 64)           283136      ['embedding_5[0][0]',            \n",
      "                                                                  'input_17[0][0]',               \n",
      "                                                                  'input_18[0][0]',               \n",
      "                                                                  'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.segment_mean_5 (TFOpLa  (None, 64)          0           ['gnn_5[0][0]',                  \n",
      " mbda)                                                            'input_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 128)          8320        ['tf.math.segment_mean_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 64)           8256        ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            65          ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 339,777\n",
      "Trainable params: 339,777\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "\n",
    "embeded = Embedding(tokenizer.num_words, 80)(data)\n",
    "\n",
    "num_graph = tf.reduce_max(node2graph)+1  \n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"message_calculation_class\"] = 'GGNN'\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_layers\"] = 6\n",
    "\n",
    "\n",
    "gnn_layer = GNN(params) \n",
    "\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )\n",
    "\n",
    "l1 = Dense(128,activation='relu')(avg)\n",
    "l2 = Dense(64,activation='relu')(l1)\n",
    "pred = Dense(1, activation='sigmoid')(l2)\n",
    "\n",
    "\n",
    "model2 = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ebe0ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "77289f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "633/633 [==============================] - 19s 25ms/step - loss: 0.6190 - auc: 0.7094 - val_loss: 0.5755 - val_auc: 0.7760\n",
      "Epoch 2/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.5545 - auc: 0.7897 - val_loss: 0.5236 - val_auc: 0.8218\n",
      "Epoch 3/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.5136 - auc: 0.8263 - val_loss: 0.4836 - val_auc: 0.8518\n",
      "Epoch 4/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.4839 - auc: 0.8488 - val_loss: 0.4625 - val_auc: 0.8705\n",
      "Epoch 5/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.4471 - auc: 0.8733 - val_loss: 0.4217 - val_auc: 0.8898\n",
      "Epoch 6/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.4135 - auc: 0.8922 - val_loss: 0.3836 - val_auc: 0.9078\n",
      "Epoch 7/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.3792 - auc: 0.9097 - val_loss: 0.3650 - val_auc: 0.9182\n",
      "Epoch 8/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.3385 - auc: 0.9273 - val_loss: 0.3115 - val_auc: 0.9373\n",
      "Epoch 9/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.3059 - auc: 0.9399 - val_loss: 0.2723 - val_auc: 0.9509\n",
      "Epoch 10/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.2706 - auc: 0.9516 - val_loss: 0.2567 - val_auc: 0.9573\n",
      "Epoch 11/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.2473 - auc: 0.9583 - val_loss: 0.2441 - val_auc: 0.9634\n",
      "Epoch 12/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.2227 - auc: 0.9655 - val_loss: 0.2056 - val_auc: 0.9691\n",
      "Epoch 13/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.1999 - auc: 0.9711 - val_loss: 0.2026 - val_auc: 0.9704\n",
      "Epoch 14/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.1862 - auc: 0.9746 - val_loss: 0.1816 - val_auc: 0.9757\n",
      "Epoch 15/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.1720 - auc: 0.9779 - val_loss: 0.1800 - val_auc: 0.9746\n",
      "Epoch 16/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.1734 - auc: 0.9779 - val_loss: 0.1665 - val_auc: 0.9774\n",
      "Epoch 17/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.1533 - auc: 0.9815 - val_loss: 0.1564 - val_auc: 0.9801\n",
      "Epoch 18/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.1438 - auc: 0.9832 - val_loss: 0.1435 - val_auc: 0.9821\n",
      "Epoch 19/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.1337 - auc: 0.9854 - val_loss: 0.1503 - val_auc: 0.9814\n",
      "Epoch 20/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.1261 - auc: 0.9869 - val_loss: 0.1622 - val_auc: 0.9803\n",
      "Epoch 21/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.1228 - auc: 0.9872 - val_loss: 0.1251 - val_auc: 0.9871\n",
      "Epoch 22/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.1222 - auc: 0.9877 - val_loss: 0.1349 - val_auc: 0.9854\n",
      "Epoch 23/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.1255 - auc: 0.9874 - val_loss: 0.1242 - val_auc: 0.9864\n",
      "Epoch 24/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.1109 - auc: 0.9896 - val_loss: 0.1148 - val_auc: 0.9882\n",
      "Epoch 25/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.1028 - auc: 0.9906 - val_loss: 0.1365 - val_auc: 0.9858\n",
      "Epoch 26/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.0969 - auc: 0.9915 - val_loss: 0.1319 - val_auc: 0.9869\n",
      "Epoch 27/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0925 - auc: 0.9920Restoring model weights from the end of the best epoch: 24.\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.0925 - auc: 0.9920 - val_loss: 0.1445 - val_auc: 0.9886\n",
      "Epoch 27: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_batchs = math.ceil(len(training_set) / batch_size)\n",
    "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1,restore_best_weights=True)\n",
    "\n",
    "hist = model2.fit(\n",
    "    gen_batch(\n",
    "        training_set, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=50,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set, batch_size=64, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "    verbose=1,callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a69fdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "#make a prediction by using the model\n",
    "y_pred_2 = model2.predict(\n",
    "    gen_batch(testing_set, batch_size=64, shuffle=False)\n",
    ")\n",
    "y_pred_2 = np.reshape(y_pred_2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "90f47161",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'label':y_pred_2})\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('trial_2_GGNN2noDrop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4278e1d",
   "metadata": {},
   "source": [
    "kaggle 0.86696 it did very well i think it still can do better with some tunning but i will try other mechanisms first then i will tune the best of them but first i want to try randomOverSample and see if it does better on same model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e928f9",
   "metadata": {},
   "source": [
    "# Trial 3.1 (randomOverSample)(GGNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "71ee7f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dad60bb0fa46719142131ab5e2793a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_set3 = read_sdf('train.sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f1e7d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20936\\2961470663.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  unique, counts = np.unique(np.array(training_set3)[:,2], return_counts=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique, counts = np.unique(np.array(training_set3)[:,2], return_counts=True)\n",
    "\n",
    "sns.barplot(x=unique, y=counts)\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Counts of target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b4e11d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20936\\833739829.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data2 = pd.DataFrame(np.array(training_set3)[:,:], columns = ['0', '1', 'target'])\n"
     ]
    }
   ],
   "source": [
    "#convert the data from List to DataFrame to make upsampling\n",
    "data2 = pd.DataFrame(np.array(training_set3)[:,:], columns = ['0', '1', 'target'])\n",
    "data2['target'] = data2['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a874b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "resampling = data2.copy()\n",
    "X_resampled, y_resampled = ros.fit_resample(resampling.drop('target', axis=1), resampling['target'])\n",
    "data_upsampledR = pd.concat([X_resampled, y_resampled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6dbffab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23806\n",
       "1    23806\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_upsampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1441fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the upsampled DataFrame into list\n",
    "training_set3 = data_upsampled.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "13bc5578",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set3, validation_set3 = train_test_split(training_set3, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "85ab6646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary size\n",
    "max_vocab = 500\n",
    "# maximum length of the tokenized vector\n",
    "max_len = 100 \n",
    "\n",
    "# build vocabulary from training set only for nodes characters\n",
    "all_nodes3 = [s[0] for s in training_set3]\n",
    "\n",
    "#training tokenizer\n",
    "tokenizer3 = Tokenizer(num_words = max_vocab)\n",
    "tokenizer3.fit_on_texts(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f518b05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_6/StatefulPartitionedCall:0', description=\"created by layer 'gnn_6'\")\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_19 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_6 (TFOpLamb  ()                  0           ['input_21[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 80)           40000       ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  ()                  0           ['tf.math.reduce_max_6[0][0]']   \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " gnn_6 (GNN)                    (None, 64)           283136      ['embedding_6[0][0]',            \n",
      "                                                                  'input_20[0][0]',               \n",
      "                                                                  'input_21[0][0]',               \n",
      "                                                                  'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.segment_mean_6 (TFOpLa  (None, 64)          0           ['gnn_6[0][0]',                  \n",
      " mbda)                                                            'input_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 128)          8320        ['tf.math.segment_mean_6[0][0]'] \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 64)           8256        ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1)            65          ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 339,777\n",
      "Trainable params: 339,777\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "\n",
    "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
    "\n",
    "num_graph = tf.reduce_max(node2graph)+1  \n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"message_calculation_class\"] = 'GGNN'\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_layers\"] = 6\n",
    "\n",
    "\n",
    "gnn_layer = GNN(params) \n",
    "\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )\n",
    "\n",
    "l1 = Dense(128,activation='relu')(avg)\n",
    "l2 = Dense(64,activation='relu')(l1)\n",
    "pred = Dense(1, activation='sigmoid')(l2)\n",
    "\n",
    "\n",
    "model3 = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f0308b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "90fc4427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "633/633 [==============================] - 17s 26ms/step - loss: 0.0372 - auc: 0.9979 - val_loss: 0.0800 - val_auc: 0.9924 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.0366 - auc: 0.9980 - val_loss: 0.0796 - val_auc: 0.9924 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.0359 - auc: 0.9981 - val_loss: 0.0824 - val_auc: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.0334 - auc: 0.9983 - val_loss: 0.0739 - val_auc: 0.9931 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.0344 - auc: 0.9982 - val_loss: 0.0772 - val_auc: 0.9926 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0340 - auc: 0.9982\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.0340 - auc: 0.9982 - val_loss: 0.0807 - val_auc: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.0312 - auc: 0.9985 - val_loss: 0.0790 - val_auc: 0.9928 - lr: 5.0000e-05\n",
      "Epoch 8/50\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.0304 - auc: 0.9984 - val_loss: 0.0750 - val_auc: 0.9929 - lr: 5.0000e-05\n",
      "Epoch 9/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0296 - auc: 0.9987Restoring model weights from the end of the best epoch: 4.\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.0296 - auc: 0.9987 - val_loss: 0.0809 - val_auc: 0.9923 - lr: 5.0000e-05\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_batchs = math.ceil(len(training_set3) / batch_size)\n",
    "num_batchs_validation = math.ceil(len(validation_set3) / batch_size)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.00005)\n",
    "hist = model3.fit(\n",
    "    gen_batch(\n",
    "        training_set3, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=50,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set3, batch_size=64, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "84cc2e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "#make a prediction by using the model\n",
    "y_pred_3 = model3.predict(\n",
    "    gen_batch(testing_set, batch_size=64, shuffle=False)\n",
    ")\n",
    "y_pred_3 = np.reshape(y_pred_3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d6037413",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'label':y_pred_3})\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('trial_3_GGNNRandomLastlll.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055451c",
   "metadata": {},
   "source": [
    "it was better on kaggle and got 0.87858 so i decided to go with randomOversample and try different mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d5129d",
   "metadata": {},
   "source": [
    "# Trial 3.2 (randomOverSample)(RGCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "258ceebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_7/StatefulPartitionedCall:0', description=\"created by layer 'gnn_7'\")\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_22 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_7 (TFOpLamb  ()                  0           ['input_24[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 80)           40000       ['input_22[0][0]']               \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  ()                  0           ['tf.math.reduce_max_7[0][0]']   \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " gnn_7 (GNN)                    (None, 64)           133376      ['embedding_7[0][0]',            \n",
      "                                                                  'input_23[0][0]',               \n",
      "                                                                  'input_24[0][0]',               \n",
      "                                                                  'tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.segment_mean_7 (TFOpLa  (None, 64)          0           ['gnn_7[0][0]',                  \n",
      " mbda)                                                            'input_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 128)          8320        ['tf.math.segment_mean_7[0][0]'] \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 64)           8256        ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            65          ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 190,017\n",
      "Trainable params: 190,017\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "\n",
    "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
    "\n",
    "num_graph = tf.reduce_max(node2graph)+1  \n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"message_calculation_class\"] = 'RGCN'\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_layers\"] = 6\n",
    "\n",
    "\n",
    "gnn_layer = GNN(params) \n",
    "\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )\n",
    "\n",
    "l1 = Dense(128,activation='relu')(avg)\n",
    "l2 = Dense(64,activation='relu')(l1)\n",
    "pred = Dense(1, activation='sigmoid')(l2)\n",
    "\n",
    "\n",
    "model4 = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d878d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0f1b7f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_5_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_5_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/cond_5_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgcn_4/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgcn_4/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/rgcn_4/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgcn/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgcn/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/rgcn/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 15s 20ms/step - loss: 0.6221 - auc: 0.7061 - val_loss: 0.5862 - val_auc: 0.7535 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.5889 - auc: 0.7481 - val_loss: 0.5504 - val_auc: 0.7894 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.5666 - auc: 0.7724 - val_loss: 0.5363 - val_auc: 0.8035 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.5493 - auc: 0.7912 - val_loss: 0.5303 - val_auc: 0.8116 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.5367 - auc: 0.8026 - val_loss: 0.5086 - val_auc: 0.8269 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.5252 - auc: 0.8137 - val_loss: 0.5137 - val_auc: 0.8341 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.5175 - auc: 0.8216 - val_loss: 0.5003 - val_auc: 0.8376 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.5038 - auc: 0.8328 - val_loss: 0.4789 - val_auc: 0.8560 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.4892 - auc: 0.8439 - val_loss: 0.4599 - val_auc: 0.8636 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.4710 - auc: 0.8566 - val_loss: 0.4401 - val_auc: 0.8783 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.4586 - auc: 0.8651 - val_loss: 0.4430 - val_auc: 0.8850 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.4422 - auc: 0.8756 - val_loss: 0.4157 - val_auc: 0.8923 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.4265 - auc: 0.8850 - val_loss: 0.3892 - val_auc: 0.9060 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.4177 - auc: 0.8897 - val_loss: 0.3843 - val_auc: 0.9080 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.4027 - auc: 0.8978 - val_loss: 0.3636 - val_auc: 0.9176 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.3905 - auc: 0.9042 - val_loss: 0.3623 - val_auc: 0.9196 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.3768 - auc: 0.9111 - val_loss: 0.3488 - val_auc: 0.9269 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.3625 - auc: 0.9179 - val_loss: 0.3267 - val_auc: 0.9344 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.3511 - auc: 0.9230 - val_loss: 0.3371 - val_auc: 0.9332 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.3446 - auc: 0.9259 - val_loss: 0.3058 - val_auc: 0.9419 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.3346 - auc: 0.9303 - val_loss: 0.3183 - val_auc: 0.9410 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.3212 - auc: 0.9355 - val_loss: 0.2799 - val_auc: 0.9503 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "633/633 [==============================] - 12s 20ms/step - loss: 0.3145 - auc: 0.9385 - val_loss: 0.2832 - val_auc: 0.9498 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3046 - auc: 0.9422\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.3046 - auc: 0.9422 - val_loss: 0.2827 - val_auc: 0.9502 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.2594 - auc: 0.9576 - val_loss: 0.2486 - val_auc: 0.9631 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.2490 - auc: 0.9606 - val_loss: 0.2281 - val_auc: 0.9672 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.2412 - auc: 0.9630 - val_loss: 0.2296 - val_auc: 0.9671 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.2390 - auc: 0.9634 - val_loss: 0.2189 - val_auc: 0.9687 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.2355 - auc: 0.9645 - val_loss: 0.2268 - val_auc: 0.9684 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2277 - auc: 0.9666\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.2277 - auc: 0.9666 - val_loss: 0.2257 - val_auc: 0.9687 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2201 - auc: 0.9689 - val_loss: 0.2054 - val_auc: 0.9733 - lr: 5.0000e-05\n",
      "Epoch 32/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2187 - auc: 0.9694 - val_loss: 0.2119 - val_auc: 0.9730 - lr: 5.0000e-05\n",
      "Epoch 33/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.2165 - auc: 0.9700 - val_loss: 0.2177 - val_auc: 0.9699 - lr: 5.0000e-05\n",
      "Epoch 34/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.2132 - auc: 0.9706 - val_loss: 0.2039 - val_auc: 0.9743 - lr: 5.0000e-05\n",
      "Epoch 35/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2129 - auc: 0.9706 - val_loss: 0.2157 - val_auc: 0.9729 - lr: 5.0000e-05\n",
      "Epoch 36/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2116 - auc: 0.9710 - val_loss: 0.2026 - val_auc: 0.9733 - lr: 5.0000e-05\n",
      "Epoch 37/50\n",
      "633/633 [==============================] - 11s 17ms/step - loss: 0.2119 - auc: 0.9708 - val_loss: 0.2145 - val_auc: 0.9716 - lr: 5.0000e-05\n",
      "Epoch 38/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2102 - auc: 0.9712 - val_loss: 0.1958 - val_auc: 0.9754 - lr: 5.0000e-05\n",
      "Epoch 39/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.2094 - auc: 0.9716 - val_loss: 0.2092 - val_auc: 0.9720 - lr: 5.0000e-05\n",
      "Epoch 40/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.2095 - auc: 0.9713 - val_loss: 0.2039 - val_auc: 0.9744 - lr: 5.0000e-05\n",
      "Epoch 41/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2059 - auc: 0.9725 - val_loss: 0.2022 - val_auc: 0.9734 - lr: 5.0000e-05\n",
      "Epoch 42/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2095 - auc: 0.9714 - val_loss: 0.1972 - val_auc: 0.9764 - lr: 5.0000e-05\n",
      "Epoch 43/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2056 - auc: 0.9725Restoring model weights from the end of the best epoch: 38.\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.2056 - auc: 0.9725 - val_loss: 0.1994 - val_auc: 0.9740 - lr: 5.0000e-05\n",
      "Epoch 43: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_batchs = math.ceil(len(training_set3) / batch_size)\n",
    "num_batchs_validation = math.ceil(len(validation_set3) / batch_size)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.00005)\n",
    "hist = model4.fit(\n",
    "    gen_batch(\n",
    "        training_set3, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=50,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set3, batch_size=64, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab04b47",
   "metadata": {},
   "source": [
    "good but not better than ggnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0127a5eb",
   "metadata": {},
   "source": [
    "# Trial 3.3 (randomOverSample)(RGAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "eaf10a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_9/StatefulPartitionedCall:0', description=\"created by layer 'gnn_9'\")\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_30 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_9 (TFOpLamb  ()                  0           ['input_30[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)        (None, 80)           40000       ['input_28[0][0]']               \n",
      "                                                                                                  \n",
      " input_29 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  ()                  0           ['tf.math.reduce_max_9[0][0]']   \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " gnn_9 (GNN)                    (None, 64)           134144      ['embedding_9[0][0]',            \n",
      "                                                                  'input_29[0][0]',               \n",
      "                                                                  'input_30[0][0]',               \n",
      "                                                                  'tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.segment_mean_8 (TFOpLa  (None, 64)          0           ['gnn_9[0][0]',                  \n",
      " mbda)                                                            'input_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          8320        ['tf.math.segment_mean_8[0][0]'] \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 64)           8256        ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 1)            65          ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 190,785\n",
      "Trainable params: 190,785\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "\n",
    "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
    "\n",
    "num_graph = tf.reduce_max(node2graph)+1  \n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"message_calculation_class\"] = 'RGAT'\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_layers\"] = 6\n",
    "params[\"num_heads\"] = 8\n",
    "\n",
    "\n",
    "gnn_layer = GNN(params) \n",
    "\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )\n",
    "\n",
    "l1 = Dense(128,activation='relu')(avg)\n",
    "l2 = Dense(64,activation='relu')(l1)\n",
    "pred = Dense(1, activation='sigmoid')(l2)\n",
    "\n",
    "\n",
    "model5 = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "model5.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "33a0e03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "633/633 [==============================] - 38s 60ms/step - loss: 0.0991 - auc: 0.9921 - val_loss: 0.1200 - val_auc: 0.9873 - lr: 5.0000e-05\n",
      "Epoch 2/50\n",
      "633/633 [==============================] - 39s 62ms/step - loss: 0.1000 - auc: 0.9917 - val_loss: 0.1169 - val_auc: 0.9875 - lr: 5.0000e-05\n",
      "Epoch 3/50\n",
      "633/633 [==============================] - 38s 60ms/step - loss: 0.0983 - auc: 0.9918 - val_loss: 0.1159 - val_auc: 0.9879 - lr: 5.0000e-05\n",
      "Epoch 4/50\n",
      "633/633 [==============================] - 36s 58ms/step - loss: 0.0987 - auc: 0.9919 - val_loss: 0.1143 - val_auc: 0.9872 - lr: 5.0000e-05\n",
      "Epoch 5/50\n",
      "633/633 [==============================] - 36s 57ms/step - loss: 0.0985 - auc: 0.9919 - val_loss: 0.1126 - val_auc: 0.9884 - lr: 5.0000e-05\n",
      "Epoch 6/50\n",
      "633/633 [==============================] - 37s 59ms/step - loss: 0.0955 - auc: 0.9924 - val_loss: 0.1088 - val_auc: 0.9886 - lr: 5.0000e-05\n",
      "Epoch 7/50\n",
      "633/633 [==============================] - 37s 58ms/step - loss: 0.0978 - auc: 0.9921 - val_loss: 0.1164 - val_auc: 0.9880 - lr: 5.0000e-05\n",
      "Epoch 8/50\n",
      "633/633 [==============================] - 35s 56ms/step - loss: 0.0974 - auc: 0.9921 - val_loss: 0.1176 - val_auc: 0.9874 - lr: 5.0000e-05\n",
      "Epoch 9/50\n",
      "633/633 [==============================] - 37s 58ms/step - loss: 0.0956 - auc: 0.9924 - val_loss: 0.1067 - val_auc: 0.9893 - lr: 5.0000e-05\n",
      "Epoch 10/50\n",
      "633/633 [==============================] - 37s 58ms/step - loss: 0.0977 - auc: 0.9920 - val_loss: 0.1131 - val_auc: 0.9883 - lr: 5.0000e-05\n",
      "Epoch 11/50\n",
      "633/633 [==============================] - 38s 60ms/step - loss: 0.0950 - auc: 0.9925 - val_loss: 0.1172 - val_auc: 0.9878 - lr: 5.0000e-05\n",
      "Epoch 12/50\n",
      "633/633 [==============================] - 37s 59ms/step - loss: 0.0961 - auc: 0.9922 - val_loss: 0.1103 - val_auc: 0.9882 - lr: 5.0000e-05\n",
      "Epoch 13/50\n",
      "633/633 [==============================] - 38s 59ms/step - loss: 0.0930 - auc: 0.9928 - val_loss: 0.1210 - val_auc: 0.9868 - lr: 5.0000e-05\n",
      "Epoch 14/50\n",
      "633/633 [==============================] - 37s 58ms/step - loss: 0.0926 - auc: 0.9927 - val_loss: 0.1053 - val_auc: 0.9893 - lr: 5.0000e-05\n",
      "Epoch 15/50\n",
      "633/633 [==============================] - 37s 59ms/step - loss: 0.0945 - auc: 0.9925 - val_loss: 0.1206 - val_auc: 0.9866 - lr: 5.0000e-05\n",
      "Epoch 16/50\n",
      "633/633 [==============================] - 37s 59ms/step - loss: 0.0933 - auc: 0.9927 - val_loss: 0.1129 - val_auc: 0.9882 - lr: 5.0000e-05\n",
      "Epoch 17/50\n",
      "633/633 [==============================] - 38s 61ms/step - loss: 0.0910 - auc: 0.9931 - val_loss: 0.1134 - val_auc: 0.9874 - lr: 5.0000e-05\n",
      "Epoch 18/50\n",
      "633/633 [==============================] - 37s 58ms/step - loss: 0.0953 - auc: 0.9923 - val_loss: 0.1078 - val_auc: 0.9891 - lr: 5.0000e-05\n",
      "Epoch 19/50\n",
      "632/633 [============================>.] - ETA: 0s - loss: 0.0916 - auc: 0.9930Restoring model weights from the end of the best epoch: 14.\n",
      "633/633 [==============================] - 37s 59ms/step - loss: 0.0916 - auc: 0.9930 - val_loss: 0.1066 - val_auc: 0.9891 - lr: 5.0000e-05\n",
      "Epoch 19: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_batchs = math.ceil(len(training_set3) / batch_size)\n",
    "num_batchs_validation = math.ceil(len(validation_set3) / batch_size)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.0001)\n",
    "hist = model5.fit(\n",
    "    gen_batch(\n",
    "        training_set3, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=50,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set3, batch_size=64, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c8058efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 3s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "#make a prediction by using the model 0.9890 auc\n",
    "y_pred_5 = model5.predict(\n",
    "    gen_batch(testing_set, batch_size=64, shuffle=False)\n",
    ")\n",
    "y_pred_5 = np.reshape(y_pred_5, -1)\n",
    "submission = pd.DataFrame({'label':y_pred_5})\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('trial_3_RGAT3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4266635",
   "metadata": {},
   "source": [
    "# Trial 3.4 (randomOverSample)(RGIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6e291fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_11/StatefulPartitionedCall:0', description=\"created by layer 'gnn_11'\")\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_36 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_11 (TFOpLam  ()                  0           ['input_36[0][0]']               \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)       (None, 80)           40000       ['input_34[0][0]']               \n",
      "                                                                                                  \n",
      " input_35 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  ()                  0           ['tf.math.reduce_max_11[0][0]']  \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " gnn_11 (GNN)                   (None, 64)           305408      ['embedding_11[0][0]',           \n",
      "                                                                  'input_35[0][0]',               \n",
      "                                                                  'input_36[0][0]',               \n",
      "                                                                  'tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.segment_mean_9 (TFOpLa  (None, 64)          0           ['gnn_11[0][0]',                 \n",
      " mbda)                                                            'input_36[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 128)          8320        ['tf.math.segment_mean_9[0][0]'] \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 64)           8256        ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 1)            65          ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 362,049\n",
      "Trainable params: 362,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "\n",
    "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
    "\n",
    "num_graph = tf.reduce_max(node2graph)+1  \n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"message_calculation_class\"] = 'RGIN'\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_layers\"] = 6\n",
    "params[\"num_aggr_MLP_hidden_layers\"] = 6\n",
    "\n",
    "\n",
    "gnn_layer = GNN(params) \n",
    "\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )\n",
    "\n",
    "l1 = Dense(128,activation='relu')(avg)\n",
    "l2 = Dense(64,activation='relu')(l1)\n",
    "pred = Dense(1, activation='sigmoid')(l2)\n",
    "\n",
    "\n",
    "model6 = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "model6.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c9ced8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgin_4/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgin_4/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/rgin_4/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgin_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgin_2/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/rgin_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgin/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgin/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/rgin/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 19s 25ms/step - loss: 0.6728 - auc: 0.6039 - val_loss: 0.6502 - val_auc: 0.6613 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.6391 - auc: 0.6762 - val_loss: 0.6184 - val_auc: 0.7137 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.6360 - auc: 0.6860 - val_loss: 0.6396 - val_auc: 0.6816 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.6410 - auc: 0.6783\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.6410 - auc: 0.6783 - val_loss: 0.6357 - val_auc: 0.6886 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.6363 - auc: 0.6855 - val_loss: 0.6363 - val_auc: 0.6852 - lr: 2.0000e-04\n",
      "Epoch 6/50\n",
      "632/633 [============================>.] - ETA: 0s - loss: 0.6359 - auc: 0.6848\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "633/633 [==============================] - 16s 25ms/step - loss: 0.6359 - auc: 0.6848 - val_loss: 0.6357 - val_auc: 0.6894 - lr: 2.0000e-04\n",
      "Epoch 7/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.6342 - auc: 0.6876Restoring model weights from the end of the best epoch: 2.\n",
      "633/633 [==============================] - 15s 24ms/step - loss: 0.6342 - auc: 0.6876 - val_loss: 0.6349 - val_auc: 0.6888 - lr: 1.0000e-04\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_batchs = math.ceil(len(training_set3) / batch_size)\n",
    "num_batchs_validation = math.ceil(len(validation_set3) / batch_size)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.0001)\n",
    "hist = model6.fit(\n",
    "    gen_batch(\n",
    "        training_set3, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=50,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set3, batch_size=64, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ad7d1",
   "metadata": {},
   "source": [
    "the worst one so far :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8e11a8",
   "metadata": {},
   "source": [
    "# Trial 3.5 (randomOverSample)(GNN-Edge-MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5af42cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_12/StatefulPartitionedCall:0', description=\"created by layer 'gnn_12'\")\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_39 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_37 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_12 (TFOpLam  ()                  0           ['input_39[0][0]']               \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " embedding_12 (Embedding)       (None, 80)           40000       ['input_37[0][0]']               \n",
      "                                                                                                  \n",
      " input_38 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  ()                  0           ['tf.math.reduce_max_12[0][0]']  \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " gnn_12 (GNN)                   (None, 64)           133376      ['embedding_12[0][0]',           \n",
      "                                                                  'input_38[0][0]',               \n",
      "                                                                  'input_39[0][0]',               \n",
      "                                                                  'tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.segment_mean_10 (TFOpL  (None, 64)          0           ['gnn_12[0][0]',                 \n",
      " ambda)                                                           'input_39[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 128)          8320        ['tf.math.segment_mean_10[0][0]']\n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 64)           8256        ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 1)            65          ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 190,017\n",
      "Trainable params: 190,017\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "\n",
    "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
    "\n",
    "num_graph = tf.reduce_max(node2graph)+1  \n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"message_calculation_class\"] = 'gnn_edge_mlp'\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_layers\"] = 6\n",
    "\n",
    "\n",
    "gnn_layer = GNN(params) \n",
    "\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )\n",
    "\n",
    "l1 = Dense(128,activation='relu')(avg)\n",
    "l2 = Dense(64,activation='relu')(l1)\n",
    "pred = Dense(1, activation='sigmoid')(l2)\n",
    "\n",
    "\n",
    "model7 = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "model7.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bfb99eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__edge_mlp_4/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__edge_mlp_4/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/gnn__edge_mlp_4/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__edge_mlp_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__edge_mlp_2/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/gnn__edge_mlp_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__edge_mlp/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__edge_mlp/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/gnn__edge_mlp/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 14s 19ms/step - loss: 0.6239 - auc: 0.7023 - val_loss: 0.5886 - val_auc: 0.7469 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.5944 - auc: 0.7387 - val_loss: 0.5764 - val_auc: 0.7741 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.5681 - auc: 0.7653 - val_loss: 0.5395 - val_auc: 0.7911 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.5568 - auc: 0.7811 - val_loss: 0.5528 - val_auc: 0.7982 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.5418 - auc: 0.7970 - val_loss: 0.5190 - val_auc: 0.8214 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.5293 - auc: 0.8089 - val_loss: 0.5227 - val_auc: 0.8219 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.5136 - auc: 0.8234 - val_loss: 0.5023 - val_auc: 0.8363 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.5001 - auc: 0.8351 - val_loss: 0.4788 - val_auc: 0.8505 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.4829 - auc: 0.8482 - val_loss: 0.4513 - val_auc: 0.8696 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.4688 - auc: 0.8583 - val_loss: 0.4592 - val_auc: 0.8688 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.4554 - auc: 0.8673 - val_loss: 0.4405 - val_auc: 0.8809 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.4412 - auc: 0.8762 - val_loss: 0.4296 - val_auc: 0.8886 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "633/633 [==============================] - 17s 27ms/step - loss: 0.4293 - auc: 0.8834 - val_loss: 0.4160 - val_auc: 0.8910 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.4200 - auc: 0.8889 - val_loss: 0.4220 - val_auc: 0.8969 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.4047 - auc: 0.8971 - val_loss: 0.3851 - val_auc: 0.9112 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.3911 - auc: 0.9040 - val_loss: 0.3886 - val_auc: 0.9069 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.3819 - auc: 0.9089 - val_loss: 0.3730 - val_auc: 0.9204 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.3706 - auc: 0.9145 - val_loss: 0.3492 - val_auc: 0.9244 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.3603 - auc: 0.9190 - val_loss: 0.3293 - val_auc: 0.9352 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.3545 - auc: 0.9216 - val_loss: 0.3625 - val_auc: 0.9272 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.3401 - auc: 0.9284 - val_loss: 0.3290 - val_auc: 0.9333 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.3305 - auc: 0.9322 - val_loss: 0.3002 - val_auc: 0.9441 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.3206 - auc: 0.9362 - val_loss: 0.3015 - val_auc: 0.9441 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "632/633 [============================>.] - ETA: 0s - loss: 0.3115 - auc: 0.9398\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.3114 - auc: 0.9399 - val_loss: 0.3019 - val_auc: 0.9460 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.2713 - auc: 0.9538 - val_loss: 0.2518 - val_auc: 0.9617 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.2621 - auc: 0.9570 - val_loss: 0.2477 - val_auc: 0.9606 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2530 - auc: 0.9596 - val_loss: 0.2603 - val_auc: 0.9597 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2504 - auc: 0.9603 - val_loss: 0.2378 - val_auc: 0.9624 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.2449 - auc: 0.9619 - val_loss: 0.2355 - val_auc: 0.9642 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.2436 - auc: 0.9623 - val_loss: 0.2191 - val_auc: 0.9677 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2365 - auc: 0.9641 - val_loss: 0.2353 - val_auc: 0.9653 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2341 - auc: 0.9651\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2341 - auc: 0.9651 - val_loss: 0.2429 - val_auc: 0.9656 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.2284 - auc: 0.9666 - val_loss: 0.2248 - val_auc: 0.9677 - lr: 5.0000e-05\n",
      "Epoch 34/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2212 - auc: 0.9686 - val_loss: 0.2134 - val_auc: 0.9715 - lr: 5.0000e-05\n",
      "Epoch 35/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2250 - auc: 0.9675 - val_loss: 0.2209 - val_auc: 0.9677 - lr: 5.0000e-05\n",
      "Epoch 36/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2232 - auc: 0.9679 - val_loss: 0.2079 - val_auc: 0.9719 - lr: 5.0000e-05\n",
      "Epoch 37/50\n",
      "633/633 [==============================] - 12s 19ms/step - loss: 0.2232 - auc: 0.9678 - val_loss: 0.2200 - val_auc: 0.9701 - lr: 5.0000e-05\n",
      "Epoch 38/50\n",
      "633/633 [==============================] - 12s 18ms/step - loss: 0.2187 - auc: 0.9692 - val_loss: 0.2088 - val_auc: 0.9717 - lr: 5.0000e-05\n",
      "Epoch 39/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2203 - auc: 0.9685 - val_loss: 0.2109 - val_auc: 0.9705 - lr: 5.0000e-05\n",
      "Epoch 40/50\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2180 - auc: 0.9693 - val_loss: 0.2126 - val_auc: 0.9698 - lr: 5.0000e-05\n",
      "Epoch 41/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2142 - auc: 0.9702Restoring model weights from the end of the best epoch: 36.\n",
      "633/633 [==============================] - 11s 18ms/step - loss: 0.2142 - auc: 0.9702 - val_loss: 0.2109 - val_auc: 0.9718 - lr: 5.0000e-05\n",
      "Epoch 41: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_batchs = math.ceil(len(training_set3) / batch_size)\n",
    "num_batchs_validation = math.ceil(len(validation_set3) / batch_size)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.00005)\n",
    "hist = model7.fit(\n",
    "    gen_batch(\n",
    "        training_set3, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=50,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set3, batch_size=64, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b19a3",
   "metadata": {},
   "source": [
    "# Trial 3.6 (randomOverSample)(GNN-FiLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "64c90c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_15/StatefulPartitionedCall:0', description=\"created by layer 'gnn_15'\")\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_48 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_46 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_15 (TFOpLam  ()                  0           ['input_48[0][0]']               \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " embedding_15 (Embedding)       (None, 80)           40000       ['input_46[0][0]']               \n",
      "                                                                                                  \n",
      " input_47 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  ()                  0           ['tf.math.reduce_max_15[0][0]']  \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " gnn_15 (GNN)                   (None, 64)           280832      ['embedding_15[0][0]',           \n",
      "                                                                  'input_47[0][0]',               \n",
      "                                                                  'input_48[0][0]',               \n",
      "                                                                  'tf.__operators__.add_15[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.segment_mean_12 (TFOpL  (None, 64)          0           ['gnn_15[0][0]',                 \n",
      " ambda)                                                           'input_48[0][0]']               \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 128)          8320        ['tf.math.segment_mean_12[0][0]']\n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 64)           8256        ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 1)            65          ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 337,473\n",
      "Trainable params: 337,473\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "\n",
    "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
    "\n",
    "num_graph = tf.reduce_max(node2graph)+1  \n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"message_calculation_class\"] = 'GNN_FiLM'\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_layers\"] = 6\n",
    "params[\"film_parameter_MLP_hidden_layers\"] = 1\n",
    "\n",
    "\n",
    "gnn_layer = GNN(params) \n",
    "\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )\n",
    "\n",
    "l1 = Dense(128,activation='relu')(avg)\n",
    "l2 = Dense(64,activation='relu')(l1)\n",
    "pred = Dense(1, activation='sigmoid')(l2)\n",
    "\n",
    "\n",
    "model8 = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "model8.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "903f31f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "633/633 [==============================] - 14s 22ms/step - loss: 0.0259 - auc: 0.9987 - val_loss: 0.0740 - val_auc: 0.9920 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "633/633 [==============================] - 13s 21ms/step - loss: 0.0262 - auc: 0.9986 - val_loss: 0.0764 - val_auc: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0238 - auc: 0.9989\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
      "633/633 [==============================] - 13s 21ms/step - loss: 0.0238 - auc: 0.9989 - val_loss: 0.0770 - val_auc: 0.9920 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "633/633 [==============================] - 13s 20ms/step - loss: 0.0210 - auc: 0.9991 - val_loss: 0.0787 - val_auc: 0.9922 - lr: 5.0000e-05\n",
      "Epoch 5/50\n",
      "633/633 [==============================] - 13s 21ms/step - loss: 0.0210 - auc: 0.9990 - val_loss: 0.0735 - val_auc: 0.9927 - lr: 5.0000e-05\n",
      "Epoch 6/50\n",
      "633/633 [==============================] - 13s 21ms/step - loss: 0.0205 - auc: 0.9992 - val_loss: 0.0835 - val_auc: 0.9915 - lr: 5.0000e-05\n",
      "Epoch 7/50\n",
      "633/633 [==============================] - 14s 22ms/step - loss: 0.0201 - auc: 0.9992 - val_loss: 0.0787 - val_auc: 0.9920 - lr: 5.0000e-05\n",
      "Epoch 8/50\n",
      "633/633 [==============================] - 14s 22ms/step - loss: 0.0201 - auc: 0.9992 - val_loss: 0.0751 - val_auc: 0.9916 - lr: 5.0000e-05\n",
      "Epoch 9/50\n",
      "633/633 [==============================] - 13s 21ms/step - loss: 0.0196 - auc: 0.9992 - val_loss: 0.0758 - val_auc: 0.9921 - lr: 5.0000e-05\n",
      "Epoch 10/50\n",
      "632/633 [============================>.] - ETA: 0s - loss: 0.0188 - auc: 0.9992Restoring model weights from the end of the best epoch: 5.\n",
      "633/633 [==============================] - 13s 21ms/step - loss: 0.0188 - auc: 0.9992 - val_loss: 0.0798 - val_auc: 0.9917 - lr: 5.0000e-05\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_batchs = math.ceil(len(training_set3) / batch_size)\n",
    "num_batchs_validation = math.ceil(len(validation_set3) / batch_size)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.00005)\n",
    "hist = model8.fit(\n",
    "    gen_batch(\n",
    "        training_set3, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=50,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set3, batch_size=64, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b654dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "#make a prediction by using the model 0.9926 auc\n",
    "y_pred_8 = model8.predict(\n",
    "    gen_batch(testing_set, batch_size=64, shuffle=False)\n",
    ")\n",
    "y_pred_8 = np.reshape(y_pred_8, -1)\n",
    "submission = pd.DataFrame({'label':y_pred_8})\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('trial_3_film3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63780d2d",
   "metadata": {},
   "source": [
    "it preformed really well but at the end ggnn won so i will give it another try with different hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b51918",
   "metadata": {},
   "source": [
    "# Trial 3.7 (randomOverSample)(ggnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c60d4fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn_23/StatefulPartitionedCall:0', description=\"created by layer 'gnn_23'\")\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_72 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_70 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_23 (TFOpLam  ()                  0           ['input_72[0][0]']               \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " embedding_23 (Embedding)       (None, 80)           40000       ['input_70[0][0]']               \n",
      "                                                                                                  \n",
      " input_71 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  ()                  0           ['tf.math.reduce_max_23[0][0]']  \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " gnn_23 (GNN)                   (None, 128)          1049600     ['embedding_23[0][0]',           \n",
      "                                                                  'input_71[0][0]',               \n",
      "                                                                  'input_72[0][0]',               \n",
      "                                                                  'tf.__operators__.add_23[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.segment_mean_13 (TFOpL  (None, 128)         0           ['gnn_23[0][0]',                 \n",
      " ambda)                                                           'input_72[0][0]']               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 128)          16512       ['tf.math.segment_mean_13[0][0]']\n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 64)           8256        ['dense_35[0][0]']               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 1)            65          ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,114,433\n",
      "Trainable params: 1,114,433\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "\n",
    "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
    "\n",
    "num_graph = tf.reduce_max(node2graph)+1  \n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"message_calculation_class\"] = 'GGNN'\n",
    "params[\"hidden_dim\"] = 128\n",
    "params[\"num_layers\"] = 6\n",
    "\n",
    "\n",
    "gnn_layer = GNN(params) \n",
    "\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )\n",
    "\n",
    "l1 = Dense(128,activation='relu')(avg)\n",
    "l2 = Dense(64,activation='relu')(l1)\n",
    "pred = Dense(1, activation='sigmoid')(l2)\n",
    "\n",
    "\n",
    "model9 = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "model9.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")\n",
    "model9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b930ce89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "633/633 [==============================] - 20s 31ms/step - loss: 0.0216 - auc: 0.9992 - val_loss: 0.0759 - val_auc: 0.9934 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "633/633 [==============================] - 19s 30ms/step - loss: 0.0193 - auc: 0.9994 - val_loss: 0.0764 - val_auc: 0.9938 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "633/633 [==============================] - 19s 31ms/step - loss: 0.0203 - auc: 0.9993 - val_loss: 0.0781 - val_auc: 0.9935 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "633/633 [==============================] - 20s 31ms/step - loss: 0.0191 - auc: 0.9994 - val_loss: 0.0700 - val_auc: 0.9946 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "633/633 [==============================] - 19s 31ms/step - loss: 0.0183 - auc: 0.9993 - val_loss: 0.0766 - val_auc: 0.9946 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "633/633 [==============================] - 19s 30ms/step - loss: 0.0176 - auc: 0.9995 - val_loss: 0.0877 - val_auc: 0.9924 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0172 - auc: 0.9994\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
      "633/633 [==============================] - 19s 30ms/step - loss: 0.0172 - auc: 0.9994 - val_loss: 0.0842 - val_auc: 0.9932 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "633/633 [==============================] - 19s 30ms/step - loss: 0.0153 - auc: 0.9995 - val_loss: 0.0697 - val_auc: 0.9948 - lr: 5.0000e-05\n",
      "Epoch 9/50\n",
      "633/633 [==============================] - 19s 30ms/step - loss: 0.0147 - auc: 0.9995 - val_loss: 0.0706 - val_auc: 0.9941 - lr: 5.0000e-05\n",
      "Epoch 10/50\n",
      "633/633 [==============================] - 19s 31ms/step - loss: 0.0143 - auc: 0.9997 - val_loss: 0.0760 - val_auc: 0.9943 - lr: 5.0000e-05\n",
      "Epoch 11/50\n",
      "633/633 [==============================] - 19s 31ms/step - loss: 0.0140 - auc: 0.9996 - val_loss: 0.0698 - val_auc: 0.9944 - lr: 5.0000e-05\n",
      "Epoch 12/50\n",
      "633/633 [==============================] - 19s 30ms/step - loss: 0.0135 - auc: 0.9996 - val_loss: 0.0792 - val_auc: 0.9927 - lr: 5.0000e-05\n",
      "Epoch 13/50\n",
      "631/633 [============================>.] - ETA: 0s - loss: 0.0137 - auc: 0.9996Restoring model weights from the end of the best epoch: 8.\n",
      "633/633 [==============================] - 19s 31ms/step - loss: 0.0137 - auc: 0.9996 - val_loss: 0.0867 - val_auc: 0.9927 - lr: 5.0000e-05\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_batchs = math.ceil(len(training_set3) / batch_size)\n",
    "num_batchs_validation = math.ceil(len(validation_set3) / batch_size)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, min_lr=0.00005)\n",
    "hist = model9.fit(\n",
    "    gen_batch(\n",
    "        training_set3, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=50,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set3, batch_size=64, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "97e4c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 2s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "#make a prediction by using the model 0.9951\n",
    "y_pred_f9 = model9.predict(\n",
    "    gen_batch(testing_set, batch_size=64, shuffle=False)\n",
    ")\n",
    "y_pred_f9 = np.reshape(y_pred_f9, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "566853df",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'label':y_pred_f9})\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('trial_3_GGNNRandomLastlllhypermodel3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936defc",
   "metadata": {},
   "source": [
    "it was worse than 3.1 trial but when i tried to submit the secound best model (film) it got higher than both 0.88152\n",
    "on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36924aa4",
   "metadata": {},
   "source": [
    "# Final trial (trial number 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "48ac3309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_26/StatefulPartitionedCall:0', description=\"created by layer 'gnn_26'\")\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_81 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_79 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_26 (TFOpLam  ()                  0           ['input_81[0][0]']               \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " embedding_26 (Embedding)       (None, 80)           40000       ['input_79[0][0]']               \n",
      "                                                                                                  \n",
      " input_80 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  ()                  0           ['tf.math.reduce_max_26[0][0]']  \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " gnn_26 (GNN)                   (None, 32)           48960       ['embedding_26[0][0]',           \n",
      "                                                                  'input_80[0][0]',               \n",
      "                                                                  'input_81[0][0]',               \n",
      "                                                                  'tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.segment_mean_15 (TFOpL  (None, 32)          0           ['gnn_26[0][0]',                 \n",
      " ambda)                                                           'input_81[0][0]']               \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 128)          4224        ['tf.math.segment_mean_15[0][0]']\n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 64)           8256        ['dense_41[0][0]']               \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 1)            65          ['dense_42[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 101,505\n",
      "Trainable params: 101,505\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "\n",
    "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
    "\n",
    "num_graph = tf.reduce_max(node2graph)+1  \n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"message_calculation_class\"] = 'GNN_FiLM'\n",
    "params[\"hidden_dim\"] = 64\n",
    "params[\"num_layers\"] = 4\n",
    "params[\"film_parameter_MLP_hidden_layers\"] = 1\n",
    "\n",
    "\n",
    "gnn_layer = GNN(params) \n",
    "\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )\n",
    "\n",
    "l1 = Dense(128,activation='relu')(avg)\n",
    "l2 = Dense(64,activation='relu')(l1)\n",
    "pred = Dense(1, activation='sigmoid')(l2)\n",
    "\n",
    "\n",
    "modelf = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "modelf.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")\n",
    "modelf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ec2849c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/concat_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/concat_2:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm_2/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 11s 14ms/step - loss: 0.6092 - auc: 0.7231 - val_loss: 0.5391 - val_auc: 0.8063 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.5276 - auc: 0.8158 - val_loss: 0.5037 - val_auc: 0.8431 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.4711 - auc: 0.8576 - val_loss: 0.4313 - val_auc: 0.8869 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.4145 - auc: 0.8917 - val_loss: 0.3846 - val_auc: 0.9122 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.3696 - auc: 0.9143 - val_loss: 0.3342 - val_auc: 0.9307 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.3282 - auc: 0.9319 - val_loss: 0.3235 - val_auc: 0.9418 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.2989 - auc: 0.9423 - val_loss: 0.2667 - val_auc: 0.9540 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.2632 - auc: 0.9544 - val_loss: 0.2410 - val_auc: 0.9624 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.2366 - auc: 0.9619 - val_loss: 0.2430 - val_auc: 0.9643 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.2243 - auc: 0.9652 - val_loss: 0.2215 - val_auc: 0.9695 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.1990 - auc: 0.9717 - val_loss: 0.1864 - val_auc: 0.9743 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.1852 - auc: 0.9742 - val_loss: 0.1876 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "633/633 [==============================] - 9s 13ms/step - loss: 0.1760 - auc: 0.9763 - val_loss: 0.1534 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "633/633 [==============================] - 9s 13ms/step - loss: 0.1689 - auc: 0.9782 - val_loss: 0.1789 - val_auc: 0.9750 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.1648 - auc: 0.9789 - val_loss: 0.1602 - val_auc: 0.9804 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "633/633 [==============================] - 9s 13ms/step - loss: 0.1518 - auc: 0.9815 - val_loss: 0.1510 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.1402 - auc: 0.9833 - val_loss: 0.1525 - val_auc: 0.9825 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "633/633 [==============================] - 9s 13ms/step - loss: 0.1334 - auc: 0.9847 - val_loss: 0.1516 - val_auc: 0.9827 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.1244 - auc: 0.9864 - val_loss: 0.1376 - val_auc: 0.9851 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.1210 - auc: 0.9873 - val_loss: 0.1457 - val_auc: 0.9845 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.1194 - auc: 0.9876 - val_loss: 0.1559 - val_auc: 0.9807 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "633/633 [==============================] - 9s 13ms/step - loss: 0.1104 - auc: 0.9889 - val_loss: 0.1236 - val_auc: 0.9854 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.1096 - auc: 0.9890 - val_loss: 0.1407 - val_auc: 0.9868 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.0941 - auc: 0.9912 - val_loss: 0.1200 - val_auc: 0.9870 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "633/633 [==============================] - 9s 13ms/step - loss: 0.0996 - auc: 0.9907 - val_loss: 0.1106 - val_auc: 0.9884 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.0926 - auc: 0.9919 - val_loss: 0.1068 - val_auc: 0.9891 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0925 - auc: 0.9918 - val_loss: 0.1082 - val_auc: 0.9872 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.0920 - auc: 0.9918 - val_loss: 0.1144 - val_auc: 0.9862 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0915 - auc: 0.9921 - val_loss: 0.1297 - val_auc: 0.9876 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0807 - auc: 0.9933 - val_loss: 0.0793 - val_auc: 0.9921 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0784 - auc: 0.9939 - val_loss: 0.1048 - val_auc: 0.9890 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0823 - auc: 0.9933 - val_loss: 0.1094 - val_auc: 0.9882 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.0756 - auc: 0.9940 - val_loss: 0.1017 - val_auc: 0.9894 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "632/633 [============================>.] - ETA: 0s - loss: 0.0739 - auc: 0.9942\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "633/633 [==============================] - 9s 13ms/step - loss: 0.0739 - auc: 0.9942 - val_loss: 0.1225 - val_auc: 0.9871 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0637 - auc: 0.9959 - val_loss: 0.0749 - val_auc: 0.9929 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "633/633 [==============================] - 9s 13ms/step - loss: 0.0524 - auc: 0.9968 - val_loss: 0.0921 - val_auc: 0.9896 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0474 - auc: 0.9973 - val_loss: 0.0762 - val_auc: 0.9929 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0429 - auc: 0.9976 - val_loss: 0.0856 - val_auc: 0.9925 - lr: 2.0000e-04\n",
      "Epoch 39/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0396 - auc: 0.9979 - val_loss: 0.0721 - val_auc: 0.9929 - lr: 2.0000e-04\n",
      "Epoch 40/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0391 - auc: 0.9980 - val_loss: 0.0746 - val_auc: 0.9917 - lr: 2.0000e-04\n",
      "Epoch 41/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.0374 - auc: 0.9981 - val_loss: 0.0784 - val_auc: 0.9920 - lr: 2.0000e-04\n",
      "Epoch 42/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0350 - auc: 0.9983 - val_loss: 0.0761 - val_auc: 0.9934 - lr: 2.0000e-04\n",
      "Epoch 43/50\n",
      "632/633 [============================>.] - ETA: 0s - loss: 0.0344 - auc: 0.9983\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.0344 - auc: 0.9983 - val_loss: 0.0737 - val_auc: 0.9928 - lr: 2.0000e-04\n",
      "Epoch 44/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.0311 - auc: 0.9986 - val_loss: 0.0689 - val_auc: 0.9933 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.0301 - auc: 0.9986 - val_loss: 0.0720 - val_auc: 0.9927 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0276 - auc: 0.9988 - val_loss: 0.0712 - val_auc: 0.9928 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "633/633 [==============================] - 8s 13ms/step - loss: 0.0266 - auc: 0.9989 - val_loss: 0.0729 - val_auc: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0272 - auc: 0.9989 - val_loss: 0.0707 - val_auc: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0257 - auc: 0.9989 - val_loss: 0.0662 - val_auc: 0.9930 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "633/633 [==============================] - 9s 14ms/step - loss: 0.0260 - auc: 0.9989 - val_loss: 0.0680 - val_auc: 0.9933 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_batchs = math.ceil(len(training_set3) / batch_size)\n",
    "num_batchs_validation = math.ceil(len(validation_set3) / batch_size)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1,restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, verbose=1, min_lr=0.0001)\n",
    "hist = modelf.fit(\n",
    "    gen_batch(\n",
    "        training_set3, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=50,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set3, batch_size=64, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "aa2f15cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "#make a prediction by using the model 0.9933 auc\n",
    "y_pred_f = modelf.predict(\n",
    "    gen_batch(testing_set, batch_size=64, shuffle=False)\n",
    ")\n",
    "y_pred_f = np.reshape(y_pred_f, -1)\n",
    "submission = pd.DataFrame({'label':y_pred_f})\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('trial_3_filmFINAL1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8865778b",
   "metadata": {},
   "source": [
    "still trial 3.6 was better if you ran the fit cell twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc800d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
